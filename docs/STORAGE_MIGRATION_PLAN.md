# Linch Mind å­˜å‚¨æ¶æ„è¿ç§»è®¡åˆ’

## ğŸ¯ è¿ç§»ç›®æ ‡

ä»**äº‹ä»¶é©±åŠ¨çš„åŸå§‹å­˜å‚¨**è¿ç§»åˆ°**AIé©±åŠ¨çš„æ™ºèƒ½å‘é‡å­˜å‚¨**

## ğŸ“Š å½“å‰é—®é¢˜åˆ†æ

### å½“å‰é”™è¯¯å®ç°
```python
# âŒ GenericEventStorage.py é”™è¯¯åšæ³•
entity_properties = {
    "event_data": event_data,  # å­˜å‚¨10KBåŸå§‹æ•°æ®
    "connector_id": connector_id,
    "event_type": event_type,
}
# æŠŠäº‹ä»¶å½“å®ä½“å­˜å‚¨åˆ°entity_metadataè¡¨
```

### æ•°æ®åº“ç°çŠ¶
```sql
-- å½“å‰åƒåœ¾æ•°æ®
sqlite3 ~/.linch-mind/development/database/linch_mind_dev.db
"SELECT COUNT(*) FROM entity_metadata;"  -- 8ä¸ªæ— æ„ä¹‰äº‹ä»¶
"SELECT entity_id, LENGTH(properties) FROM entity_metadata;"  -- æ¯ä¸ª10KB+
```

## ğŸš€ è¿ç§»å®æ–½è®¡åˆ’

### Phase 1: æ–°æ¶æ„å®ç° (ä¼˜å…ˆçº§æœ€é«˜)

#### 1.1 åˆ›å»ºæ–°çš„Ollamaé›†æˆæœåŠ¡
```python
# daemon/services/ai/ollama_service.py
class OllamaService:
    """æœ¬åœ°AIæœåŠ¡é›†æˆ"""
    
    def __init__(self):
        self.embedding_model = "nomic-embed-text"  # 384ç»´
        self.llm_model = "llama3.2:3b"
        
    async def evaluate_content_value(self, content: str) -> float:
        """AIé©±åŠ¨çš„å†…å®¹ä»·å€¼è¯„ä¼° 0-1åˆ†"""
        prompt = f"""
        è¯„ä¼°å†…å®¹ä»·å€¼(0-1åˆ†):
        - è°ƒè¯•æ—¥å¿—/åƒåœ¾ä¿¡æ¯: 0.0-0.2
        - ä¸´æ—¶æ•°æ®: 0.2-0.4  
        - ä¸€èˆ¬ä¿¡æ¯: 0.4-0.6
        - æœ‰ç”¨ä¿¡æ¯: 0.6-0.8
        - é‡è¦çŸ¥è¯†: 0.8-1.0
        
        å†…å®¹: {content[:500]}
        
        åªè¿”å›æ•°å­—: 0.7
        """
        response = await self._chat(prompt)
        return float(response.strip())
    
    async def extract_semantic_summary(self, content: str) -> str:
        """æå–è¯­ä¹‰æ‘˜è¦(100å­—ä»¥å†…)"""
        prompt = f"""
        å°†ä»¥ä¸‹å†…å®¹å‹ç¼©ä¸º100å­—ä»¥å†…çš„è¯­ä¹‰æ‘˜è¦ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯:
        {content[:2000]}
        
        æ‘˜è¦:
        """
        return await self._chat(prompt)
    
    async def embed_text(self, text: str) -> List[float]:
        """æœ¬åœ°å‘é‡åŒ–"""
        # è°ƒç”¨Ollama APIè¿›è¡Œå‘é‡åŒ–
        pass
```

#### 1.2 åˆ›å»ºæ™ºèƒ½äº‹ä»¶å¤„ç†å™¨
```python
# daemon/services/storage/intelligent_event_processor.py
class IntelligentEventProcessor:
    """AIé©±åŠ¨çš„æ™ºèƒ½äº‹ä»¶å¤„ç†"""
    
    def __init__(self):
        self.ollama = OllamaService()
        self.vector_store = FAISSVectorStore()
        
    async def process_connector_event(self, event: ConnectorEvent) -> bool:
        """æ™ºèƒ½äº‹ä»¶å¤„ç†æµæ°´çº¿"""
        
        # 1. ä»·å€¼è¯„ä¼°
        value_score = await self.ollama.evaluate_content_value(event.content)
        if value_score < 0.3:
            logger.info(f"Discarding low-value content: {value_score}")
            return False  # ç›´æ¥ä¸¢å¼ƒ
            
        # 2. è¯­ä¹‰æ‘˜è¦
        summary = await self.ollama.extract_semantic_summary(event.content)
        
        # 3. å‘é‡åŒ–
        vector = await self.ollama.embed_text(summary)
        
        # 4. å­˜å‚¨åˆ°å‘é‡åº“
        doc_id = await self.vector_store.add_document(
            vector=vector,
            metadata={
                "summary": summary,  # åªå­˜æ‘˜è¦ï¼Œä¸å­˜åŸæ–‡!
                "source": event.connector_id,
                "timestamp": event.timestamp,
                "value_score": value_score,
                "keywords": await self._extract_keywords(summary)
            }
        )
        
        # 5. é«˜ä»·å€¼å†…å®¹æ‰æå–å®ä½“
        if value_score > 0.8:
            entities = await self._extract_valuable_entities(summary)
            await self._store_entities(entities, doc_id)
            
        return True
```

#### 1.3 åˆ›å»ºFAISSå‘é‡å­˜å‚¨
```python
# daemon/services/storage/faiss_vector_store.py
class FAISSVectorStore:
    """åŸºäºFAISSçš„å‘é‡å­˜å‚¨"""
    
    def __init__(self):
        self.index_dir = Path("~/.linch-mind/knowledge/hot_index").expanduser()
        self.current_shard = self._load_current_shard()
        
    def _load_current_shard(self) -> FAISSIndex:
        """åŠ è½½å½“å‰æ´»è·ƒåˆ†ç‰‡"""
        shard_path = self.index_dir / f"current_{datetime.now():%Y_Q%q}"
        if not shard_path.exists():
            return self._create_new_shard(shard_path)
        return self._load_existing_shard(shard_path)
        
    async def add_document(self, vector: List[float], metadata: Dict) -> str:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“"""
        # å‹ç¼©å‘é‡ (384ç»´ -> 256ç»´ + float16)
        compressed_vector = self._compress_vector(vector)
        
        # æ·»åŠ åˆ°FAISSç´¢å¼•
        doc_id = f"doc_{uuid.uuid4().hex[:8]}"
        self.current_shard.add_with_ids([compressed_vector], [doc_id])
        
        # å­˜å‚¨å…ƒæ•°æ®
        await self._store_metadata(doc_id, metadata)
        
        # æ£€æŸ¥åˆ†ç‰‡å¤§å°
        if self.current_shard.ntotal > self.MAX_SHARD_SIZE:
            await self._create_new_shard()
            
        return doc_id
```

### Phase 2: æ›¿æ¢ç°æœ‰å®ç°

#### 2.1 ä¿®æ”¹GenericEventStorage
```python
# ä¿®æ”¹ daemon/services/ipc_routes/generic_event_storage.py
class GenericEventStorage:
    def __init__(self):
        self.intelligent_processor = IntelligentEventProcessor()  # æ–°å¢
        # ä¿ç•™åŸæœ‰å®ç°ä½œä¸ºfallback
        
    async def store_generic_event(self, ...):
        """æ–°çš„æ™ºèƒ½å­˜å‚¨é€»è¾‘"""
        try:
            # ä½¿ç”¨æ–°çš„æ™ºèƒ½å¤„ç†å™¨
            success = await self.intelligent_processor.process_connector_event(
                ConnectorEvent(
                    connector_id=connector_id,
                    event_type=event_type,
                    content=str(event_data),  # è½¬æ¢ä¸ºæ–‡æœ¬
                    timestamp=timestamp
                )
            )
            
            if success:
                logger.info(f"âœ… Intelligently processed event from {connector_id}")
                return True
            else:
                logger.info(f"âš ï¸ Low-value event discarded from {connector_id}")
                return True  # ä¸¢å¼ƒä¹Ÿç®—æˆåŠŸ
                
        except Exception as e:
            logger.error(f"Intelligent processing failed, falling back: {e}")
            # Fallbackåˆ°åŸæœ‰é€»è¾‘ï¼ˆä¸´æ—¶ï¼‰
            return await self._legacy_store_event(...)
```

### Phase 3: æ•°æ®æ¸…ç†å’Œè¿ç§»

#### 3.1 æ¸…ç†å½“å‰åƒåœ¾æ•°æ®
```python
# scripts/cleanup_legacy_data.py
class LegacyDataCleanup:
    """æ¸…ç†ç°æœ‰çš„åƒåœ¾æ•°æ®"""
    
    async def cleanup_entity_metadata(self):
        """æ¸…ç†entity_metadataè¡¨ä¸­çš„äº‹ä»¶æ•°æ®"""
        
        with self.db.get_session() as session:
            # æŸ¥æ‰¾æ‰€æœ‰connector_eventç±»å‹çš„ä¼ªå®ä½“
            fake_entities = session.query(EntityMetadata).filter_by(
                type="connector_event"
            ).all()
            
            logger.info(f"Found {len(fake_entities)} fake entities to clean")
            
            for entity in fake_entities:
                # æ£€æŸ¥æ˜¯å¦å€¼å¾—è¿ç§»
                properties = entity.properties
                content = str(properties.get('event_data', ''))
                
                if len(content) > 1000:  # å¤§å†…å®¹éœ€è¦è¯„ä¼°
                    value_score = await self.ollama.evaluate_content_value(content)
                    
                    if value_score > 0.5:  # æœ‰ä»·å€¼çš„è¿ç§»åˆ°æ–°ç³»ç»Ÿ
                        await self.intelligent_processor.process_connector_event(
                            ConnectorEvent(
                                connector_id=properties.get('connector_id'),
                                event_type=properties.get('event_type'),
                                content=content,
                                timestamp=properties.get('timestamp')
                            )
                        )
                        logger.info(f"Migrated valuable entity: {entity.entity_id}")
                    
                # åˆ é™¤åŸå§‹åƒåœ¾æ•°æ®
                session.delete(entity)
                
            session.commit()
            logger.info("âœ… Legacy data cleanup completed")
```

#### 3.2 è¿ç§»è„šæœ¬
```bash
#!/bin/bash
# scripts/migrate_to_intelligent_storage.sh

echo "ğŸš€ å¼€å§‹è¿ç§»åˆ°æ™ºèƒ½å­˜å‚¨æ¶æ„"

# 1. å¤‡ä»½å½“å‰æ•°æ®åº“
cp ~/.linch-mind/development/database/linch_mind_dev.db \
   ~/.linch-mind/development/database/linch_mind_dev.backup.$(date +%Y%m%d_%H%M%S).db

# 2. åˆå§‹åŒ–Ollamaæ¨¡å‹
ollama pull nomic-embed-text
ollama pull llama3.2:3b

# 3. åˆ›å»ºæ–°çš„å­˜å‚¨ç›®å½•ç»“æ„
mkdir -p ~/.linch-mind/knowledge/{hot_index,warm_index,cold_archive,ollama_cache}

# 4. è¿è¡Œæ•°æ®æ¸…ç†å’Œè¿ç§»
cd daemon && python -m scripts.cleanup_legacy_data

# 5. æ›´æ–°ä»£ç åˆ°æ–°å®ç°
git checkout feature/intelligent-storage

echo "âœ… è¿ç§»å®Œæˆ"
```

## ğŸ“‹ å®æ–½æ£€æŸ¥æ¸…å•

### âœ… å‡†å¤‡é˜¶æ®µ
- [ ] å®‰è£…Ollamaå¹¶ä¸‹è½½æ¨¡å‹
- [ ] å¤‡ä»½å½“å‰æ•°æ®åº“
- [ ] åˆ›å»ºæ–°å­˜å‚¨ç›®å½•ç»“æ„

### âœ… å¼€å‘é˜¶æ®µ  
- [ ] å®ç°OllamaService
- [ ] å®ç°IntelligentEventProcessor
- [ ] å®ç°FAISSVectorStore
- [ ] ä¿®æ”¹GenericEventStorage

### âœ… æµ‹è¯•é˜¶æ®µ
- [ ] å•å…ƒæµ‹è¯•æ–°ç»„ä»¶
- [ ] é›†æˆæµ‹è¯•æ™ºèƒ½å¤„ç†æµæ°´çº¿
- [ ] æ€§èƒ½æµ‹è¯•å‘é‡æ£€ç´¢

### âœ… è¿ç§»é˜¶æ®µ
- [ ] æ¸…ç†ç°æœ‰åƒåœ¾æ•°æ®
- [ ] è¿ç§»æœ‰ä»·å€¼çš„å†å²æ•°æ®
- [ ] éªŒè¯æ–°ç³»ç»Ÿå·¥ä½œæ­£å¸¸

### âœ… æ¸…ç†é˜¶æ®µ
- [ ] åˆ é™¤legacyä»£ç 
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] æ€§èƒ½ä¼˜åŒ–

## ğŸ¯ é¢„æœŸæ•ˆæœ

### å­˜å‚¨ä¼˜åŒ–
- **å½“å‰**: 8ä¸ªäº‹ä»¶ = ~80KB åƒåœ¾æ•°æ®
- **è¿ç§»å**: 2-3ä¸ªæœ‰ä»·å€¼çš„å‘é‡åŒ–æ–‡æ¡£ = ~2KB

### æ€§èƒ½æå‡
- **æ£€ç´¢é€Ÿåº¦**: ä»SQLå…¨è¡¨æ‰«æ â†’ FAISSå‘é‡æ£€ç´¢
- **å­˜å‚¨æˆæœ¬**: 95%+ çš„ç©ºé—´èŠ‚çœ
- **å†…å®¹è´¨é‡**: AIé©±åŠ¨çš„æ™ºèƒ½è¿‡æ»¤

### æ¶æ„æ¸…ç†
- ç§»é™¤äº‹ä»¶å­˜å‚¨çš„æ¦‚å¿µæ··ä¹±
- å»ºç«‹æ¸…æ™°çš„æ•°æ®ç”Ÿå‘½å‘¨æœŸ
- å®ç°çœŸæ­£çš„çŸ¥è¯†ç®¡ç†ç³»ç»Ÿ

---
*è¿ç§»è®¡åˆ’ç‰ˆæœ¬: v1.0*  
*åˆ›å»ºæ—¶é—´: 2025-08-15*  
*é¢„è®¡å®Œæˆ: 2å‘¨*