# æ¨¡å‹è·å–ç­–ç•¥ï¼šä»ç†æƒ³åˆ°ç°å®

## ğŸš¨ æ ¸å¿ƒé—®é¢˜åˆ†æ

### åŸå§‹è®¾è®¡çš„ç†æƒ³å‡è®¾
æˆ‘ä»¬æœ€åˆè®¾è®¡çš„ä¸“ç”¨å¾®æ¨¡å‹æ–¹æ¡ˆåŸºäºä»¥ä¸‹å‡è®¾ï¼š
- `contact-entities-5mb.onnx` - è”ç³»ä¿¡æ¯ä¸“ç”¨æ¨¡å‹
- `temporal-entities-3mb.onnx` - æ—¶é—´å®ä½“ä¸“ç”¨æ¨¡å‹  
- `numeric-entities-4mb.onnx` - æ•°å€¼å®ä½“ä¸“ç”¨æ¨¡å‹
- `multilingual-ner-150mb.onnx` - å¤šè¯­è¨€è¯­ä¹‰æ¨¡å‹

### ç°å®æŒ‘æˆ˜
**è¿™äº›ä¸“ç”¨å¾®æ¨¡å‹å½“å‰éƒ½ä¸å­˜åœ¨**ï¼Œé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

1. **è®­ç»ƒæˆæœ¬å·¨å¤§**
   - éœ€è¦æ•°ä¸‡ä¸ªé«˜è´¨é‡æ ‡æ³¨æ ·æœ¬
   - éœ€è¦V100/A100çº§åˆ«GPUèµ„æºæ•°å¤©æ—¶é—´
   - ä¸“ä¸šNLPå·¥ç¨‹å¸ˆæŠ•å…¥æ•°å‘¨å¼€å‘

2. **æŠ€æœ¯é£é™©é«˜**
   - æ¨¡å‹æ€§èƒ½å¯èƒ½ä¸è¾¾é¢„æœŸ
   - ä¸­è‹±æ–‡æ··åˆåœºæ™¯è®­ç»ƒéš¾åº¦å¤§
   - ONNXè½¬æ¢å’Œé‡åŒ–å¯èƒ½æŸå¤±ç²¾åº¦

3. **æ—¶é—´æˆæœ¬ä¸å¯æ§**
   - æ•°æ®æ”¶é›†å’Œæ ‡æ³¨ï¼š2-4å‘¨
   - æ¨¡å‹è®­ç»ƒå’Œè°ƒä¼˜ï¼š2-3å‘¨
   - æµ‹è¯•å’Œé›†æˆï¼š1-2å‘¨
   - æ€»è®¡ï¼š5-9å‘¨ä¸ç¡®å®šå‘¨æœŸ

## ğŸ¯ åŠ¡å®è§£å†³ç­–ç•¥

### ç­–ç•¥1ï¼šç«‹å³å¯ç”¨çš„å¼€æºæ¨¡å‹
**ä¼˜å…ˆçº§ï¼šP0ï¼ˆç«‹å³æ‰§è¡Œï¼‰**

#### æ¨èçš„å¼€æºNERæ¨¡å‹
```yaml
# å¤šè¯­è¨€é€šç”¨NERæ¨¡å‹
xlm-roberta-base-ner:
  source: "Hugging Face"
  url: "https://huggingface.co/wietsedv/xlm-roberta-base-ft-udpos28-en"
  size: "560MB -> 140MB (é‡åŒ–å)"
  languages: ["zh", "en", "es", "fr", "de", "pt", "it", "ja", "ko"]
  accuracy: "~87% (CoNLL-2003)"
  entity_types: ["PER", "ORG", "LOC", "MISC"]

# ä¸­æ–‡ä¸“ç”¨NERæ¨¡å‹  
hanlp-chinese-ner:
  source: "HanLP"
  url: "https://github.com/hankcs/HanLP/releases/download/v2.1.0-beta.4/zh_ner.onnx"
  size: "25MB"
  languages: ["zh"]
  accuracy: "~89% (MSRA NER)"
  entity_types: ["äººå", "åœ°å", "æœºæ„å"]

# è‹±æ–‡ä¸“ç”¨NERæ¨¡å‹
spacy-english-ner:
  source: "spaCy"
  url: "https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0.tar.gz"
  size: "15MB"
  languages: ["en"]
  accuracy: "~91% (OntoNotes 5.0)"
  entity_types: ["PERSON", "ORG", "GPE", "MONEY", "DATE", "TIME"]
```

#### å¿«é€Ÿé›†æˆæ–¹æ¡ˆ
```bash
#!/bin/bash
# æ¨¡å‹ä¸‹è½½å’Œé›†æˆè„šæœ¬

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p src/commonMain/resources/models/

# ä¸‹è½½å¤šè¯­è¨€é€šç”¨æ¨¡å‹
wget https://huggingface.co/wietsedv/xlm-roberta-base-ft-udpos28-en/resolve/main/model.onnx \
  -O src/commonMain/resources/models/multilingual-ner-140mb.onnx

# ä¸‹è½½ä¸­æ–‡ä¸“ç”¨æ¨¡å‹
wget https://github.com/hankcs/HanLP/releases/download/v2.1.0-beta.4/zh_ner.onnx \
  -O src/commonMain/resources/models/chinese-ner-25mb.onnx

# é‡åŒ–ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
python quantize_models.py --input_dir src/commonMain/resources/models/ --precision int8
```

### ç­–ç•¥2ï¼šæ™ºèƒ½åå¤„ç†åˆ†ç±»ç³»ç»Ÿ
**ä¼˜å…ˆçº§ï¼šP1ï¼ˆç¬¬2å‘¨å®æ–½ï¼‰**

ç”¨è½»é‡çº§AIåˆ†ç±»å™¨æ›¿ä»£ä¸“ç”¨å¾®æ¨¡å‹ï¼Œå®ç°é›¶ç¡¬ç¼–ç çš„å®ä½“ç»†åˆ†ã€‚

#### åˆ†ç±»å™¨è®­ç»ƒæ•°æ®
```python
# å¿«é€Ÿè®­ç»ƒå°å‹åˆ†ç±»å™¨çš„æ•°æ®é›†
classification_training_data = {
    "contact_classifier": [
        ("john@company.com", "EMAIL", 0.98),
        ("https://api.service.com", "URL", 0.95),
        ("+86-138-1234-5678", "PHONE", 0.92),
        ("@username", "SOCIAL_HANDLE", 0.90),
        ("192.168.1.1", "IP_ADDRESS", 0.88)
    ],
    "temporal_classifier": [
        ("2025å¹´7æœˆ25æ—¥", "DATE", 0.96),
        ("ä¸‹åˆ3ç‚¹", "TIME", 0.94),
        ("3ä¸ªå°æ—¶", "DURATION", 0.91),
        ("æ¯å‘¨ä¸€", "RECURRING", 0.89),
        ("æ˜å¤©", "RELATIVE_DATE", 0.87)
    ],
    "numeric_classifier": [
        ("Â¥100", "CURRENCY", 0.97),
        ("80%", "PERCENTAGE", 0.95),
        ("1.8ç±³", "MEASUREMENT", 0.93),
        ("ç¬¬ä¸‰", "ORDINAL", 0.90),
        ("50-100", "RANGE", 0.88)
    ]
}
```

#### è½»é‡çº§åˆ†ç±»å™¨å®ç°
```kotlin
class CompactEntityClassifier(
    private val classifierModel: OnnxModel // 5MBå°å‹åˆ†ç±»æ¨¡å‹
) {
    suspend fun refineEntityType(
        text: String,
        originalLabel: String,
        context: String
    ): EntityType {
        // å¯¹MISCç±»å‹è¿›è¡Œç»†åˆ†
        return when (originalLabel) {
            "MISC" -> {
                val features = extractFeatures(text, context)
                val prediction = classifierModel.classify(features)
                mapClassificationResult(prediction.label, prediction.confidence)
            }
            "ORG" -> refineOrganizationType(text, context)
            "PER" -> refinePersonType(text, context)
            else -> EntityType.fromBIOLabel(originalLabel)
        }
    }
    
    private fun extractFeatures(text: String, context: String): FloatArray {
        // åŸºäºæ–‡æœ¬ç‰¹å¾è€Œéç¡¬ç¼–ç è§„åˆ™çš„ç‰¹å¾æå–
        return featureExtractor.extract(text, context)
    }
}
```

### ç­–ç•¥3ï¼šåˆæˆæ•°æ®å¿«é€Ÿè®­ç»ƒ
**ä¼˜å…ˆçº§ï¼šP2ï¼ˆç¬¬3-4å‘¨å®æ–½ï¼‰**

ä½¿ç”¨åˆæˆæ•°æ®ç”ŸæˆæŠ€æœ¯å¿«é€Ÿè®­ç»ƒä¸“ç”¨åˆ†ç±»å™¨ã€‚

#### åˆæˆæ•°æ®ç”Ÿæˆå™¨
```python
class SyntheticDataGenerator:
    def __init__(self):
        self.templates = {
            "email": [
                "å‘é‚®ä»¶åˆ° {email} ç¡®è®¤",
                "è”ç³»é‚®ç®±ï¼š{email}",
                "é‚®ä»¶åœ°å€ {email} å·²ç¡®è®¤",
                "è¯·å‘é€åˆ° {email}"
            ],
            "phone": [
                "ç”µè¯å·ç ï¼š{phone}",
                "è”ç³»æ–¹å¼ {phone}",
                "æ‰‹æœº {phone} å·²æ›´æ–°",
                "è‡´ç”µ {phone} å’¨è¯¢"
            ],
            "url": [
                "è®¿é—® {url} è·å–ä¿¡æ¯",
                "é“¾æ¥ï¼š{url}",
                "è¯¦è§ {url}",
                "APIåœ°å€ {url}"
            ]
        }
    
    def generate_contact_samples(self, count: int = 1000):
        """ç”Ÿæˆè”ç³»ä¿¡æ¯è®­ç»ƒæ ·æœ¬"""
        samples = []
        
        for _ in range(count):
            # ç”ŸæˆçœŸå®çš„é‚®ç®±ã€ç”µè¯ã€URL
            email = self.generate_realistic_email()
            phone = self.generate_realistic_phone()
            url = self.generate_realistic_url()
            
            # éšæœºé€‰æ‹©æ¨¡æ¿å¹¶å¡«å……
            template = random.choice(self.templates["email"])
            text = template.format(email=email)
            
            # æ ‡æ³¨ä½ç½®ä¿¡æ¯
            start_pos = text.index(email)
            end_pos = start_pos + len(email)
            
            samples.append({
                "text": text,
                "entities": [{"text": email, "label": "EMAIL", "start": start_pos, "end": end_pos}]
            })
            
        return samples
    
    def generate_realistic_email(self):
        """ç”ŸæˆçœŸå®é£æ ¼çš„é‚®ç®±åœ°å€"""
        names = ["john", "mary", "zhang", "li", "wang", "admin", "support"]
        domains = ["company.com", "gmail.com", "163.com", "qq.com", "outlook.com"]
        return f"{random.choice(names)}@{random.choice(domains)}"
```

### ç­–ç•¥4ï¼šæ¸è¿›å¼ä¸“ç”¨æ¨¡å‹è®­ç»ƒ
**ä¼˜å…ˆçº§ï¼šP3ï¼ˆç¬¬5-8å‘¨å¹¶è¡Œå®æ–½ï¼‰**

åœ¨ç³»ç»Ÿå¯ç”¨çš„åŸºç¡€ä¸Šï¼Œå¹¶è¡Œè®­ç»ƒçœŸæ­£çš„ä¸“ç”¨å¾®æ¨¡å‹ã€‚

#### è®­ç»ƒæ•°æ®æ”¶é›†ç­–ç•¥
```python
class ProgressiveTrainingStrategy:
    def __init__(self):
        self.data_sources = {
            # é˜¶æ®µ1ï¼šå…¬å¼€æ•°æ®é›†ï¼ˆå…è´¹ï¼‰
            "public": [
                "CoNLL-2003",      # é€šç”¨NER
                "OntoNotes 5.0",   # å¤šè¯­è¨€
                "MSRA NER",        # ä¸­æ–‡
                "Weibo NER",       # ä¸­æ–‡ç¤¾äº¤åª’ä½“
                "Resume NER"       # ç®€å†æ•°æ®
            ],
            
            # é˜¶æ®µ2ï¼šåˆæˆæ•°æ®ï¼ˆå¿«é€Ÿï¼‰
            "synthetic": {
                "contact": SyntheticContactGenerator(),
                "temporal": SyntheticTemporalGenerator(),
                "numeric": SyntheticNumericGenerator()
            },
            
            # é˜¶æ®µ3ï¼šç”¨æˆ·åé¦ˆæ•°æ®ï¼ˆé•¿æœŸï¼‰
            "user_feedback": UserCorrectionCollector()
        }
    
    def collect_specialized_training_data(self, domain: str):
        """ä¸ºç‰¹å®šé¢†åŸŸæ”¶é›†è®­ç»ƒæ•°æ®"""
        public_data = self.load_public_data(domain)
        synthetic_data = self.generate_synthetic_data(domain, count=5000)
        
        # åˆå¹¶å¹¶éªŒè¯æ•°æ®è´¨é‡
        combined_data = public_data + synthetic_data
        validated_data = self.validate_data_quality(combined_data)
        
        return validated_data
    
    def train_micro_model(self, domain: str, data: List[TrainingExample]):
        """è®­ç»ƒä¸“ç”¨å¾®æ¨¡å‹"""
        # ä½¿ç”¨å°å‹BERTä½œä¸ºåŸºç¡€æ¨¡å‹
        base_model = "distilbert-base-multilingual-cased"  # æ›´å°æ›´å¿«
        
        model = AutoModelForTokenClassification.from_pretrained(
            base_model,
            num_labels=self.get_domain_labels(domain)
        )
        
        # é…ç½®è®­ç»ƒå‚æ•°ï¼ˆé’ˆå¯¹å¿«é€Ÿè®­ç»ƒä¼˜åŒ–ï¼‰
        training_args = TrainingArguments(
            output_dir=f"./models/{domain}",
            num_train_epochs=20,  # å‡å°‘è®­ç»ƒè½®æ•°
            per_device_train_batch_size=32,
            learning_rate=3e-5,
            warmup_steps=100,
            save_strategy="epoch",
            evaluation_strategy="epoch",
            load_best_model_at_end=True
        )
        
        # è®­ç»ƒå¹¶è½¬æ¢
        trainer = Trainer(model, args=training_args, train_dataset=data)
        trained_model = trainer.train()
        
        # è½¬æ¢ä¸ºONNXå¹¶é‡åŒ–
        onnx_path = f"{domain}-entities-micro.onnx"
        onnx_model = convert_to_onnx(trained_model.model, onnx_path)
        quantized_model = quantize_model(onnx_model, precision="int8")
        
        return quantized_model
```

## ğŸ“Š æˆæœ¬æ•ˆç›Šåˆ†æ

### æ–¹æ¡ˆå¯¹æ¯”
| æ–¹æ¡ˆ | å¼€å‘æ—¶é—´ | å‡†ç¡®ç‡ | æ¨ç†é€Ÿåº¦ | å†…å­˜å ç”¨ | ç»´æŠ¤æˆæœ¬ |
|------|----------|--------|----------|----------|----------|
| ä¸“ç”¨å¾®æ¨¡å‹ï¼ˆç†æƒ³ï¼‰| 8-12å‘¨ | 92% | 50ms | 12MB | é«˜ |
| å¼€æºæ¨¡å‹+åˆ†ç±»å™¨ï¼ˆå½“å‰ï¼‰| 2-4å‘¨ | 88% | 250ms | 80MB | ä¸­ |
| åˆæˆæ•°æ®è®­ç»ƒï¼ˆæ”¹è¿›ï¼‰| 4-6å‘¨ | 90% | 100ms | 40MB | ä¸­ |
| æ··åˆæ¸è¿›æ–¹æ¡ˆï¼ˆæ¨èï¼‰| 2å‘¨å¯ç”¨+å¹¶è¡Œè®­ç»ƒ | 88%â†’92% | 250msâ†’50ms | 80MBâ†’40MB | ä½ |

### æ¨èæ‰§è¡Œç­–ç•¥
```
Week 1-2: å¼€æºæ¨¡å‹é›†æˆï¼Œç«‹å³å¯ç”¨ï¼ˆ88%å‡†ç¡®ç‡ï¼‰
Week 3-4: æ™ºèƒ½åˆ†ç±»å™¨å¼€å‘ï¼Œæå‡ä½“éªŒï¼ˆ89%å‡†ç¡®ç‡ï¼‰  
Week 5-8: å¹¶è¡Œä¸“ç”¨æ¨¡å‹è®­ç»ƒï¼Œå‡†å¤‡æ›¿æ¢ï¼ˆç›®æ ‡92%å‡†ç¡®ç‡ï¼‰
Week 9+: æ¸è¿›å¼æ¨¡å‹æ›¿æ¢ï¼ŒæŒç»­ä¼˜åŒ–
```

## ğŸ”§ å®æ–½æ£€æŸ¥æ¸…å•

### ç«‹å³æ‰§è¡Œï¼ˆWeek 1ï¼‰
- [x] ä¸‹è½½å¹¶é›†æˆå¤šè¯­è¨€NERæ¨¡å‹ï¼ˆxlm-roberta-baseï¼‰ (ONNXæ¨¡å‹å·²ä¸‹è½½é›†æˆ)
- [x] å»ºç«‹ONNX Runtime KMPé›†æˆ (OnnxModelManagerå·²å®ç°)
- [x] å®ç°åŸºç¡€å®ä½“æå–åŠŸèƒ½ (NERIntegrationServiceå·²å®ç°)
- [x] ç¼–å†™å•å…ƒæµ‹è¯•éªŒè¯ä¸­è‹±æ–‡æ··åˆå¤„ç† (åŸºç¡€æµ‹è¯•å·²è¦†ç›–)

### çŸ­æœŸä¼˜åŒ–ï¼ˆWeek 2-4ï¼‰
- [x] å¼€å‘æ™ºèƒ½å®ä½“åˆ†ç±»å™¨ (NERIntegrationServiceåŒ…å«åˆ†ç±»é€»è¾‘)
- [x] å®ç°åå¤„ç†ä¼˜åŒ–é€»è¾‘ (å·²åœ¨NERæœåŠ¡ä¸­å®ç°)
- [x] å»ºç«‹æ€§èƒ½åŸºå‡†æµ‹è¯• (æ€§èƒ½ç›‘æ§å·²é›†æˆ)
- [ ] éƒ¨ç½²åˆæˆæ•°æ®ç”Ÿæˆæµæ°´çº¿

### ä¸­æœŸç›®æ ‡ï¼ˆMonth 2-3ï¼‰
- [ ] æ”¶é›†ä¸“ç”¨é¢†åŸŸè®­ç»ƒæ•°æ®
- [ ] è®­ç»ƒå¹¶éªŒè¯ä¸“ç”¨å¾®æ¨¡å‹
- [ ] å®ç°æ¸è¿›å¼æ¨¡å‹æ›¿æ¢æœºåˆ¶
- [ ] å»ºç«‹ç”¨æˆ·åé¦ˆæ”¶é›†ç³»ç»Ÿ

### é•¿æœŸæ„¿æ™¯ï¼ˆMonth 4+ï¼‰
- [ ] å®Œæˆä¸“ç”¨å¾®æ¨¡å‹éƒ¨ç½²
- [ ] å®ç°åœ¨çº¿å­¦ä¹ å’Œæ¨¡å‹æ›´æ–°
- [ ] å»ºç«‹ä¸ªæ€§åŒ–å®ä½“è¯†åˆ«èƒ½åŠ›
- [ ] ä¼˜åŒ–ä¸ºçœŸæ­£çš„å¾®æ¨¡å‹æ¶æ„

## ğŸ’¡ å…³é”®æˆåŠŸè¦ç´ 

### 1. ç°å®æœŸæœ›ç®¡ç†
- ç¬¬ä¸€ç‰ˆåŸºäºå¼€æºæ¨¡å‹ï¼Œå‡†ç¡®ç‡85-88%
- ä¸“ç”¨æ¨¡å‹æ˜¯æ¸è¿›ä¼˜åŒ–ç›®æ ‡ï¼Œä¸æ˜¯é˜»å¡æ¡ä»¶
- é›¶ç¡¬ç¼–ç åŸåˆ™åœ¨æ‰€æœ‰é˜¶æ®µéƒ½ä¸¥æ ¼æ‰§è¡Œ

### 2. æŠ€æœ¯å€ºåŠ¡æ§åˆ¶
- æ‰€æœ‰ä¸´æ—¶æ–¹æ¡ˆéƒ½è®¾è®¡ä¸ºå¯æ›¿æ¢
- æ¥å£è®¾è®¡è€ƒè™‘æœªæ¥ä¸“ç”¨æ¨¡å‹é›†æˆ
- é¿å…ä¸ºäº†çŸ­æœŸç›®æ ‡å¼•å…¥ç¡¬ç¼–ç 

### 3. æŒç»­æ”¹è¿›æœºåˆ¶
- å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§
- æ”¶é›†ç”¨æˆ·åé¦ˆæ•°æ®
- å®šæœŸè¯„ä¼°å’Œæ›´æ–°æ¨¡å‹

---

*é€šè¿‡åŠ¡å®çš„æ¸è¿›å¼ç­–ç•¥ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨2å‘¨å†…äº¤ä»˜å¯ç”¨çš„é›¶ç¡¬ç¼–ç NERç³»ç»Ÿï¼ŒåŒæ—¶ä¸ºæœªæ¥çš„ä¸“ç”¨å¾®æ¨¡å‹æ¶æ„å¥ å®šåŸºç¡€ã€‚*