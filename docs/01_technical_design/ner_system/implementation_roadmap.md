# NERç³»ç»Ÿå®æ–½è·¯çº¿å›¾ v2.0

## ğŸ¯ é›¶ç¡¬ç¼–ç å¾®æ¨¡å‹æ¶æ„å®æ–½åŸåˆ™

1. **é›¶ç¡¬ç¼–ç ** - æ‰€æœ‰è¯†åˆ«é€»è¾‘åŸºäºAIæ¨¡å‹ï¼Œæ— ä¸šåŠ¡è§„åˆ™ç¡¬ç¼–ç 
2. **å¾®æ¨¡å‹ä¼˜å…ˆ** - ä¸“ç”¨è½»é‡çº§æ¨¡å‹å¤„ç†å¸¸è§å®ä½“ï¼Œé€šç”¨æ¨¡å‹å¤„ç†å¤æ‚è¯­ä¹‰
3. **æ€§èƒ½ä¼˜åŒ–** - æ™ºèƒ½æ¨¡å‹è°ƒåº¦ï¼Œé¿å…ä¸å¿…è¦çš„å¤§æ¨¡å‹æ¨ç†
4. **ä¼˜é›…é™çº§** - æ¨¡å‹å¤±è´¥æ—¶çš„åŸºç¡€æ–‡æœ¬åˆ†æå¤‡é€‰æ–¹æ¡ˆ

## ğŸš€ ç°å®å¯è¡Œçš„å®æ–½è·¯å¾„ï¼ˆä¿®æ­£ç‰ˆï¼‰

### âš ï¸ å…³é”®è°ƒæ•´ï¼šæ¨¡å‹è·å–ç°å®åŒ–
é‰´äºä¸“ç”¨å¾®æ¨¡å‹éœ€è¦ä»é›¶è®­ç»ƒï¼Œæˆ‘ä»¬é‡‡ç”¨**æ¸è¿›å¼ç­–ç•¥**ï¼š
1. **é˜¶æ®µ1-2**ï¼šåŸºäºå¼€æºæ¨¡å‹æ„å»ºå¯ç”¨ç³»ç»Ÿ 
2. **é˜¶æ®µ3+**ï¼šå¹¶è¡Œè®­ç»ƒä¸“ç”¨æ¨¡å‹é€æ­¥æ›¿æ¢

### é˜¶æ®µ1ï¼šå¼€æºæ¨¡å‹é›†æˆ (Week 1-2) 
**ç›®æ ‡**: åŸºäºç°æœ‰å¼€æºNERæ¨¡å‹å»ºç«‹å¯ç”¨ç³»ç»Ÿ

#### 1.1 å¼€æºæ¨¡å‹ä¸‹è½½ä¸é›†æˆ
```bash
# ä¸‹è½½ç°æœ‰å¼€æºNERæ¨¡å‹
wget https://huggingface.co/wietsedv/xlm-roberta-base-ft-udpos28-en/resolve/main/model.onnx
wget https://github.com/hankcs/HanLP/releases/download/v2.1.0-beta.4/zh_ner.onnx

# é›†æˆåˆ°KMPé¡¹ç›®èµ„æº
mkdir -p src/commonMain/resources/models/
cp xlm-roberta-base-ft-udpos28-en.onnx src/commonMain/resources/models/multilingual-ner-50mb.onnx
cp zh_ner.onnx src/commonMain/resources/models/chinese-ner-25mb.onnx
```

#### 1.2 KMP ONNXè¿è¡Œæ—¶é›†æˆ
```kotlin
// ç°å®ç‰ˆæœ¬ï¼šæ”¯æŒç°æœ‰æ¨¡å‹çš„ç®¡ç†å™¨
expect class OnnxModelManager {
    suspend fun loadModel(modelPath: String): OnnxModel
    fun releaseModel(modelName: String)
    fun getSupportedModels(): List<ModelInfo>
}

data class ModelInfo(
    val name: String,
    val path: String,
    val sizeBytes: Long,
    val supportedLanguages: Set<String>,
    val entityTypes: Set<String>,
    val expectedAccuracy: Float
)
```

#### 1.2 å¾®æ¨¡å‹æŠ½è±¡æ¥å£
```kotlin
// é›¶ç¡¬ç¼–ç çš„AIå®ä½“æå–å™¨
interface AIEntityExtractor {
    val modelName: String
    val modelSize: Long
    suspend fun extract(text: String): List<ExtractedEntity>
    suspend fun isModelReady(): Boolean
}

// å¾®æ¨¡å‹å®ç°åŸºç±»
abstract class MicroModelExtractor(
    private val modelPath: String,
    private val modelManager: OnnxModelManager
) : AIEntityExtractor {
    
    private val model by lazy { 
        runBlocking { modelManager.loadModel(modelPath) }
    }
    
    override suspend fun extract(text: String): List<ExtractedEntity> {
        return model.predict(text).map { prediction ->
            ExtractedEntity(
                text = prediction.text,
                type = mapPredictionToEntityType(prediction.type),
                confidence = prediction.confidence,
                startOffset = prediction.startOffset,
                endOffset = prediction.endOffset,
                source = modelName
            )
        }
    }
    
    protected abstract fun mapPredictionToEntityType(modelType: String): EntityType
}
```

### é˜¶æ®µ2ï¼šæ™ºèƒ½åå¤„ç†ç³»ç»Ÿ (Week 3-4)
**ç›®æ ‡**: å®ç°é›¶ç¡¬ç¼–ç çš„åå¤„ç†åˆ†ç±»ç³»ç»Ÿï¼ˆæ›¿ä»£ä¸“ç”¨å¾®æ¨¡å‹ï¼‰

#### 2.1 æ™ºèƒ½å®ä½“åˆ†ç±»å™¨ï¼ˆæ›¿ä»£ä¸“ç”¨å¾®æ¨¡å‹ï¼‰
```kotlin
// ä½¿ç”¨è½»é‡çº§AIåˆ†ç±»å™¨è¿›è¡Œåå¤„ç†ï¼Œé¿å…ç¡¬ç¼–ç 
class IntelligentEntityClassifier(
    private val contextAnalyzer: ContextAnalysisModel // 5MBå°å‹åˆ†ç±»æ¨¡å‹
) {
    suspend fun refineEntityType(
        text: String,
        rawLabel: String, 
        context: String
    ): EntityType {
        // é›¶ç¡¬ç¼–ç ï¼šå®Œå…¨åŸºäºAIæ¨¡å‹åˆ†ç±»
        return when (rawLabel) {
            "MISC" -> contextAnalyzer.classifyMiscEntity(text, context)
            "ORG" -> contextAnalyzer.distinguishOrgType(text, context)
            "PER" -> contextAnalyzer.refinePerson(text, context)
            else -> EntityType.fromBIOLabel(rawLabel)
        }
    }
}

class ContextAnalysisModel(
    private val miniClassifier: OnnxModel // è½»é‡çº§åˆ†ç±»æ¨¡å‹
) {
    suspend fun classifyMiscEntity(text: String, context: String): EntityType {
        val features = extractContextFeatures(text, context)
        val prediction = miniClassifier.predict(features)
        
        return when (prediction.label) {
            "CONTACT_INFO" -> inferContactSubtype(text, prediction.confidence)
            "TEMPORAL" -> inferTemporalSubtype(text, prediction.confidence)
            "NUMERIC" -> inferNumericSubtype(text, prediction.confidence)
            "TECHNOLOGY" -> EntityType.TECHNOLOGY
            else -> EntityType.CONCEPT
        }
    }
}
```

#### 2.2 ç°å®ç‰ˆæœ¬çš„NERæœåŠ¡ç»„åˆ
```kotlin
// åŸºäºå¼€æºæ¨¡å‹ + æ™ºèƒ½åå¤„ç†çš„ç°å®æ–¹æ¡ˆ
class PragmaticNERService(
    private val backboneModel: OnnxModel,        // 50MBå¼€æºé€šç”¨æ¨¡å‹
    private val entityClassifier: IntelligentEntityClassifier  // 5MBåˆ†ç±»å™¨
) {
    suspend fun extractEntities(text: String): List<ExtractedEntity> {
        // æ­¥éª¤1ï¼šä½¿ç”¨å¼€æºé€šç”¨æ¨¡å‹è·å–åŸºç¡€è¯†åˆ«ç»“æœ
        val rawEntities = backboneModel.predict(text)
        
        // æ­¥éª¤2ï¼šæ™ºèƒ½åå¤„ç†åˆ†ç±»ï¼ˆæ›¿ä»£ä¸“ç”¨å¾®æ¨¡å‹ï¼‰
        return rawEntities.map { raw ->
            ExtractedEntity(
                text = raw.text,
                type = entityClassifier.refineEntityType(
                    raw.text, 
                    raw.label, 
                    extractContext(text, raw.start, raw.end)
                ),
                confidence = calculateAdjustedConfidence(raw),
                startOffset = raw.start,
                endOffset = raw.end,
                source = "BackboneModel+IntelligentClassifier"
            )
        }
    }
}
```

#### 2.3 ä¼˜é›…é™çº§æœºåˆ¶
```kotlin
// å½“AIæ¨¡å‹ä¸å¯ç”¨æ—¶çš„åŸºç¡€æ–‡æœ¬åˆ†æ
class BasicTextAnalyzer {
    suspend fun extractBasicEntities(text: String): List<ExtractedEntity> {
        // ä½¿ç”¨åŸºç¡€çš„æ–‡æœ¬åˆ†ææŠ€æœ¯ï¼ˆéç¡¬ç¼–ç æ­£åˆ™ï¼‰
        return listOf(
            extractByWordBoundaries(text),
            extractByCapitalization(text),
            extractByFormat(text)  // åŸºäºé€šç”¨æ ¼å¼ç‰¹å¾ï¼Œè€Œéç‰¹å®šæ­£åˆ™
        ).flatten()
    }
    
    private fun extractByFormat(text: String): List<ExtractedEntity> {
        // åŸºäºç»Ÿè®¡ç‰¹å¾è€Œéç¡¬ç¼–ç è§„åˆ™
        return statisticalPatternDetector.findPotentialEntities(text)
    }
}
```
```

### é˜¶æ®µ3ï¼šä¸“ç”¨æ¨¡å‹è®­ç»ƒå¯åŠ¨ (Week 5-8)  
**ç›®æ ‡**: å¹¶è¡Œå¼€å±•ä¸“ç”¨å¾®æ¨¡å‹è®­ç»ƒï¼Œä¸ºæ¸è¿›å¼æ›¿æ¢åšå‡†å¤‡

#### 3.1 è®­ç»ƒæ•°æ®æ”¶é›†ä¸å‡†å¤‡
```python
# ä¸“ç”¨å¾®æ¨¡å‹è®­ç»ƒæ•°æ®æ”¶é›†æµæ°´çº¿
class MicroModelTrainingPipeline:
    def __init__(self):
        self.data_sources = {
            "public_datasets": [
                "CoNLL-2003",      # é€šç”¨NERæ•°æ®
                "OntoNotes 5.0",   # å¤šè¯­è¨€å®ä½“
                "MSRA NER",        # ä¸­æ–‡NERæ•°æ®
                "Weibo NER"        # ä¸­æ–‡ç¤¾äº¤åª’ä½“æ•°æ®
            ],
            "synthetic_generators": {
                "contact": ContactDataGenerator(),
                "temporal": TemporalDataGenerator(),
                "numeric": NumericDataGenerator()
            }
        }
    
    def prepare_contact_training_data(self):
        """ä¸ºè”ç³»ä¿¡æ¯å¾®æ¨¡å‹å‡†å¤‡è®­ç»ƒæ•°æ®"""
        return [
            ("å‘é‚®ä»¶åˆ° john@company.com ç¡®è®¤ä¼šè®®æ—¶é—´", [("john@company.com", "EMAIL", 4, 20)]),
            ("è®¿é—®APIæ¥å£ https://api.service.com/v1/users", [("https://api.service.com/v1/users", "URL", 7, 37)]),
            ("è”ç³»æ‰‹æœºï¼š+86-138-1234-5678", [("+86-138-1234-5678", "PHONE", 5, 21)]),
            ("å…³æ³¨Twitter @username", [("@username", "SOCIAL_HANDLE", 8, 17)])
        ]
        
    def prepare_temporal_training_data(self):
        """ä¸ºæ—¶é—´å®ä½“å¾®æ¨¡å‹å‡†å¤‡è®­ç»ƒæ•°æ®"""
        return [
            ("ä¼šè®®å®šåœ¨2025å¹´7æœˆ25æ—¥ä¸‹åˆ3ç‚¹", [("2025å¹´7æœˆ25æ—¥", "DATE", 4, 15), ("ä¸‹åˆ3ç‚¹", "TIME", 15, 19)]),
            ("ä»»åŠ¡é¢„è®¡éœ€è¦3ä¸ªå·¥ä½œæ—¥å®Œæˆ", [("3ä¸ªå·¥ä½œæ—¥", "DURATION", 5, 9)]),
            ("æ¯å‘¨ä¸€ä¸Šåˆ9ç‚¹ä¾‹ä¼š", [("æ¯å‘¨ä¸€", "RECURRING", 0, 3), ("ä¸Šåˆ9ç‚¹", "TIME", 3, 7)])
        ]
```

#### 3.2 å¾®æ¨¡å‹è®­ç»ƒå®æ–½
```python
# ä¸“ç”¨å¾®æ¨¡å‹è®­ç»ƒè„šæœ¬
class MicroModelTrainer:
    def __init__(self, domain: str):
        self.domain = domain
        self.base_model = "bert-base-multilingual-cased"
        self.training_config = {
            "epochs": 50,
            "batch_size": 16,
            "learning_rate": 2e-5,
            "max_length": 512
        }
    
    def train_contact_model(self, training_data: List[TrainingExample]):
        """è®­ç»ƒè”ç³»ä¿¡æ¯ä¸“ç”¨æ¨¡å‹"""
        model = AutoModelForTokenClassification.from_pretrained(
            self.base_model,
            num_labels=len(CONTACT_LABELS)  # EMAIL, PHONE, URLç­‰
        )
        
        # è®­ç»ƒæ¨¡å‹
        trainer = Trainer(model, training_data, self.training_config)
        trained_model = trainer.train()
        
        # è½¬æ¢ä¸ºONNXå¹¶é‡åŒ–
        onnx_model = convert_to_onnx(trained_model, "contact-entities-5mb.onnx")
        quantized_model = quantize_model(onnx_model, precision="int8")
        
        return quantized_model
    
    def validate_model_performance(self, model, test_data):
        """éªŒè¯æ¨¡å‹æ€§èƒ½æ˜¯å¦è¾¾åˆ°é¢„æœŸ"""
        predictions = model.predict(test_data)
        metrics = calculate_metrics(predictions, test_data.labels)
        
        return {
            "accuracy": metrics.accuracy,
            "precision": metrics.precision,
            "recall": metrics.recall,
            "f1_score": metrics.f1
        }
```

#### 3.3 æ¸è¿›å¼æ¨¡å‹æ›¿æ¢ç­–ç•¥
```kotlin
// æ”¯æŒæ¸è¿›å¼æ¨¡å‹æ›¿æ¢çš„æ¶æ„
class ProgressiveModelManager {
    private val availableModels = mutableMapOf<String, ModelInfo>()
    private val modelPriority = listOf(
        "specialized_micro_models",  // æœ€ä¼˜ï¼šè®­ç»ƒå¥½çš„ä¸“ç”¨å¾®æ¨¡å‹
        "general_with_classifier",   // å½“å‰ï¼šé€šç”¨æ¨¡å‹+åˆ†ç±»å™¨
        "basic_text_analysis"        // å…œåº•ï¼šåŸºç¡€æ–‡æœ¬åˆ†æ
    )
    
    suspend fun getBestAvailableModel(entityDomain: String): NERProcessor {
        return when (entityDomain) {
            "contact" -> tryLoadModel("contact-entities-5mb.onnx") 
                ?: fallbackToGeneralModel()
            "temporal" -> tryLoadModel("temporal-entities-3mb.onnx")
                ?: fallbackToGeneralModel() 
            "numeric" -> tryLoadModel("numeric-entities-4mb.onnx")
                ?: fallbackToGeneralModel()
            else -> fallbackToGeneralModel()
        }
    }
    
    private suspend fun fallbackToGeneralModel(): NERProcessor {
        // é™çº§åˆ°å½“å‰å¯ç”¨çš„é€šç”¨æ¨¡å‹+åˆ†ç±»å™¨æ–¹æ¡ˆ
        return PragmaticNERService(backboneModel, entityClassifier)
    }
}
```

class PriorityAssignmentService {
    fun assignPriority(filePath: String, fileType: String): ProcessingPriority {
        return when {
            filePath.contains("node_modules") -> ProcessingPriority.IGNORE
            filePath.contains("/src/") -> ProcessingPriority.HIGH
            fileType in setOf("md", "kt", "java", "py") -> ProcessingPriority.HIGH
            else -> ProcessingPriority.MEDIUM
        }
    }
}
```

#### 3.2 å®¹é‡æ§åˆ¶ä¸å¢é‡å¤„ç†
```kotlin
class SmartDataProcessor : DataParser {
    private val priorityService = PriorityAssignmentService()
    private val incrementalProcessor = IncrementalProcessor()
    
    override suspend fun parse(data: CollectedData): ParseResult {
        // 1. åˆ†é…ä¼˜å…ˆçº§
        val priority = priorityService.assignPriority(data.sourceInfo.path, data.type.name)
        
        // 2. æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
        if (priority == ProcessingPriority.IGNORE) {
            return ParseResult.skipped()
        }
        
        // 3. å¢é‡å¤„ç†æ£€æŸ¥
        val processResult = incrementalProcessor.processIfChanged(data.sourceInfo.path)
        if (processResult.isSkipped) {
            return ParseResult.fromCache(processResult)
        }
        
        // 4. å®¹é‡æ§åˆ¶å¤„ç†
        return when {
            data.content.length > MAX_FILE_SIZE -> processLargeContent(data)
            priority == ProcessingPriority.HIGH -> processWithFullNER(data)
            else -> processWithBasicExtraction(data)
        }
    }
}
```

#### 3.3 ç”¨æˆ·é…ç½®æœºåˆ¶
```kotlin
data class ProcessingConfig(
    val excludePatterns: List<String> = listOf(
        "**/node_modules/**", "**/build/**", "**/.git/**"
    ),
    val resourceLimits: ResourceLimits = ResourceLimits(
        maxFileSizeMb = 10,
        backgroundThreads = 4
    )
)
```

### é˜¶æ®µ4ï¼šæ™ºèƒ½è°ƒåº¦ä¸æ€§èƒ½ä¼˜åŒ– (Week 7-8)
**ç›®æ ‡**: å®ç°æ™ºèƒ½æ¨¡å‹è°ƒåº¦å’Œæ€§èƒ½ä¼˜åŒ–æœºåˆ¶

#### 4.1 æ ¸å¿ƒå¤šè¯­è¨€æ¨¡å‹ï¼ˆTier 1ï¼‰
```kotlin
class CoreMultilingualProcessor : EntityExtractor {
    private val coreModel by lazy { 
        loadCoreModel("core-multilingual-ner.onnx") 
    }
    
    val supportedLanguages = setOf("zh", "en", "es", "fr", "de", "ja", "ko", "ru")
    
    override suspend fun extract(text: String): List<ExtractedEntity> {
        return coreModel.predict(text)
    }
}
```

#### 4.2 æ™ºèƒ½è¯­è¨€è·¯ç”±ç³»ç»Ÿ
```kotlin
class IntelligentLanguageRouter {
    private val languageDetector = FastLanguageDetector()
    private val coreProcessor = CoreMultilingualProcessor()
    private val specialistProcessors = mutableMapOf<String, SpecialistLanguageProcessor>()
    private val fallbackProcessor = LightweightRuleProcessor()
    
    suspend fun routeAndProcess(text: String): List<ExtractedEntity> {
        val detectedLanguage = languageDetector.detect(text)
        
        return when {
            specialistProcessors.containsKey(detectedLanguage.code) -> 
                specialistProcessors[detectedLanguage.code]!!.extract(text)
            coreProcessor.supportedLanguages.contains(detectedLanguage.code) -> 
                coreProcessor.extract(text)
            else -> {
                notifyLanguagePackAvailable(detectedLanguage.code)
                fallbackProcessor.extract(text)
            }
        }
    }
}
```

#### 4.3 åŠ¨æ€æ¨¡å‹ç®¡ç†
```kotlin
class LanguagePackManager {
    private val modelRegistry = ModelRegistry()
    private val modelCache = ModelCache(maxModelsInMemory = 3)
    
    suspend fun downloadLanguagePack(languageCode: String): DownloadResult {
        val modelInfo = modelRegistry.getModelInfo(languageCode)
        return downloadManager.download(modelInfo)
    }
    
    fun getAvailableLanguages(): List<LanguageInfo> {
        return modelRegistry.listAvailableModels()
    }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. å»¶è¿ŸåŠ è½½
- ONNXæ¨¡å‹ä»…åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½
- è¯å…¸æ–‡ä»¶æŒ‰éœ€åŠ è½½
- æ­£åˆ™è¡¨è¾¾å¼é¢„ç¼–è¯‘ç¼“å­˜

### 2. æ–‡æœ¬é•¿åº¦é™åˆ¶
```kotlin
class TextProcessor {
    fun shouldProcess(text: String): Boolean {
        return text.length < 10000 // è¶…é•¿æ–‡æœ¬è·³è¿‡NER
    }
}
```

### 3. ç®€å•ç¼“å­˜
```kotlin
class SimpleEntityCache {
    private val cache = LinkedHashMap<String, List<ExtractedEntity>>(100, 0.75f, true)
    
    fun get(textHash: String): List<ExtractedEntity>? = cache[textHash]
    fun put(textHash: String, entities: List<ExtractedEntity>) {
        if (cache.size >= 100) cache.remove(cache.keys.first())
        cache[textHash] = entities
    }
}
```

## ğŸ“Š ä¿®æ­£åçš„æˆåŠŸæŒ‡æ ‡

### ç°å®ç‰ˆæœ¬æ€§èƒ½ç›®æ ‡
- **å¤„ç†é€Ÿåº¦**: < 250ms/1000å­—ç¬¦ï¼ˆé€šç”¨æ¨¡å‹+åˆ†ç±»å™¨ï¼‰< 50msï¼ˆæœªæ¥ä¸“ç”¨å¾®æ¨¡å‹ï¼‰
- **å†…å­˜å ç”¨**: < 100MBï¼ˆå½“å‰æ–¹æ¡ˆï¼‰< 300MBï¼ˆå®Œæ•´å¾®æ¨¡å‹æ–¹æ¡ˆï¼‰
- **å¯åŠ¨å»¶è¿Ÿ**: < 5ç§’ï¼ˆå¼€æºæ¨¡å‹åŠ è½½ï¼‰< 3ç§’ï¼ˆé‡åŒ–ä¼˜åŒ–åï¼‰
- **å‡†ç¡®ç‡**: > 85%ï¼ˆé€šç”¨å®ä½“ï¼‰> 88%ï¼ˆåå¤„ç†å¢å¼ºï¼‰> 92%ï¼ˆæœªæ¥ä¸“ç”¨æ¨¡å‹ï¼‰

### ç°å®åŠŸèƒ½ç›®æ ‡
- **é›¶ç¡¬ç¼–ç **: æ‰€æœ‰è¯†åˆ«é€»è¾‘åŸºäºAIæ¨¡å‹ï¼ˆåŒ…æ‹¬åå¤„ç†åˆ†ç±»å™¨ï¼‰
- **æ¸è¿›å¼å‡çº§**: ä»å¼€æºæ¨¡å‹å¹³æ»‘è¿‡æ¸¡åˆ°ä¸“ç”¨å¾®æ¨¡å‹
- **ä¸­è‹±æ··åˆ**: åŸºäºå¤šè¯­è¨€é¢„è®­ç»ƒæ¨¡å‹çš„æ··åˆæ–‡æœ¬å¤„ç†
- **ä¼˜é›…é™çº§**: å¤šå±‚æ¬¡å¤‡é€‰æ–¹æ¡ˆç¡®ä¿ç³»ç»Ÿå¯ç”¨æ€§

## ğŸ¯ ä¸‹ä¸€é˜¶æ®µè®¡åˆ’

### æ€§èƒ½ä¼˜åŒ–é˜¶æ®µ (Month 2)
1. æ‰¹å¤„ç†ä¼˜åŒ–
2. å¼‚æ­¥å¤„ç†
3. æ¨¡å‹é‡åŒ–å’Œä¼˜åŒ–

### åŠŸèƒ½å¢å¼ºé˜¶æ®µ (Month 3)
1. æ›´å¤šå®ä½“ç±»å‹
2. å…³ç³»æŠ½å–
3. ä¸Šä¸‹æ–‡ç†è§£

## ğŸ’¡ å…³é”®åŸåˆ™

1. **å…ˆè·‘èµ·æ¥** - åŸºç¡€åŠŸèƒ½ä¼˜å…ˆï¼Œå®Œç¾ä¸»ä¹‰åç½®
2. **æ€§èƒ½å¯¼å‘** - æ¯ä¸ªå†³ç­–éƒ½è€ƒè™‘æ€§èƒ½å½±å“
3. **ç®€å•ç›´æ¥** - é¿å…è¿‡åº¦æŠ½è±¡å’Œå¤æ‚è®¾è®¡
4. **å¯è§‚æµ‹æ€§** - æ·»åŠ åŸºç¡€ç›‘æ§ï¼Œä¾¿äºä¼˜åŒ–

---

*ä¸“æ³¨äºV0 PoCçš„æ ¸å¿ƒä»·å€¼ï¼šè®©ç³»ç»ŸçœŸæ­£å¯ç”¨ï¼Œä¸ºåç»­è¿­ä»£å¥ å®šåŸºç¡€ã€‚*