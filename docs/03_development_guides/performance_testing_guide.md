# æ€§èƒ½åŸºå‡†ä¸æµ‹è¯•æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜Linch Mindé¡¹ç›®çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ã€è´¨é‡æ§åˆ¶å’ŒæŒç»­é›†æˆæµ‹è¯•æµç¨‹ã€‚

## ğŸ“‹ ç›®å½•

- [æ€§èƒ½åŸºå‡†è¦æ±‚](#æ€§èƒ½åŸºå‡†è¦æ±‚)
- [æµ‹è¯•æ¡†æ¶å’Œå·¥å…·](#æµ‹è¯•æ¡†æ¶å’Œå·¥å…·)
- [è¿è¡Œæµ‹è¯•æŒ‡å—](#è¿è¡Œæµ‹è¯•æŒ‡å—)
- [æ€§èƒ½åŸºå‡†æµ‹è¯•](#æ€§èƒ½åŸºå‡†æµ‹è¯•)
- [ä»£ç è¦†ç›–ç‡è¦æ±‚](#ä»£ç è¦†ç›–ç‡è¦æ±‚)
- [CI/CDé›†æˆ](#cicdé›†æˆ)

## æ€§èƒ½åŸºå‡†è¦æ±‚

### ğŸ¯ æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡

æ ¹æ®é¡¹ç›®çš„æŠ€æœ¯é“å¾‹ï¼Œä»¥ä¸‹æ˜¯å¿…é¡»æ»¡è¶³çš„æ€§èƒ½åŸºå‡†ï¼š

#### IPCé€šä¿¡æ€§èƒ½
- **å»¶è¿Ÿè¦æ±‚**: < 5ms (å¹³å‡å“åº”æ—¶é—´)
- **ååé‡è¦æ±‚**: > 10,000 RPS
- **å¹¶å‘è¿æ¥**: æ”¯æŒ > 1000 å¹¶å‘å®¢æˆ·ç«¯
- **å†…å­˜ä½¿ç”¨**: IPCæœåŠ¡å™¨ < 50MB å³°å€¼å†…å­˜

#### åº”ç”¨å¯åŠ¨æ€§èƒ½
- **å†·å¯åŠ¨æ—¶é—´**: < 3 ç§’ï¼ˆä»å‘½ä»¤æ‰§è¡Œåˆ°æœåŠ¡å°±ç»ªï¼‰
- **çƒ­å¯åŠ¨æ—¶é—´**: < 1 ç§’ï¼ˆdaemonå·²è¿è¡Œï¼Œå¯åŠ¨UIï¼‰
- **ç¯å¢ƒåˆå§‹åŒ–**: < 5 ç§’ï¼ˆé¦–æ¬¡ç¯å¢ƒè®¾ç½®ï¼‰

#### å†…å­˜ä½¿ç”¨é™åˆ¶
- **Daemonå³°å€¼å†…å­˜**: < 500MB
- **UIå³°å€¼å†…å­˜**: < 200MB
- **è¿æ¥å™¨å†…å­˜**: < 50MB per connector

#### æ•°æ®åº“æ€§èƒ½
- **SQLiteæŸ¥è¯¢**: < 10msï¼ˆç®€å•æŸ¥è¯¢ï¼‰
- **æ‰¹é‡æ’å…¥**: > 1000 records/s
- **FAISSå‘é‡æœç´¢**: < 50msï¼ˆ10kå‘é‡ï¼‰
- **NetworkXå›¾æŸ¥è¯¢**: < 100msï¼ˆ1kèŠ‚ç‚¹ï¼‰

## æµ‹è¯•æ¡†æ¶å’Œå·¥å…·

### ğŸ”§ Pythonæµ‹è¯•æ ˆ

```bash
# ä¸»è¦æµ‹è¯•å·¥å…·
pytest ^8.0.0              # æµ‹è¯•æ¡†æ¶
pytest-asyncio ^0.24.0     # å¼‚æ­¥æµ‹è¯•æ”¯æŒ
pytest-cov ^6.0.0          # ä»£ç è¦†ç›–ç‡
pytest-mock ^3.14.0        # Mockæ”¯æŒ
pytest-xdist ^3.6.0        # å¹¶è¡Œæµ‹è¯•

# æ€§èƒ½æµ‹è¯•
pytest-benchmark            # æ€§èƒ½åŸºå‡†æµ‹è¯•
memory-profiler            # å†…å­˜ä½¿ç”¨åˆ†æ
```

### ğŸ“ æµ‹è¯•ç›®å½•ç»“æ„

```
daemon/tests/
â”œâ”€â”€ conftest.py                          # æµ‹è¯•é…ç½®å’Œå›ºä»¶
â”œâ”€â”€ conftest_ipc.py                      # IPCæµ‹è¯•ä¸“ç”¨é…ç½®
â”œâ”€â”€ test_architecture_performance.py     # æ¶æ„æ€§èƒ½æµ‹è¯•
â”œâ”€â”€ test_core_components.py              # æ ¸å¿ƒç»„ä»¶æµ‹è¯•
â”œâ”€â”€ test_ipc_integration.py              # IPCé›†æˆæµ‹è¯•
â”œâ”€â”€ test_ipc_integration_comprehensive.py # å…¨é¢IPCæµ‹è¯•
â”œâ”€â”€ test_database_service_effective.py   # æ•°æ®åº“æœåŠ¡æµ‹è¯•
â”œâ”€â”€ test_connector_manager_effective.py  # è¿æ¥å™¨ç®¡ç†æµ‹è¯•
â”œâ”€â”€ test_storage_integration.py          # å­˜å‚¨é›†æˆæµ‹è¯•
â””â”€â”€ ipc_test_client.py                   # IPCæµ‹è¯•å®¢æˆ·ç«¯
```

### âš™ï¸ æµ‹è¯•é…ç½®ï¼ˆpytest.iniï¼‰

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# æµ‹è¯•é€‰é¡¹
addopts = -v --tb=short --strict-markers --asyncio-mode=auto --cov=core --cov=services/ipc --cov-report=term-missing --cov-fail-under=80

# æµ‹è¯•æ ‡è®°
markers =
    unit: å•å…ƒæµ‹è¯•
    integration: é›†æˆæµ‹è¯•
    slow: è¿è¡Œç¼“æ…¢çš„æµ‹è¯•
    performance: æ€§èƒ½æµ‹è¯•
    database: æ•°æ®åº“ç›¸å…³æµ‹è¯•
    connector: è¿æ¥å™¨ç›¸å…³æµ‹è¯•
```

## è¿è¡Œæµ‹è¯•æŒ‡å—

### ğŸš€ åŸºç¡€æµ‹è¯•å‘½ä»¤

```bash
# è¿›å…¥daemonç›®å½•
cd daemon

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
poetry run pytest

# è¿è¡Œç‰¹å®šç±»å‹çš„æµ‹è¯•
poetry run pytest -m unit          # å•å…ƒæµ‹è¯•
poetry run pytest -m integration   # é›†æˆæµ‹è¯•
poetry run pytest -m performance   # æ€§èƒ½æµ‹è¯•

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
poetry run pytest tests/test_core_components.py

# è¿è¡Œå¹¶è¡Œæµ‹è¯•ï¼ˆåŠ é€Ÿï¼‰
poetry run pytest -n auto

# è¯¦ç»†è¾“å‡º
poetry run pytest -v -s
```

### ğŸ“Š ä»£ç è¦†ç›–ç‡æµ‹è¯•

```bash
# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
poetry run pytest --cov=core --cov=services --cov-report=html

# æŸ¥çœ‹è¯¦ç»†è¦†ç›–ç‡
poetry run pytest --cov=core --cov-report=term-missing

# è®¾ç½®è¦†ç›–ç‡å¤±è´¥é˜ˆå€¼
poetry run pytest --cov-fail-under=80
```

### âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# è¿è¡Œæ¶æ„æ€§èƒ½æµ‹è¯•
poetry run pytest tests/test_architecture_performance.py -v

# è¿è¡ŒIPCæ€§èƒ½æµ‹è¯•
poetry run pytest tests/test_ipc_integration_comprehensive.py::test_ipc_performance -v

# è¿è¡Œå†…å­˜ä½¿ç”¨æµ‹è¯•
poetry run pytest tests/test_architecture_performance.py::test_memory_usage -v

# ä½¿ç”¨åŸºå‡†æµ‹è¯•å·¥å…·
poetry run pytest --benchmark-only tests/
```

## æ€§èƒ½åŸºå‡†æµ‹è¯•

### ğŸ”¥ IPCæ€§èƒ½æµ‹è¯•

```python
# ç¤ºä¾‹ï¼šIPCå»¶è¿Ÿæµ‹è¯•
@pytest.mark.performance
async def test_ipc_latency():
    """æµ‹è¯•IPCå“åº”å»¶è¿Ÿ"""
    client = IPCTestClient()

    # é¢„çƒ­
    for _ in range(10):
        await client.send_request("ping", {})

    # æµ‹é‡å»¶è¿Ÿ
    latencies = []
    for _ in range(1000):
        start_time = time.perf_counter()
        response = await client.send_request("ping", {})
        end_time = time.perf_counter()

        latency_ms = (end_time - start_time) * 1000
        latencies.append(latency_ms)

    # éªŒè¯æ€§èƒ½æŒ‡æ ‡
    avg_latency = statistics.mean(latencies)
    p95_latency = sorted(latencies)[int(len(latencies) * 0.95)]

    assert avg_latency < 5.0, f"å¹³å‡å»¶è¿Ÿ {avg_latency:.2f}ms è¶…è¿‡ 5ms è¦æ±‚"
    assert p95_latency < 10.0, f"P95å»¶è¿Ÿ {p95_latency:.2f}ms è¶…è¿‡ 10ms è¦æ±‚"
```

### ğŸ“ˆ ååé‡æµ‹è¯•

```python
@pytest.mark.performance
async def test_ipc_throughput():
    """æµ‹è¯•IPCååé‡"""
    client = IPCTestClient()

    # å¹¶å‘è¿æ¥æ•°
    concurrent_clients = 100
    requests_per_client = 100

    async def client_worker():
        responses = []
        for _ in range(requests_per_client):
            response = await client.send_request("echo", {"data": "test"})
            responses.append(response)
        return responses

    # æµ‹é‡ååé‡
    start_time = time.perf_counter()

    tasks = [client_worker() for _ in range(concurrent_clients)]
    results = await asyncio.gather(*tasks)

    end_time = time.perf_counter()

    total_requests = concurrent_clients * requests_per_client
    duration = end_time - start_time
    rps = total_requests / duration

    assert rps > 10000, f"ååé‡ {rps:.0f} RPS ä½äº 10,000 RPS è¦æ±‚"
```

### ğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•

```python
@pytest.mark.performance
def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨é™åˆ¶"""
    import psutil
    import os

    process = psutil.Process(os.getpid())

    # åŸºç¡€å†…å­˜ä½¿ç”¨
    baseline_memory = process.memory_info().rss / 1024 / 1024  # MB

    # æ‰§è¡Œå…¸å‹æ“ä½œ
    service_container = get_container()
    database_service = service_container.get(DatabaseService)

    # æ‰§è¡Œä¸€äº›æ•°æ®åº“æ“ä½œ
    for _ in range(1000):
        database_service.get_all_connectors()

    # æµ‹é‡å†…å­˜å¢é•¿
    current_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_growth = current_memory - baseline_memory

    assert current_memory < 500, f"å†…å­˜ä½¿ç”¨ {current_memory:.1f}MB è¶…è¿‡ 500MB é™åˆ¶"
    assert memory_growth < 50, f"å†…å­˜å¢é•¿ {memory_growth:.1f}MB è¿‡å¤§"
```

## ä»£ç è¦†ç›–ç‡è¦æ±‚

### ğŸ“Š è¦†ç›–ç‡ç›®æ ‡

- **æ ¸å¿ƒæ¨¡å—**: â‰¥ 90% (core/*)
- **æœåŠ¡å±‚**: â‰¥ 85% (services/*)
- **IPCç»„ä»¶**: â‰¥ 95% (services/ipc/*)
- **æ•´ä½“é¡¹ç›®**: â‰¥ 80%

### ğŸ¯ è¦†ç›–ç‡åˆ†æ

```bash
# ç”ŸæˆHTMLè¦†ç›–ç‡æŠ¥å‘Š
poetry run pytest --cov=core --cov=services --cov-report=html

# æŸ¥çœ‹å…·ä½“æ–‡ä»¶è¦†ç›–æƒ…å†µ
poetry run pytest --cov=core --cov-report=term-missing

# è¦†ç›–ç‡é…ç½®ç¤ºä¾‹
[coverage:run]
source = .
omit =
    */tests/*
    */test_*
    */__pycache__/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
```

## CI/CDé›†æˆ

### ğŸ”„ è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹

```bash
#!/bin/bash
# scripts/run_tests.sh

set -e

echo "ğŸ§ª è¿è¡ŒLinch Mindæµ‹è¯•å¥—ä»¶"

# ç¯å¢ƒæ£€æŸ¥
echo "ğŸ“‹ æ£€æŸ¥æµ‹è¯•ç¯å¢ƒ..."
poetry install --only=dev

# ä»£ç è´¨é‡æ£€æŸ¥
echo "ğŸ” ä»£ç è´¨é‡æ£€æŸ¥..."
poetry run black --check .
poetry run isort --check .
poetry run flake8 .
poetry run mypy .

# å®‰å…¨æ‰«æ
echo "ğŸ›¡ï¸ å®‰å…¨æ‰«æ..."
poetry run bandit -r . --exclude ./tests
poetry run safety check

# å•å…ƒæµ‹è¯•
echo "ğŸƒ è¿è¡Œå•å…ƒæµ‹è¯•..."
poetry run pytest tests/ -m "unit" --cov=core --cov=services --cov-fail-under=80

# é›†æˆæµ‹è¯•
echo "ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•..."
poetry run pytest tests/ -m "integration" -v

# æ€§èƒ½æµ‹è¯•
echo "âš¡ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."
poetry run pytest tests/ -m "performance" --benchmark-only

echo "âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡"
```

### ğŸ›ï¸ GitHub Actionsé…ç½®

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.13]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install dependencies
      working-directory: ./daemon
      run: |
        poetry install --only=dev

    - name: Run tests
      working-directory: ./daemon
      run: |
        chmod +x ../scripts/run_tests.sh
        ../scripts/run_tests.sh

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./daemon/coverage.xml
```

### ğŸ“ˆ æ€§èƒ½å›å½’æ£€æµ‹

```bash
# æ€§èƒ½åŸºå‡†æ¯”è¾ƒ
poetry run pytest tests/test_architecture_performance.py --benchmark-compare

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
poetry run pytest tests/ --benchmark-json=performance_report.json

# æ€§èƒ½è¶‹åŠ¿åˆ†æ
python scripts/analyze_performance_trends.py
```

## ğŸ› ï¸ æµ‹è¯•æœ€ä½³å®è·µ

### âœ… æµ‹è¯•ç¼–å†™æŒ‡å—

1. **æµ‹è¯•å‘½å**: ä½¿ç”¨æè¿°æ€§çš„æµ‹è¯•åç§°
2. **AAAæ¨¡å¼**: Arrange-Act-Assert
3. **éš”ç¦»æ€§**: æ¯ä¸ªæµ‹è¯•ç‹¬ç«‹è¿è¡Œ
4. **æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–**: ä½¿ç”¨mocké¿å…å¤–éƒ¨ä¾èµ–
5. **æ€§èƒ½æ•æ„Ÿ**: æ ‡è®°æ€§èƒ½æµ‹è¯•å¹¶è®¾ç½®åˆç†é˜ˆå€¼

### ğŸ—ï¸ æµ‹è¯•å›ºä»¶ç¤ºä¾‹

```python
# conftest.py
import pytest
import tempfile
from core.container import ServiceContainer

@pytest.fixture
def temp_database():
    """ä¸´æ—¶æ•°æ®åº“å›ºä»¶"""
    with tempfile.NamedTemporaryFile(suffix='.db', delete=True) as tmp:
        yield tmp.name

@pytest.fixture
async def ipc_server():
    """IPCæœåŠ¡å™¨æµ‹è¯•å›ºä»¶"""
    from services.ipc import UnifiedIPCServer

    server = UnifiedIPCServer()
    await server.start()

    yield server

    await server.stop()

@pytest.fixture
def mock_services():
    """æ¨¡æ‹ŸæœåŠ¡å›ºä»¶"""
    container = ServiceContainer()

    # æ³¨å†Œæ¨¡æ‹ŸæœåŠ¡
    mock_db = Mock()
    container.register_singleton(DatabaseService, lambda: mock_db)

    yield container

    container.clear()
```

### ğŸ“ æµ‹è¯•æŠ¥å‘Š

```bash
# ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š
poetry run pytest --html=test_report.html --self-contained-html

# æ€§èƒ½åŸºå‡†æŠ¥å‘Š
poetry run pytest --benchmark-histogram=benchmark_histogram

# è¦†ç›–ç‡å¾½ç« ç”Ÿæˆ
coverage-badge -o coverage.svg
```

---

*è¯¥æµ‹è¯•æŒ‡å—ç¡®ä¿Linch Mindé¡¹ç›®åœ¨æ‰€æœ‰å¼€å‘é˜¶æ®µéƒ½ä¿æŒé«˜è´¨é‡æ ‡å‡†å’Œæ€§èƒ½è¦æ±‚ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹ç¡®ä¿æ¶æ„é“å¾‹çš„ä¸¥æ ¼æ‰§è¡Œã€‚*
