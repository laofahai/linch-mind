# Linch Mind Daemon - é¢„å‘å¸ƒç¯å¢ƒé…ç½®
# é¢„å‘å¸ƒç¯å¢ƒï¼šæ¥è¿‘ç”Ÿäº§é…ç½®ï¼Œç”¨äºæœ€ç»ˆæµ‹è¯•éªŒè¯

[environment]
name = "staging"

[server]
debug = true                # é¢„å‘å¸ƒä¿ç•™è°ƒè¯•ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥
log_level = "INFO"          # æ ‡å‡†æ—¥å¿—çº§åˆ«

[server.ipc]
socket_path = "~/.linch-mind/staging/daemon.socket"  # é¢„å‘å¸ƒç¯å¢ƒSocketè·¯å¾„
timeout = 30                # IPCè¶…æ—¶æ—¶é—´(ç§’) - é€‚ä¸­è®¾ç½®
buffer_size = 8192          # æ ‡å‡†ç¼“å†²åŒºå¤§å°

[database]
use_encryption = true       # ğŸ”’ é¢„å‘å¸ƒç¯å¢ƒå¯ç”¨åŠ å¯†æµ‹è¯•
backup_enabled = true       # å¯ç”¨å¤‡ä»½åŠŸèƒ½æµ‹è¯•
backup_interval_hours = 6   # 6å°æ—¶å¤‡ä»½é—´éš”
connection_pool_size = 10   # ä¸­ç­‰è¿æ¥æ± é…ç½®
query_timeout = 15          # é€‚ä¸­çš„æŸ¥è¯¢è¶…æ—¶

[ai]
default_embedding_model = "all-MiniLM-L6-v2"  # ä¸ç”Ÿäº§ç¯å¢ƒä¸€è‡´
cache_embeddings = true     # å¯ç”¨ç¼“å­˜

[ai.providers.openai]
enabled = true              # OpenAI provider
api_key_env = "OPENAI_API_KEY"  # ç¯å¢ƒå˜é‡è¯»å–
model = "gpt-3.5-turbo"     # é¢„å‘å¸ƒç¯å¢ƒä½¿ç”¨ä¸­çº§æ¨¡å‹
max_tokens = 2000           # ä¸­ç­‰tokené™åˆ¶

[storage]
vector_dimension = 384      # å‘é‡ç»´åº¦
vector_index_type = "faiss" # FAISSå‘é‡ç´¢å¼•
vector_max_workers = 4      # ä¸­ç­‰å¹¶å‘worker
enable_backup = true        # æµ‹è¯•å‘é‡å¤‡ä»½åŠŸèƒ½
backup_interval_hours = 12  # 12å°æ—¶å¤‡ä»½é—´éš”

[connector]
health_check_interval = 30  # 30ç§’æ£€æŸ¥é—´éš” - é€‚ä¸­ç›‘æ§
auto_restart_failed = true  # è‡ªåŠ¨é‡å¯æµ‹è¯•
max_restart_attempts = 5    # é€‚ä¸­é‡è¯•æ¬¡æ•°
startup_delay = 2           # è¾ƒçŸ­å¯åŠ¨å»¶è¿Ÿ
