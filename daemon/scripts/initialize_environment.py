#!/usr/bin/env python3
"""
Environment Initialization System - æ™ºèƒ½ç¯å¢ƒåˆå§‹åŒ–
è‡ªåŠ¨åŒ–ç¯å¢ƒè®¾ç½®ï¼šç›®å½•ã€æ•°æ®åº“ã€æ¨¡å‹ã€è¿æ¥å™¨

æ ¸å¿ƒåŠŸèƒ½:
- ç¯å¢ƒæ„ŸçŸ¥çš„åˆå§‹åŒ–æµç¨‹
- æ•°æ®åº“Schemaè‡ªåŠ¨åˆ›å»ºå’Œè¿ç§»
- æ¨¡å‹æ–‡ä»¶ä¸‹è½½å’Œé…ç½®
- è¿æ¥å™¨è‡ªåŠ¨æ³¨å†Œå’Œé…ç½®
- å¥åº·æ£€æŸ¥å’ŒéªŒè¯
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# æ·»åŠ daemonç›®å½•åˆ°Pythonè·¯å¾„
daemon_dir = Path(__file__).parent.parent
sys.path.insert(0, str(daemon_dir))

from config.core_config import get_core_config
from core.container import get_container
from core.environment_manager import get_environment_manager
from core.service_facade import get_service, reset_service_facade

logger = logging.getLogger(__name__)


class EnvironmentInitializer:
    """ç¯å¢ƒåˆå§‹åŒ–å™¨ - æ™ºèƒ½è‡ªåŠ¨åŒ–è®¾ç½®"""

    def __init__(self):
        self.env_manager = get_environment_manager()
        self.config_manager = get_core_config()
        self.initialization_steps: List[Dict[str, Any]] = []

        logger.info(
            f"Environment Initializer - Target: {self.env_manager.current_environment.value}"
        )

    async def initialize_current_environment(
        self,
        force_reinit: bool = False,
        skip_models: bool = False,
        skip_connectors: bool = False,
    ) -> bool:
        """åˆå§‹åŒ–å½“å‰ç¯å¢ƒ

        Args:
            force_reinit: å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
            skip_models: è·³è¿‡æ¨¡å‹ä¸‹è½½
            skip_connectors: è·³è¿‡è¿æ¥å™¨è®¾ç½®

        Returns:
            æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        """
        try:
            logger.info("=" * 60)
            logger.info(f"å¼€å§‹åˆå§‹åŒ–ç¯å¢ƒ: {self.env_manager.current_environment.value}")
            logger.info("=" * 60)

            # æ­¥éª¤1: éªŒè¯ç›®å½•ç»“æ„
            await self._ensure_directory_structure()

            # æ­¥éª¤2: åˆå§‹åŒ–æ•°æ®åº“
            await self._initialize_database(force_reinit)

            # æ­¥éª¤2.5: åˆå§‹åŒ–Universal IndexæœåŠ¡
            await self._initialize_universal_index()

            # æ­¥éª¤2.6: éªŒè¯AIå…³è”æœåŠ¡é…ç½®
            await self._validate_ai_correlation_config()

            # æ­¥éª¤3: è®¾ç½®æ¨¡å‹æ–‡ä»¶ (å¯é€‰)
            if not skip_models:
                await self._setup_models()

            # æ­¥éª¤4: é…ç½®è¿æ¥å™¨ (å¯é€‰)
            if not skip_connectors:
                await self._setup_connectors()

            # æ­¥éª¤5: è¿è¡Œå¥åº·æ£€æŸ¥
            health_ok = await self._run_health_checks()

            # æ­¥éª¤6: ç”Ÿæˆåˆå§‹åŒ–æŠ¥å‘Š
            await self._generate_initialization_report()

            if health_ok:
                logger.info("âœ… ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸå®Œæˆ")
                return True
            else:
                logger.warning("âš ï¸  ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œä½†å­˜åœ¨ä¸€äº›é—®é¢˜")
                return False

        except Exception as e:
            logger.error(f"âŒ ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback

            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False

    async def _ensure_directory_structure(self):
        """ç¡®ä¿ç›®å½•ç»“æ„å®Œæ•´"""
        logger.info("ğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„...")

        config = self.env_manager.current_config
        required_dirs = [
            ("åŸºç¡€ç›®å½•", config.base_path),
            ("é…ç½®ç›®å½•", config.config_dir),
            ("æ•°æ®ç›®å½•", config.data_dir),
            ("æ—¥å¿—ç›®å½•", config.logs_dir),
            ("ç¼“å­˜ç›®å½•", config.cache_dir),
            ("å‘é‡ç›®å½•", config.vectors_dir),
            ("æ•°æ®åº“ç›®å½•", config.database_dir),
        ]

        created_dirs = []
        for name, path in required_dirs:
            if not path.exists():
                path.mkdir(parents=True, exist_ok=True)
                created_dirs.append((name, str(path)))
                logger.info(f"  âœ… åˆ›å»º {name}: {path}")
            else:
                logger.debug(f"  ğŸ“ {name} å·²å­˜åœ¨: {path}")

        # å…±äº«æ¨¡å‹ç›®å½•
        shared_models = self.env_manager.get_shared_models_directory()
        if not shared_models.exists():
            shared_models.mkdir(parents=True, exist_ok=True)
            created_dirs.append(("å…±äº«æ¨¡å‹ç›®å½•", str(shared_models)))
            logger.info(f"  âœ… åˆ›å»ºå…±äº«æ¨¡å‹ç›®å½•: {shared_models}")

        self.initialization_steps.append(
            {
                "step": "directory_structure",
                "status": "completed",
                "created_directories": created_dirs,
            }
        )

        logger.info(f"ğŸ“ ç›®å½•ç»“æ„æ£€æŸ¥å®Œæˆ - åˆ›å»ºäº† {len(created_dirs)} ä¸ªç›®å½•")

    async def _initialize_database(self, force_reinit: bool = False):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        logger.info("ğŸ—„ï¸  åˆå§‹åŒ–æ•°æ®åº“...")

        try:
            # è·å–æ•°æ®åº“æœåŠ¡ (é€šè¿‡DIå®¹å™¨)
            from services.unified_database_service import UnifiedDatabaseService as DatabaseService

            container = get_container()

            # æ³¨å†Œæ•°æ®åº“æœåŠ¡ (å¦‚æœå°šæœªæ³¨å†Œ)
            if not container.is_registered(DatabaseService):

                def create_database_service():
                    return DatabaseService()

                container.register_singleton(DatabaseService, create_database_service)

            db_service = container.get_service(DatabaseService)

            # è·å–æ•°æ®åº“ä¿¡æ¯
            db_info = db_service.get_environment_database_info()
            logger.info(f"æ•°æ®åº“URL: {db_info['database_url']}")
            logger.info(f"åŠ å¯†: {db_info['use_encryption']}")

            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
            db_exists = db_info.get("database_exists", True)

            if (
                force_reinit
                and db_exists
                and not db_info["database_url"].endswith(":memory:")
            ):
                logger.warning("ğŸ”„ å¼ºåˆ¶é‡æ–°åˆå§‹åŒ– - åˆ é™¤ç°æœ‰æ•°æ®åº“")
                db_file_path = db_info["database_url"].replace("sqlite:///", "")
                if os.path.exists(db_file_path):
                    os.remove(db_file_path)
                    logger.info("  âœ… ç°æœ‰æ•°æ®åº“å·²åˆ é™¤")

            # åˆå§‹åŒ–æ•°æ®åº“Schema
            await db_service.initialize()

            # éªŒè¯æ•°æ®åº“
            stats = db_service.get_database_stats()
            logger.info(
                f"  âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ - è¿æ¥å™¨è¡¨: {stats.get('connectors_count', 0)} æ¡è®°å½•"
            )

            self.initialization_steps.append(
                {
                    "step": "database_initialization",
                    "status": "completed",
                    "database_info": db_info,
                    "stats": stats,
                }
            )

        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialization_steps.append(
                {"step": "database_initialization", "status": "failed", "error": str(e)}
            )
            raise

    async def _initialize_universal_index(self):
        """åˆå§‹åŒ–Universal IndexæœåŠ¡"""
        logger.info("ğŸ” åˆå§‹åŒ–Universal IndexæœåŠ¡...")

        try:
            from services.storage.universal_index_service import UniversalIndexService

            container = get_container()

            # æ³¨å†ŒUniversal IndexæœåŠ¡ (å¦‚æœå°šæœªæ³¨å†Œ)
            if not container.is_registered(UniversalIndexService):
                def create_universal_index_service():
                    return UniversalIndexService()
                container.register_singleton(UniversalIndexService, create_universal_index_service)

            # è·å–å¹¶åˆå§‹åŒ–æœåŠ¡
            universal_index = container.get_service(UniversalIndexService)
            
            # åˆå§‹åŒ–æœåŠ¡ (åˆ›å»ºæ•°æ®åº“å’Œè¡¨ç»“æ„)
            success = universal_index.initialize()
            
            if success:
                logger.info("  âœ… Universal IndexæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
                
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                stats = universal_index.get_statistics()
                logger.info(f"  ğŸ“Š ç´¢å¼•ç»Ÿè®¡: {stats.get('total_items', 0)} é¡¹")
                
                self.initialization_steps.append({
                    "step": "universal_index_initialization",
                    "status": "completed",
                    "stats": stats
                })
            else:
                raise Exception("Universal IndexæœåŠ¡åˆå§‹åŒ–å¤±è´¥")

        except Exception as e:
            logger.error(f"Universal Indexåˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialization_steps.append({
                "step": "universal_index_initialization", 
                "status": "failed", 
                "error": str(e)
            })
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼ŒUniversal Indexå¤±è´¥ä¸åº”é˜»æ­¢æ•´ä¸ªåˆå§‹åŒ–
            logger.warning("Universal Indexåˆå§‹åŒ–å¤±è´¥ï¼Œä½†ç»§ç»­å…¶ä»–åˆå§‹åŒ–æ­¥éª¤")
    
    async def _validate_ai_correlation_config(self):
        """éªŒè¯AIå…³è”æœåŠ¡é…ç½® - ç¡®ä¿AIé©±åŠ¨çš„äº‹ä»¶åˆ†æå¯ç”¨"""
        logger.info("ğŸ¤– éªŒè¯AIå…³è”æœåŠ¡é…ç½®...")
        
        try:
            # éªŒè¯Ollamaé…ç½®
            from config.database_config_manager import get_unified_config
            config = get_unified_config()
            
            if config and hasattr(config, 'ollama') and config.ollama:
                ollama_config = config.ollama
                logger.info(f"  âœ… Ollamaé…ç½®å·²æ‰¾åˆ°: {ollama_config.host}")
                logger.info(f"  ğŸ“ AIæ¨¡å‹: {ollama_config.llm_model}")
                
                # éªŒè¯AIå…³è”å™¨æœåŠ¡
                correlator_status = "unknown"
                buffer_size = 0
                try:
                    from services.event_correlation.ai_driven_correlator import get_ai_correlator
                    correlator = get_ai_correlator()
                    buffer_size = correlator.max_buffer_size
                    logger.info("  ğŸ”— AIé©±åŠ¨å…³è”å™¨åˆå§‹åŒ–æˆåŠŸ")
                    logger.info(f"  ğŸ“Š äº‹ä»¶ç¼“å†²åŒºå®¹é‡: {buffer_size}")
                    correlator_status = "ready"
                    
                    # éªŒè¯AIæœåŠ¡è¿é€šæ€§
                    try:
                        import aiohttp
                        async with aiohttp.ClientSession() as session:
                            async with session.get(f"{ollama_config.host}/api/tags", timeout=aiohttp.ClientTimeout(total=5)) as response:
                                if response.status == 200:
                                    logger.info("  ğŸŒ OllamaæœåŠ¡è¿é€šæ€§: âœ… æ­£å¸¸")
                                else:
                                    logger.warning(f"  ğŸŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status}")
                    except Exception as conn_e:
                        logger.warning(f"  ğŸŒ OllamaæœåŠ¡è¿é€šæ€§æ£€æŸ¥å¤±è´¥: {conn_e}")
                        
                except Exception as e:
                    logger.warning(f"  âš ï¸ AIå…³è”å™¨åˆå§‹åŒ–è­¦å‘Š: {e}")
                    correlator_status = "error"
                
                self.initialization_steps.append({
                    "step": "ai_correlation_config",
                    "status": "completed",
                    "ollama_host": ollama_config.host,
                    "ai_model": ollama_config.llm_model,
                    "ai_driven": True,
                    "correlator_status": correlator_status,
                    "buffer_capacity": buffer_size,
                    "features": [
                        "semantic_analysis",
                        "pattern_discovery", 
                        "behavior_insights",
                        "learning_feedback",
                        "conversational_ai"
                    ]
                })
            else:
                logger.warning("  âš ï¸ Ollamaé…ç½®æœªæ‰¾åˆ°ï¼ŒAIå…³è”åŠŸèƒ½å°†ä½¿ç”¨é™çº§æ¨¡å¼")
                self.initialization_steps.append({
                    "step": "ai_correlation_config",
                    "status": "warning",
                    "ai_driven": False,
                    "fallback_mode": True
                })
            
        except Exception as e:
            logger.error(f"AIå…³è”é…ç½®éªŒè¯å¤±è´¥: {e}")
            self.initialization_steps.append({
                "step": "ai_correlation_config", 
                "status": "failed", 
                "error": str(e)
            })
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé…ç½®å¤±è´¥ä¸åº”é˜»æ­¢æ•´ä¸ªåˆå§‹åŒ–
            logger.warning("AIå…³è”é…ç½®éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­å…¶ä»–åˆå§‹åŒ–æ­¥éª¤")

    async def _setup_models(self):
        """è®¾ç½®AIæ¨¡å‹æ–‡ä»¶"""
        logger.info("ğŸ¤– è®¾ç½®AIæ¨¡å‹...")

        try:
            from config.core_config import get_ai_config

            ai_config = get_ai_config()
            shared_models_dir = self.env_manager.get_shared_models_directory()

            # æ£€æŸ¥é»˜è®¤åµŒå…¥æ¨¡å‹
            default_model = ai_config.default_embedding_model
            logger.info(f"é»˜è®¤åµŒå…¥æ¨¡å‹: {default_model}")

            # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹ä¸‹è½½é€»è¾‘
            # æš‚æ—¶åªè®°å½•æ¨¡å‹é…ç½®
            model_info = {
                "default_embedding_model": default_model,
                "models_directory": str(shared_models_dir),
                "model_providers": len(ai_config.providers),
            }

            self.initialization_steps.append(
                {"step": "model_setup", "status": "completed", "model_info": model_info}
            )

            logger.info("ğŸ¤– AIæ¨¡å‹è®¾ç½®å®Œæˆ")

        except Exception as e:
            logger.error(f"æ¨¡å‹è®¾ç½®å¤±è´¥: {e}")
            self.initialization_steps.append(
                {"step": "model_setup", "status": "failed", "error": str(e)}
            )

    async def _setup_connectors(self):
        """è®¾ç½®è¿æ¥å™¨åŸºç¡€ç¯å¢ƒ"""
        logger.info("ğŸ”Œ è®¾ç½®è¿æ¥å™¨åŸºç¡€ç¯å¢ƒ...")

        try:
            # ä»…éªŒè¯è¿æ¥å™¨ç›®å½•å­˜åœ¨ï¼Œä¸æ³¨å†ŒæœåŠ¡
            project_root = Path(__file__).parent.parent.parent
            connectors_dir = project_root / "connectors"
            
            if not connectors_dir.exists():
                logger.warning(f"è¿æ¥å™¨ç›®å½•ä¸å­˜åœ¨: {connectors_dir}")
            
            # æ£€æŸ¥å®˜æ–¹è¿æ¥å™¨ç›®å½•
            official_dir = connectors_dir / "official"
            if official_dir.exists():
                official_connectors = list(official_dir.glob("*/"))
                logger.info(f"  ğŸ“¦ å‘ç° {len(official_connectors)} ä¸ªå®˜æ–¹è¿æ¥å™¨ç›®å½•")
            else:
                logger.info("  ğŸ“¦ å®˜æ–¹è¿æ¥å™¨ç›®å½•ä¸å­˜åœ¨")

            self.initialization_steps.append({
                "step": "connector_setup",
                "status": "completed", 
                "message": "è¿æ¥å™¨åŸºç¡€ç¯å¢ƒéªŒè¯å®Œæˆ"
            })

            logger.info("ğŸ”Œ è¿æ¥å™¨åŸºç¡€ç¯å¢ƒè®¾ç½®å®Œæˆ")

        except Exception as e:
            logger.error(f"è¿æ¥å™¨ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            self.initialization_steps.append(
                {"step": "connector_setup", "status": "failed", "error": str(e)}
            )

    async def _auto_discover_connectors(self, connector_manager):
        """è‡ªåŠ¨å‘ç°é¡¹ç›®ä¸­çš„è¿æ¥å™¨"""
        from config.core_config import get_connector_config

        connector_config = get_connector_config()
        connectors_dir = Path(connector_config.config_dir)

        if not connectors_dir.exists():
            logger.warning(f"è¿æ¥å™¨ç›®å½•ä¸å­˜åœ¨: {connectors_dir}")
            return

        # æŸ¥æ‰¾å®˜æ–¹è¿æ¥å™¨
        official_dir = connectors_dir / "official"
        if official_dir.exists():
            for connector_path in official_dir.iterdir():
                if connector_path.is_dir():
                    connector_toml = connector_path / "connector.toml"
                    if connector_toml.exists():
                        try:
                            await self._register_connector(
                                connector_manager, connector_toml
                            )
                        except Exception as e:
                            logger.warning(f"æ³¨å†Œè¿æ¥å™¨å¤±è´¥ {connector_path.name}: {e}")

    async def _register_connector(self, connector_manager, connector_toml_path: Path):
        """æ³¨å†Œå•ä¸ªè¿æ¥å™¨"""
        import tomllib

        with open(connector_toml_path, "rb") as f:
            connector_info = tomllib.load(f)

        # åŸºç¡€è¿æ¥å™¨ä¿¡æ¯
        connector_data = {
            "connector_id": connector_info.get("id", connector_toml_path.parent.name),
            "name": connector_info.get("name", "æœªçŸ¥è¿æ¥å™¨"),
            "version": connector_info.get("version", "1.0.0"),
            "description": connector_info.get("description", ""),
            "executable_path": str(
                connector_toml_path.parent
                / "bin"
                / "release"
                / connector_info.get(
                    "executable", f"linch-mind-{connector_json_path.parent.name}"
                )
            ),
            "config_schema": connector_info.get("config_schema", {}),
            "metadata": connector_info,
        }

        # æ£€æŸ¥å¯æ‰§è¡Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(connector_data["executable_path"]).exists():
            logger.warning(
                f"è¿æ¥å™¨å¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {connector_data['executable_path']}"
            )
            return

        # æ³¨å†Œè¿æ¥å™¨
        success = connector_manager.register_connector(connector_data)
        if success:
            logger.info(f"  âœ… æ³¨å†Œè¿æ¥å™¨: {connector_data['name']}")
        else:
            logger.warning(f"  âŒ æ³¨å†Œè¿æ¥å™¨å¤±è´¥: {connector_data['name']}")

    async def _run_health_checks(self) -> bool:
        """è¿è¡Œå¥åº·æ£€æŸ¥"""
        logger.info("ğŸ¥ è¿è¡Œå¥åº·æ£€æŸ¥...")

        checks_passed = 0
        total_checks = 0
        health_results = []

        try:
            # æ£€æŸ¥1: ç›®å½•ç»“æ„
            total_checks += 1
            config = self.env_manager.current_config
            dirs_ok = all(
                d.exists()
                for d in [
                    config.base_path,
                    config.config_dir,
                    config.data_dir,
                    config.logs_dir,
                    config.cache_dir,
                    config.vectors_dir,
                    config.database_dir,
                ]
            )

            if dirs_ok:
                checks_passed += 1
                health_results.append(("ç›®å½•ç»“æ„", "âœ…", "æ‰€æœ‰ç›®å½•å­˜åœ¨"))
            else:
                health_results.append(("ç›®å½•ç»“æ„", "âŒ", "éƒ¨åˆ†ç›®å½•ç¼ºå¤±"))

            # æ£€æŸ¥2: æ•°æ®åº“è¿æ¥
            total_checks += 1
            try:
                from services.unified_database_service import UnifiedDatabaseService as DatabaseService

                db_service = get_service(DatabaseService)
                stats = db_service.get_database_stats()
                checks_passed += 1
                health_results.append(
                    (
                        "æ•°æ®åº“è¿æ¥",
                        "âœ…",
                        f"è¿æ¥æ­£å¸¸ - {stats.get('connectors_count', 0)} ä¸ªè¿æ¥å™¨",
                    )
                )
            except Exception as e:
                health_results.append(("æ•°æ®åº“è¿æ¥", "âŒ", f"è¿æ¥å¤±è´¥: {e}"))

            # æ£€æŸ¥3: ç¯å¢ƒé…ç½®
            total_checks += 1
            env_summary = self.env_manager.get_environment_summary()
            if env_summary:
                checks_passed += 1
                health_results.append(
                    ("ç¯å¢ƒé…ç½®", "âœ…", f"ç¯å¢ƒ: {env_summary['current_environment']}")
                )
            else:
                health_results.append(("ç¯å¢ƒé…ç½®", "âŒ", "ç¯å¢ƒé…ç½®å¼‚å¸¸"))

            # å¥åº·æ£€æŸ¥æŠ¥å‘Š
            logger.info(f"ğŸ¥ å¥åº·æ£€æŸ¥å®Œæˆ: {checks_passed}/{total_checks} é¡¹é€šè¿‡")
            for name, status, details in health_results:
                logger.info(f"  {status} {name}: {details}")

            self.initialization_steps.append(
                {
                    "step": "health_checks",
                    "status": "completed",
                    "checks_passed": checks_passed,
                    "total_checks": total_checks,
                    "results": health_results,
                }
            )

            return checks_passed == total_checks

        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            self.initialization_steps.append(
                {"step": "health_checks", "status": "failed", "error": str(e)}
            )
            return False

    async def _generate_initialization_report(self):
        """ç”Ÿæˆåˆå§‹åŒ–æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆåˆå§‹åŒ–æŠ¥å‘Š...")

        try:
            config = self.env_manager.current_config
            report_path = (
                config.logs_dir
                / f"initialization-{self.env_manager.current_environment.value}.json"
            )

            report = {
                "environment": self.env_manager.current_environment.value,
                "initialized_at": str(datetime.now()),
                "initialization_steps": self.initialization_steps,
                "environment_summary": self.env_manager.get_environment_summary(),
                "config_info": self.config_manager.get_environment_info(),
            }

            import json

            # ä¿å­˜æŠ¥å‘Š
            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"ğŸ“Š åˆå§‹åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

            # æ˜¾ç¤ºæ‘˜è¦
            successful_steps = [
                s for s in self.initialization_steps if s["status"] == "completed"
            ]
            failed_steps = [
                s for s in self.initialization_steps if s["status"] == "failed"
            ]

            logger.info("åˆå§‹åŒ–æ‘˜è¦:")
            logger.info(f"  âœ… æˆåŠŸæ­¥éª¤: {len(successful_steps)}")
            logger.info(f"  âŒ å¤±è´¥æ­¥éª¤: {len(failed_steps)}")

            if failed_steps:
                logger.warning("å¤±è´¥æ­¥éª¤:")
                for step in failed_steps:
                    logger.warning(
                        f"  - {step['step']}: {step.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    )

        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆå§‹åŒ–æŠ¥å‘Šå¤±è´¥: {e}")


async def initialize_environment(
    env_name: Optional[str] = None,
    force_reinit: bool = False,
    skip_models: bool = False,
    skip_connectors: bool = False,
) -> bool:
    """åˆå§‹åŒ–æŒ‡å®šç¯å¢ƒ

    Args:
        env_name: ç¯å¢ƒåç§°ï¼ŒNoneè¡¨ç¤ºå½“å‰ç¯å¢ƒ
        force_reinit: å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
        skip_models: è·³è¿‡æ¨¡å‹è®¾ç½®
        skip_connectors: è·³è¿‡è¿æ¥å™¨è®¾ç½®

    Returns:
        æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
    """
    try:
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        # å¦‚æœæŒ‡å®šäº†ç¯å¢ƒåç§°ï¼Œå…ˆåˆ‡æ¢ç¯å¢ƒ
        if env_name:
            env_manager = get_environment_manager()
            from core.environment_manager import Environment

            target_env = Environment.from_string(env_name)

            if target_env != env_manager.current_environment:
                logger.info(f"åˆ‡æ¢åˆ°ç›®æ ‡ç¯å¢ƒ: {target_env.value}")
                env_manager.permanently_switch_environment(target_env)

                # é‡ç½®æœåŠ¡facadeä»¥ä½¿ç”¨æ–°ç¯å¢ƒ
                reset_service_facade()

        # åˆ›å»ºåˆå§‹åŒ–å™¨å¹¶æ‰§è¡Œåˆå§‹åŒ–
        initializer = EnvironmentInitializer()
        success = await initializer.initialize_current_environment(
            force_reinit=force_reinit,
            skip_models=skip_models,
            skip_connectors=skip_connectors,
        )

        return success

    except Exception as e:
        logger.error(f"ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback

        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False


async def main():
    """CLIä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Linch Mind Environment Initializer")
    parser.add_argument("--env", "-e", help="ç›®æ ‡ç¯å¢ƒ (development/staging/production)")
    parser.add_argument("--force", "-f", action="store_true", help="å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–")
    parser.add_argument("--skip-models", action="store_true", help="è·³è¿‡æ¨¡å‹è®¾ç½®")
    parser.add_argument("--skip-connectors", action="store_true", help="è·³è¿‡è¿æ¥å™¨è®¾ç½®")
    parser.add_argument("--list-envs", action="store_true", help="åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒ")

    args = parser.parse_args()

    if args.list_envs:
        env_manager = get_environment_manager()
        envs = env_manager.list_environments()

        print("å¯ç”¨ç¯å¢ƒ:")
        for env in envs:
            marker = (
                " (å½“å‰)"
                if env["name"] == env_manager.current_environment.value
                else ""
            )
            print(f"  - {env['display_name']} ({env['name']}){marker}")
            print(f"    è·¯å¾„: {env['base_path']}")
        return

    # æ‰§è¡Œåˆå§‹åŒ–
    success = await initialize_environment(
        env_name=args.env,
        force_reinit=args.force,
        skip_models=args.skip_models,
        skip_connectors=args.skip_connectors,
    )

    if success:
        print("âœ… ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        print("âŒ ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
