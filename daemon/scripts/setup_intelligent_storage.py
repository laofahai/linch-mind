#!/usr/bin/env python3
"""
æ™ºèƒ½å­˜å‚¨ç¯å¢ƒè®¾ç½®è„šæœ¬
è‡ªåŠ¨è®¾ç½®Ollamaæ¨¡å‹ã€å­˜å‚¨ç›®å½•ç»“æ„å’Œåˆå§‹åŒ–é…ç½®
"""

import asyncio
import json
import logging
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import aiohttp

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config.intelligent_storage import get_config_manager, get_intelligent_storage_config
from core.environment_manager import get_environment_manager

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class IntelligentStorageSetup:
    """æ™ºèƒ½å­˜å‚¨ç¯å¢ƒè®¾ç½®å™¨"""
    
    def __init__(self):
        self.config_manager = get_config_manager()
        self.config = get_intelligent_storage_config()
        self.env_manager = get_environment_manager()
        
        # Ollamaè¿æ¥è®¾ç½®
        self.ollama_host = self.config.ollama.host
        self.embedding_model = self.config.ollama.embedding_model
        self.llm_model = self.config.ollama.llm_model
        
        # æ‰€éœ€æ¨¡å‹åˆ—è¡¨
        self.required_models = [
            self.embedding_model,
            self.llm_model,
        ]

    async def setup_complete_environment(self) -> bool:
        """è®¾ç½®å®Œæ•´çš„æ™ºèƒ½å­˜å‚¨ç¯å¢ƒ"""
        try:
            logger.info("ğŸš€ å¼€å§‹è®¾ç½®æ™ºèƒ½å­˜å‚¨ç¯å¢ƒ...")
            
            # 1. æ£€æŸ¥ç³»ç»Ÿä¾èµ–
            if not await self._check_system_dependencies():
                return False
            
            # 2. è®¾ç½®å­˜å‚¨ç›®å½•ç»“æ„
            await self._setup_storage_directories()
            
            # 3. æ£€æŸ¥å’Œå®‰è£…Ollama
            if not await self._setup_ollama():
                return False
            
            # 4. ä¸‹è½½å¿…éœ€æ¨¡å‹
            if not await self._download_required_models():
                return False
            
            # 5. éªŒè¯æ¨¡å‹å¯ç”¨æ€§
            if not await self._verify_models():
                return False
            
            # 6. ç”Ÿæˆé…ç½®æ–‡ä»¶
            await self._generate_config_files()
            
            # 7. åˆå§‹åŒ–å­˜å‚¨ç»“æ„
            await self._initialize_storage_structure()
            
            # 8. è¿è¡Œç³»ç»Ÿæµ‹è¯•
            if not await self._run_system_tests():
                logger.warning("ç³»ç»Ÿæµ‹è¯•å¤±è´¥ï¼Œä½†ç¯å¢ƒè®¾ç½®å·²å®Œæˆ")
            
            logger.info("âœ… æ™ºèƒ½å­˜å‚¨ç¯å¢ƒè®¾ç½®å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return False

    # === ç³»ç»Ÿä¾èµ–æ£€æŸ¥ ===

    async def _check_system_dependencies(self) -> bool:
        """æ£€æŸ¥ç³»ç»Ÿä¾èµ–"""
        logger.info("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
        
        # æ£€æŸ¥PythonåŒ…
        required_packages = [
            "faiss-cpu",
            "aiohttp", 
            "numpy",
            "sqlalchemy",
        ]
        
        missing_packages = []
        for package in required_packages:
            try:
                __import__(package.replace("-", "_"))
            except ImportError:
                missing_packages.append(package)
        
        if missing_packages:
            logger.error(f"ç¼ºå°‘å¿…éœ€çš„PythonåŒ…: {missing_packages}")
            logger.info("è¯·è¿è¡Œ: pip install " + " ".join(missing_packages))
            return False
        
        # æ£€æŸ¥å¯é€‰åŒ…
        optional_packages = ["psutil", "sentence-transformers"]
        for package in optional_packages:
            try:
                __import__(package.replace("-", "_"))
                logger.info(f"âœ… å¯é€‰åŒ…å·²å®‰è£…: {package}")
            except ImportError:
                logger.warning(f"âš ï¸  å»ºè®®å®‰è£…å¯é€‰åŒ…: {package}")
        
        logger.info("âœ… ç³»ç»Ÿä¾èµ–æ£€æŸ¥å®Œæˆ")
        return True

    # === å­˜å‚¨ç›®å½•è®¾ç½® ===

    async def _setup_storage_directories(self):
        """è®¾ç½®å­˜å‚¨ç›®å½•ç»“æ„"""
        logger.info("ğŸ“ è®¾ç½®å­˜å‚¨ç›®å½•ç»“æ„...")
        
        directories = [
            self.config.storage_dir,
            self.config.storage_dir / "hot_index",
            self.config.storage_dir / "warm_index", 
            self.config.storage_dir / "cold_archive",
            self.config.cache_dir,
            self.config.temp_dir,
            self.config.storage_dir / "backups",
            self.config.storage_dir / "logs",
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.debug(f"åˆ›å»ºç›®å½•: {directory}")
        
        # åˆ›å»ºREADMEæ–‡ä»¶
        readme_content = """# Linch Mind æ™ºèƒ½å­˜å‚¨ç›®å½•ç»“æ„

## ç›®å½•è¯´æ˜

- `hot_index/`: çƒ­æ•°æ®ç´¢å¼• (æœ€è¿‘90å¤©çš„é«˜é¢‘è®¿é—®æ•°æ®)
- `warm_index/`: æ¸©æ•°æ®ç´¢å¼• (90å¤©-1å¹´çš„ä¸­é¢‘è®¿é—®æ•°æ®)  
- `cold_archive/`: å†·æ•°æ®å½’æ¡£ (1å¹´ä»¥ä¸Šçš„ä½é¢‘è®¿é—®æ•°æ®)
- `ollama_cache/`: Ollamaæ¨¡å‹ç¼“å­˜å’Œå“åº”ç¼“å­˜
- `temp/`: ä¸´æ—¶æ–‡ä»¶ç›®å½•
- `backups/`: æ•°æ®å¤‡ä»½ç›®å½•
- `logs/`: å­˜å‚¨ç³»ç»Ÿæ—¥å¿—

## æ•°æ®ç”Ÿå‘½å‘¨æœŸ

1. æ–°æ•°æ®è¿›å…¥ `hot_index/` è¿›è¡Œå®æ—¶å¤„ç†å’Œé¢‘ç¹è®¿é—®
2. 90å¤©åè‡ªåŠ¨è¿ç§»åˆ° `warm_index/` è¿›è¡Œä¸­ç­‰é¢‘ç‡è®¿é—®
3. 1å¹´åå‹ç¼©å¹¶å½’æ¡£åˆ° `cold_archive/` è¿›è¡Œé•¿æœŸä¿å­˜
4. 3å¹´åæ ¹æ®ä»·å€¼è¯„åˆ†å†³å®šæ˜¯å¦æ°¸ä¹…åˆ é™¤

## æ³¨æ„äº‹é¡¹

- ä¸è¦æ‰‹åŠ¨ä¿®æ”¹ç´¢å¼•æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨æä¾›çš„APIæ¥å£
- å®šæœŸå¤‡ä»½ `hot_index/` å’Œ `warm_index/` ä¸­çš„é‡è¦æ•°æ®
- `temp/` ç›®å½•ä¼šè‡ªåŠ¨æ¸…ç†ï¼Œä¸è¦å­˜æ”¾é‡è¦æ–‡ä»¶
"""
        
        readme_file = self.config.storage_dir / "README.md"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        logger.info(f"âœ… å­˜å‚¨ç›®å½•ç»“æ„è®¾ç½®å®Œæˆ: {self.config.storage_dir}")

    # === Ollamaè®¾ç½® ===

    async def _setup_ollama(self) -> bool:
        """è®¾ç½®Ollama"""
        logger.info("ğŸ¤– è®¾ç½®Ollama...")
        
        # æ£€æŸ¥Ollamaæ˜¯å¦å·²å®‰è£…
        if not await self._check_ollama_installed():
            logger.info("Ollamaæœªå®‰è£…ï¼Œå¼€å§‹å®‰è£…...")
            if not await self._install_ollama():
                return False
        
        # å¯åŠ¨OllamaæœåŠ¡
        if not await self._start_ollama_service():
            return False
        
        # éªŒè¯è¿æ¥
        if not await self._check_ollama_connection():
            return False
        
        logger.info("âœ… Ollamaè®¾ç½®å®Œæˆ")
        return True

    async def _check_ollama_installed(self) -> bool:
        """æ£€æŸ¥Ollamaæ˜¯å¦å·²å®‰è£…"""
        try:
            result = subprocess.run(["ollama", "--version"], 
                                 capture_output=True, text=True)
            if result.returncode == 0:
                logger.info(f"âœ… Ollamaå·²å®‰è£…: {result.stdout.strip()}")
                return True
            return False
        except FileNotFoundError:
            return False

    async def _install_ollama(self) -> bool:
        """å®‰è£…Ollama"""
        try:
            logger.info("æ­£åœ¨ä¸‹è½½å’Œå®‰è£…Ollama...")
            
            # macOS/Linuxå®‰è£…è„šæœ¬
            install_cmd = "curl -fsSL https://ollama.com/install.sh | sh"
            process = await asyncio.create_subprocess_shell(
                install_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                logger.info("âœ… Ollamaå®‰è£…æˆåŠŸ")
                return True
            else:
                logger.error(f"Ollamaå®‰è£…å¤±è´¥: {stderr.decode()}")
                return False
                
        except Exception as e:
            logger.error(f"å®‰è£…Ollamaæ—¶å‡ºé”™: {e}")
            return False

    async def _start_ollama_service(self) -> bool:
        """å¯åŠ¨OllamaæœåŠ¡"""
        try:
            # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²è¿è¡Œ
            if await self._check_ollama_connection():
                logger.info("âœ… OllamaæœåŠ¡å·²åœ¨è¿è¡Œ")
                return True
            
            logger.info("å¯åŠ¨OllamaæœåŠ¡...")
            
            # åå°å¯åŠ¨Ollama
            process = await asyncio.create_subprocess_exec(
                "ollama", "serve",
                stdout=asyncio.subprocess.DEVNULL,
                stderr=asyncio.subprocess.DEVNULL
            )
            
            # ç­‰å¾…æœåŠ¡å¯åŠ¨
            await asyncio.sleep(3)
            
            # éªŒè¯æœåŠ¡å¯åŠ¨
            if await self._check_ollama_connection():
                logger.info("âœ… OllamaæœåŠ¡å¯åŠ¨æˆåŠŸ")
                return True
            else:
                logger.error("OllamaæœåŠ¡å¯åŠ¨å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å¯åŠ¨OllamaæœåŠ¡æ—¶å‡ºé”™: {e}")
            return False

    async def _check_ollama_connection(self) -> bool:
        """æ£€æŸ¥Ollamaè¿æ¥"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.ollama_host}/api/tags") as response:
                    if response.status == 200:
                        return True
            return False
        except Exception:
            return False

    # === æ¨¡å‹ä¸‹è½½ ===

    async def _download_required_models(self) -> bool:
        """ä¸‹è½½å¿…éœ€æ¨¡å‹"""
        logger.info("ğŸ“¥ ä¸‹è½½å¿…éœ€çš„AIæ¨¡å‹...")
        
        for model in self.required_models:
            if not await self._download_model(model):
                logger.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {model}")
                return False
        
        logger.info("âœ… æ‰€æœ‰å¿…éœ€æ¨¡å‹ä¸‹è½½å®Œæˆ")
        return True

    async def _download_model(self, model: str) -> bool:
        """ä¸‹è½½å•ä¸ªæ¨¡å‹"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
            if await self._check_model_exists(model):
                logger.info(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model}")
                return True
            
            logger.info(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model}")
            
            # ä½¿ç”¨ollama pullå‘½ä»¤ä¸‹è½½
            process = await asyncio.create_subprocess_exec(
                "ollama", "pull", model,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            # æ˜¾ç¤ºä¸‹è½½è¿›åº¦
            while True:
                line = await process.stdout.readline()
                if not line:
                    break
                logger.info(f"ä¸‹è½½è¿›åº¦: {line.decode().strip()}")
            
            await process.wait()
            
            if process.returncode == 0:
                logger.info(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: {model}")
                return True
            else:
                stderr = await process.stderr.read()
                logger.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {stderr.decode()}")
                return False
                
        except Exception as e:
            logger.error(f"ä¸‹è½½æ¨¡å‹æ—¶å‡ºé”™ [{model}]: {e}")
            return False

    async def _check_model_exists(self, model: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.ollama_host}/api/tags") as response:
                    if response.status == 200:
                        data = await response.json()
                        models = {m["name"] for m in data.get("models", [])}
                        return model in models
            return False
        except Exception:
            return False

    # === æ¨¡å‹éªŒè¯ ===

    async def _verify_models(self) -> bool:
        """éªŒè¯æ¨¡å‹åŠŸèƒ½"""
        logger.info("ğŸ§ª éªŒè¯æ¨¡å‹åŠŸèƒ½...")
        
        # æµ‹è¯•åµŒå…¥æ¨¡å‹
        if not await self._test_embedding_model():
            return False
        
        # æµ‹è¯•LLMæ¨¡å‹
        if not await self._test_llm_model():
            return False
        
        logger.info("âœ… æ¨¡å‹åŠŸèƒ½éªŒè¯å®Œæˆ")
        return True

    async def _test_embedding_model(self) -> bool:
        """æµ‹è¯•åµŒå…¥æ¨¡å‹"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.ollama_host}/api/embeddings",
                    json={
                        "model": self.embedding_model,
                        "prompt": "æµ‹è¯•æ–‡æœ¬å‘é‡åŒ–åŠŸèƒ½"
                    }
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        embedding = data.get("embedding", [])
                        if len(embedding) == 384:  # nomic-embed-textç»´åº¦
                            logger.info(f"âœ… åµŒå…¥æ¨¡å‹æµ‹è¯•æˆåŠŸ: {self.embedding_model}")
                            return True
            
            logger.error(f"åµŒå…¥æ¨¡å‹æµ‹è¯•å¤±è´¥: {self.embedding_model}")
            return False
            
        except Exception as e:
            logger.error(f"æµ‹è¯•åµŒå…¥æ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False

    async def _test_llm_model(self) -> bool:
        """æµ‹è¯•LLMæ¨¡å‹"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.ollama_host}/api/generate",
                    json={
                        "model": self.llm_model,
                        "prompt": "è¯·å›å¤'æ¨¡å‹æµ‹è¯•æˆåŠŸ'",
                        "stream": False
                    }
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        response_text = data.get("response", "")
                        if "æˆåŠŸ" in response_text or "success" in response_text.lower():
                            logger.info(f"âœ… LLMæ¨¡å‹æµ‹è¯•æˆåŠŸ: {self.llm_model}")
                            return True
            
            logger.error(f"LLMæ¨¡å‹æµ‹è¯•å¤±è´¥: {self.llm_model}")
            return False
            
        except Exception as e:
            logger.error(f"æµ‹è¯•LLMæ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False

    # === é…ç½®æ–‡ä»¶ç”Ÿæˆ ===

    async def _generate_config_files(self):
        """ç”Ÿæˆé…ç½®æ–‡ä»¶"""
        logger.info("ğŸ“ ç”Ÿæˆé…ç½®æ–‡ä»¶...")
        
        # ç”Ÿæˆé…ç½®æ¨¡æ¿
        config_template_path = self.config.storage_dir / "config_template.json"
        self.config_manager.save_config_template(config_template_path)
        
        # å¯¼å‡ºå½“å‰é…ç½®
        current_config_path = self.config.storage_dir / "current_config.json"
        self.config_manager.export_current_config(current_config_path)
        
        # ç”Ÿæˆç¯å¢ƒå˜é‡æ–‡ä»¶
        env_file_path = self.config.storage_dir / ".env.example"
        env_content = f"""# Linch Mind æ™ºèƒ½å­˜å‚¨ç¯å¢ƒå˜é‡

# Ollamaé…ç½®
OLLAMA_HOST={self.ollama_host}
OLLAMA_EMBEDDING_MODEL={self.embedding_model}
OLLAMA_LLM_MODEL={self.llm_model}

# å¤„ç†é…ç½®
ENABLE_INTELLIGENT_PROCESSING=true
AI_VALUE_THRESHOLD={self.config.ollama.value_threshold}

# å­˜å‚¨é…ç½®
STORAGE_DIR={self.config.storage_dir}
CACHE_DIR={self.config.cache_dir}

# è°ƒè¯•é…ç½®
DEBUG={str(self.config.debug).lower()}
ENVIRONMENT={self.config.environment}
"""
        
        with open(env_file_path, 'w', encoding='utf-8') as f:
            f.write(env_content)
        
        logger.info(f"âœ… é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ: {self.config.storage_dir}")

    # === å­˜å‚¨ç»“æ„åˆå§‹åŒ– ===

    async def _initialize_storage_structure(self):
        """åˆå§‹åŒ–å­˜å‚¨ç»“æ„"""
        logger.info("ğŸ—ƒï¸  åˆå§‹åŒ–å­˜å‚¨ç»“æ„...")
        
        # åˆ›å»ºåˆ†ç‰‡å…ƒæ•°æ®æ–‡ä»¶
        shard_metadata = {
            "shards": [],
            "version": "1.0",
            "created_at": datetime.utcnow().isoformat(),
            "last_updated": datetime.utcnow().isoformat(),
        }
        
        metadata_file = self.config.storage_dir / "shard_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(shard_metadata, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºç»Ÿè®¡æ–‡ä»¶
        stats_file = self.config.storage_dir / "storage_stats.json"
        initial_stats = {
            "total_documents": 0,
            "total_shards": 0,
            "storage_size_mb": 0.0,
            "last_updated": datetime.utcnow().isoformat(),
        }
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(initial_stats, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… å­˜å‚¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")

    # === ç³»ç»Ÿæµ‹è¯• ===

    async def _run_system_tests(self) -> bool:
        """è¿è¡Œç³»ç»Ÿæµ‹è¯•"""
        logger.info("ğŸ§ª è¿è¡Œç³»ç»Ÿæµ‹è¯•...")
        
        try:
            # å¯¼å…¥å¹¶æµ‹è¯•æ ¸å¿ƒç»„ä»¶
            from services.ai.ollama_service import OllamaService
            from services.storage.faiss_vector_store import FAISSVectorStore
            from services.storage.intelligent_event_processor import IntelligentEventProcessor
            
            # æµ‹è¯•OllamaæœåŠ¡
            ollama_service = OllamaService(
                ollama_host=self.ollama_host,
                embedding_model=self.embedding_model,
                llm_model=self.llm_model,
            )
            
            if not await ollama_service.initialize():
                logger.error("OllamaæœåŠ¡åˆå§‹åŒ–æµ‹è¯•å¤±è´¥")
                return False
            
            # æµ‹è¯•å†…å®¹è¯„ä¼°
            test_score = await ollama_service.evaluate_content_value("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹")
            if 0.0 <= test_score <= 1.0:
                logger.info(f"âœ… å†…å®¹è¯„ä¼°æµ‹è¯•æˆåŠŸ: {test_score:.3f}")
            else:
                logger.error("å†…å®¹è¯„ä¼°æµ‹è¯•å¤±è´¥")
                return False
            
            # æµ‹è¯•å‘é‡å­˜å‚¨
            vector_store = FAISSVectorStore(storage_dir=self.config.storage_dir)
            if not await vector_store.initialize():
                logger.error("å‘é‡å­˜å‚¨åˆå§‹åŒ–æµ‹è¯•å¤±è´¥")
                return False
            
            await ollama_service.close()
            await vector_store.close()
            
            logger.info("âœ… ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            return False

    # === å…¬å…±æ¥å£ ===

    async def check_environment_status(self) -> Dict[str, bool]:
        """æ£€æŸ¥ç¯å¢ƒçŠ¶æ€"""
        status = {
            "ollama_installed": await self._check_ollama_installed(),
            "ollama_running": await self._check_ollama_connection(),
            "models_available": True,
            "storage_dirs": True,
        }
        
        # æ£€æŸ¥æ¨¡å‹
        for model in self.required_models:
            if not await self._check_model_exists(model):
                status["models_available"] = False
                break
        
        # æ£€æŸ¥å­˜å‚¨ç›®å½•
        required_dirs = [
            self.config.storage_dir,
            self.config.cache_dir,
            self.config.temp_dir,
        ]
        
        for directory in required_dirs:
            if not directory.exists():
                status["storage_dirs"] = False
                break
        
        return status

    async def repair_environment(self) -> bool:
        """ä¿®å¤ç¯å¢ƒé—®é¢˜"""
        logger.info("ğŸ”§ ä¿®å¤ç¯å¢ƒé—®é¢˜...")
        
        status = await self.check_environment_status()
        
        # ä¿®å¤Ollama
        if not status["ollama_installed"]:
            if not await self._install_ollama():
                return False
        
        if not status["ollama_running"]:
            if not await self._start_ollama_service():
                return False
        
        # ä¿®å¤æ¨¡å‹
        if not status["models_available"]:
            if not await self._download_required_models():
                return False
        
        # ä¿®å¤å­˜å‚¨ç›®å½•
        if not status["storage_dirs"]:
            await self._setup_storage_directories()
        
        logger.info("âœ… ç¯å¢ƒä¿®å¤å®Œæˆ")
        return True


async def main():
    """ä¸»å‡½æ•°"""
    setup = IntelligentStorageSetup()
    
    print("ğŸš€ Linch Mind æ™ºèƒ½å­˜å‚¨ç¯å¢ƒè®¾ç½®")
    print("=" * 50)
    
    # æ£€æŸ¥å½“å‰çŠ¶æ€
    status = await setup.check_environment_status()
    print(f"å½“å‰ç¯å¢ƒçŠ¶æ€:")
    for key, value in status.items():
        status_icon = "âœ…" if value else "âŒ"
        print(f"  {status_icon} {key}: {value}")
    
    print()
    
    # å¦‚æœç¯å¢ƒä¸å®Œæ•´ï¼Œè¿›è¡Œè®¾ç½®
    if not all(status.values()):
        confirm = input("æ˜¯å¦ç»§ç»­è®¾ç½®æ™ºèƒ½å­˜å‚¨ç¯å¢ƒ? (y/N): ")
        if confirm.lower() in ('y', 'yes'):
            success = await setup.setup_complete_environment()
            if success:
                print("\nğŸ‰ æ™ºèƒ½å­˜å‚¨ç¯å¢ƒè®¾ç½®æˆåŠŸï¼")
                print(f"å­˜å‚¨ç›®å½•: {setup.config.storage_dir}")
                print(f"ç¼“å­˜ç›®å½•: {setup.config.cache_dir}")
                print(f"Ollamaä¸»æœº: {setup.ollama_host}")
            else:
                print("\nâŒ ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                return 1
        else:
            print("å–æ¶ˆè®¾ç½®")
            return 0
    else:
        print("âœ… ç¯å¢ƒå·²æ­£ç¡®è®¾ç½®ï¼Œæ— éœ€é¢å¤–æ“ä½œ")
    
    return 0


if __name__ == "__main__":
    import sys
    from datetime import datetime
    
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­è®¾ç½®")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ è®¾ç½®è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)