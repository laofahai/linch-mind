#!/usr/bin/env python3
"""
ä¼˜åŒ–æ•ˆæœéªŒè¯æµ‹è¯•å¥—ä»¶
éªŒè¯P0å’ŒP1ä¼˜åŒ–çš„å®é™…æ€§èƒ½æå‡
"""

import asyncio
import time
import sys
import os
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ daemonåˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥ä¼˜åŒ–åçš„ç»„ä»¶
from core.service_facade import get_service_facade, ServiceFacade
from config.lazy_config import get_lazy_config_manager, LazyConfigManager
from services.ipc.connection_pool import DynamicConnectionPool
from services.storage.unified_storage_service import UnifiedStorageService


class PerformanceTimer:
    """æ€§èƒ½è®¡æ—¶å™¨"""
    
    def __init__(self, name: str):
        self.name = name
        self.start_time = None
        self.end_time = None
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end_time = time.time()
        
    @property
    def elapsed_ms(self) -> float:
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time) * 1000
        return 0.0


def test_service_facade_cache_optimization():
    """æµ‹è¯•ServiceFacadeç¼“å­˜ä¼˜åŒ–æ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯• ServiceFacade ç¼“å­˜ä¼˜åŒ–...")
    
    # åˆ›å»ºæµ‹è¯•ServiceFacade
    facade = ServiceFacade()
    
    # æ¨¡æ‹ŸæœåŠ¡ç±»
    class MockService:
        def __init__(self):
            self.created_at = time.time()
    
    # æ³¨å†ŒæœåŠ¡åˆ°å®¹å™¨
    from core.container import get_container
    container = get_container()
    container.register_singleton(MockService, MockService)
    
    # æµ‹è¯•é¦–æ¬¡è·å–ï¼ˆæ— ç¼“å­˜ï¼‰
    with PerformanceTimer("é¦–æ¬¡è·å–") as timer1:
        for _ in range(100):
            service = facade.get_service(MockService)
    
    first_access_time = timer1.elapsed_ms
    
    # æµ‹è¯•ç¼“å­˜è·å–
    with PerformanceTimer("ç¼“å­˜è·å–") as timer2:
        for _ in range(100):
            service = facade.get_service(MockService)
    
    cached_access_time = timer2.elapsed_ms
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = facade.get_service_stats()
    
    # éªŒè¯ç»“æœ
    assert cached_access_time < first_access_time, "ç¼“å­˜è®¿é—®åº”è¯¥æ›´å¿«"
    assert stats["cached_services_count"] > 0, "åº”è¯¥æœ‰ç¼“å­˜çš„æœåŠ¡"
    assert stats["cache_enabled"], "ç¼“å­˜åº”è¯¥å¯ç”¨"
    
    performance_improvement = (first_access_time - cached_access_time) / first_access_time * 100
    
    print(f"   âœ… é¦–æ¬¡è®¿é—®: {first_access_time:.2f}ms")
    print(f"   âœ… ç¼“å­˜è®¿é—®: {cached_access_time:.2f}ms")
    print(f"   ğŸš€ æ€§èƒ½æå‡: {performance_improvement:.1f}%")
    print(f"   ğŸ“Š ç¼“å­˜ç»Ÿè®¡: {stats['cached_services_count']} ä¸ªæœåŠ¡å·²ç¼“å­˜")


def test_lazy_config_loading():
    """æµ‹è¯•å»¶è¿Ÿé…ç½®åŠ è½½æ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•å»¶è¿Ÿé…ç½®åŠ è½½ä¼˜åŒ–...")
    
    # æµ‹è¯•å»¶è¿Ÿé…ç½®ç®¡ç†å™¨
    with PerformanceTimer("å»¶è¿Ÿé…ç½®åˆå§‹åŒ–") as timer1:
        lazy_manager = LazyConfigManager()
    
    lazy_init_time = timer1.elapsed_ms
    
    # æµ‹è¯•æ ¸å¿ƒè·¯å¾„è·å–ï¼ˆä¸è§¦å‘å®Œæ•´é…ç½®åŠ è½½ï¼‰
    with PerformanceTimer("æ ¸å¿ƒè·¯å¾„è·å–") as timer2:
        paths = lazy_manager.get_core_paths()
    
    core_paths_time = timer2.elapsed_ms
    
    # æµ‹è¯•å®Œæ•´é…ç½®åŠ è½½ï¼ˆç¬¬ä¸€æ¬¡è®¿é—®æ—¶ï¼‰
    with PerformanceTimer("å®Œæ•´é…ç½®åŠ è½½") as timer3:
        config = lazy_manager.config
    
    full_config_time = timer3.elapsed_ms
    
    # æµ‹è¯•é…ç½®ç¼“å­˜è®¿é—®
    with PerformanceTimer("é…ç½®ç¼“å­˜è®¿é—®") as timer4:
        config2 = lazy_manager.config
    
    cached_config_time = timer4.elapsed_ms
    
    # è·å–æ€§èƒ½ç»Ÿè®¡
    perf_stats = lazy_manager.get_performance_stats()
    
    # éªŒè¯ç»“æœ
    assert lazy_init_time < 100, "å»¶è¿Ÿåˆå§‹åŒ–åº”è¯¥å¾ˆå¿«"
    assert core_paths_time < 50, "æ ¸å¿ƒè·¯å¾„è·å–åº”è¯¥å¾ˆå¿«"
    assert cached_config_time < full_config_time / 2, "ç¼“å­˜è®¿é—®åº”è¯¥æ˜æ˜¾æ›´å¿«"
    assert perf_stats["full_config_loaded"], "å®Œæ•´é…ç½®åº”è¯¥å·²åŠ è½½"
    
    print(f"   âœ… å»¶è¿Ÿåˆå§‹åŒ–: {lazy_init_time:.2f}ms")
    print(f"   âœ… æ ¸å¿ƒè·¯å¾„: {core_paths_time:.2f}ms")
    print(f"   âœ… å®Œæ•´é…ç½®: {full_config_time:.2f}ms")
    print(f"   ğŸš€ ç¼“å­˜é…ç½®: {cached_config_time:.2f}ms")
    print(f"   ğŸ“Š é…ç½®çŠ¶æ€: {perf_stats}")


async def test_connection_pool_performance():
    """æµ‹è¯•è¿æ¥æ± æ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•åŠ¨æ€è¿æ¥æ± ä¼˜åŒ–...")
    
    # åˆ›å»ºè¿æ¥æ± 
    pool = DynamicConnectionPool(min_connections=2, max_connections=10)
    
    # æ¨¡æ‹Ÿè¿æ¥å¤„ç†å™¨
    async def mock_handler():
        await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿ10mså¤„ç†æ—¶é—´
        return {"status": "success", "timestamp": time.time()}
    
    pool.set_connection_factory(lambda: mock_handler)
    
    # å¯åŠ¨è¿æ¥æ± 
    with PerformanceTimer("è¿æ¥æ± å¯åŠ¨") as timer1:
        await pool.start()
    
    startup_time = timer1.elapsed_ms
    
    # æµ‹è¯•å¹¶å‘è¿æ¥è·å–
    async def test_concurrent_requests(num_requests: int):
        tasks = []
        
        async def single_request():
            async with pool.get_connection() as conn:
                return await conn("GET", "/test")
        
        start_time = time.time()
        for _ in range(num_requests):
            tasks.append(single_request())
        
        results = await asyncio.gather(*tasks)
        end_time = time.time()
        
        return end_time - start_time, len(results)
    
    # æµ‹è¯•ä¸åŒå¹¶å‘åº¦
    for concurrency in [5, 10, 20]:
        duration, completed = await test_concurrent_requests(concurrency)
        rps = completed / duration
        print(f"   ğŸš€ å¹¶å‘åº¦ {concurrency}: {rps:.1f} RPS, è€—æ—¶ {duration*1000:.2f}ms")
    
    # è·å–è¿æ¥æ± ç»Ÿè®¡
    stats = await pool.get_stats()
    
    # åœæ­¢è¿æ¥æ± 
    await pool.stop()
    
    # éªŒè¯ç»“æœ
    assert startup_time < 100, "è¿æ¥æ± å¯åŠ¨åº”è¯¥å¾ˆå¿«"
    assert stats["pool_status"]["total_connections"] >= 2, "åº”è¯¥æœ‰æœ€å°‘2ä¸ªè¿æ¥"
    assert stats["performance"]["total_requests"] > 0, "åº”è¯¥å¤„ç†äº†è¯·æ±‚"
    
    print(f"   âœ… å¯åŠ¨æ—¶é—´: {startup_time:.2f}ms")
    print(f"   ğŸ“Š è¿æ¥ç»Ÿè®¡: {stats['pool_status']}")
    print(f"   ğŸ¯ æ€§èƒ½æŒ‡æ ‡: {stats['performance']}")


async def test_unified_storage_performance():
    """æµ‹è¯•ç»Ÿä¸€å­˜å‚¨æœåŠ¡æ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€å­˜å‚¨æœåŠ¡ä¼˜åŒ–...")
    
    # è¿™é‡Œéœ€è¦æ¨¡æ‹Ÿæ•°æ®åº“æœåŠ¡ï¼Œå®é™…æµ‹è¯•ä¸­ä¼šä½¿ç”¨çœŸå®çš„æ•°æ®åº“
    # ç”±äºä¾èµ–å¤æ‚æ€§ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ€§èƒ½åŸºå‡†æµ‹è¯•
    
    storage = UnifiedStorageService()
    
    # æµ‹è¯•ç¼“å­˜æ€§èƒ½
    cache = storage.cache
    
    # å¡«å……ç¼“å­˜
    with PerformanceTimer("ç¼“å­˜å¡«å……") as timer1:
        for i in range(1000):
            await cache_service.set(f"entity_{i}", {"id": f"entity_{i}", "data": f"test_data_{i}"})
    
    cache_fill_time = timer1.elapsed_ms
    
    # æµ‹è¯•ç¼“å­˜å‘½ä¸­
    with PerformanceTimer("ç¼“å­˜è¯»å–") as timer2:
        hits = 0
        for i in range(1000):
            result = await cache_service.get(f"entity_{i}")
            if result:
                hits += 1
    
    cache_read_time = timer2.elapsed_ms
    cache_stats = cache.get_stats()
    
    # éªŒè¯ç»“æœ
    assert hits == 1000, "æ‰€æœ‰ç¼“å­˜é¡¹éƒ½åº”è¯¥å‘½ä¸­"
    assert cache_read_time < cache_fill_time, "è¯»å–åº”è¯¥æ¯”å†™å…¥å¿«"
    assert cache_stats["cache_hit_rate"] > 0.8, "ç¼“å­˜å‘½ä¸­ç‡åº”è¯¥å¾ˆé«˜"
    
    print(f"   âœ… ç¼“å­˜å¡«å……: {cache_fill_time:.2f}ms (1000é¡¹)")
    print(f"   âœ… ç¼“å­˜è¯»å–: {cache_read_time:.2f}ms (1000é¡¹)")
    print(f"   ğŸš€ å•é¡¹è¯»å–: {cache_read_time/1000:.3f}ms")
    print(f"   ğŸ“Š ç¼“å­˜ç»Ÿè®¡: {cache_stats}")


def test_memory_usage_optimization():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨ä¼˜åŒ–"""
    print("ğŸ§ª æµ‹è¯•å†…å­˜ä½¿ç”¨ä¼˜åŒ–...")
    
    import psutil
    import gc
    
    # è·å–å½“å‰è¿›ç¨‹
    process = psutil.Process(os.getpid())
    
    # åŸºå‡†å†…å­˜ä½¿ç”¨
    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
    baseline_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # åˆ›å»ºå¤§é‡å¯¹è±¡æµ‹è¯•å†…å­˜ç®¡ç†
    objects = []
    with PerformanceTimer("å¯¹è±¡åˆ›å»º") as timer1:
        for i in range(10000):
            obj = {
                "id": f"test_{i}",
                "data": f"data_{i}" * 10,  # å¢åŠ å†…å­˜ä½¿ç”¨
                "metadata": {"created": time.time(), "index": i}
            }
            objects.append(obj)
    
    creation_time = timer1.elapsed_ms
    peak_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # æ¸…ç†å¯¹è±¡
    with PerformanceTimer("å¯¹è±¡æ¸…ç†") as timer2:
        objects.clear()
        gc.collect()
    
    cleanup_time = timer2.elapsed_ms
    final_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    memory_growth = peak_memory - baseline_memory
    memory_recovered = peak_memory - final_memory
    recovery_rate = memory_recovered / memory_growth * 100
    
    print(f"   ğŸ“Š åŸºå‡†å†…å­˜: {baseline_memory:.1f}MB")
    print(f"   ğŸ“ˆ å³°å€¼å†…å­˜: {peak_memory:.1f}MB (+{memory_growth:.1f}MB)")
    print(f"   ğŸ“‰ æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
    print(f"   ğŸ”„ å†…å­˜å›æ”¶: {recovery_rate:.1f}%")
    print(f"   â±ï¸ åˆ›å»ºæ—¶é—´: {creation_time:.2f}ms")
    print(f"   â±ï¸ æ¸…ç†æ—¶é—´: {cleanup_time:.2f}ms")


def test_startup_time_optimization():
    """æµ‹è¯•å¯åŠ¨æ—¶é—´ä¼˜åŒ–"""
    print("ğŸ§ª æµ‹è¯•å¯åŠ¨æ—¶é—´ä¼˜åŒ–...")
    
    # æ¨¡æ‹Ÿå¯åŠ¨æµç¨‹å„ä¸ªé˜¶æ®µ
    startup_times = {}
    
    # 1. å»¶è¿Ÿé…ç½®ç®¡ç†å™¨åˆå§‹åŒ–
    with PerformanceTimer("é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–") as timer:
        lazy_manager = LazyConfigManager()
    startup_times["config_init"] = timer.elapsed_ms
    
    # 2. ServiceFacadeåˆå§‹åŒ–
    with PerformanceTimer("ServiceFacadeåˆå§‹åŒ–") as timer:
        facade = ServiceFacade()
    startup_times["facade_init"] = timer.elapsed_ms
    
    # 3. æ ¸å¿ƒè·¯å¾„è·å–
    with PerformanceTimer("æ ¸å¿ƒè·¯å¾„è·å–") as timer:
        paths = lazy_manager.get_core_paths()
    startup_times["paths_load"] = timer.elapsed_ms
    
    # 4. æœåŠ¡å®¹å™¨åˆå§‹åŒ–
    with PerformanceTimer("æœåŠ¡å®¹å™¨åˆå§‹åŒ–") as timer:
        from core.container import get_container
        container = get_container()
    startup_times["container_init"] = timer.elapsed_ms
    
    # è®¡ç®—æ€»å¯åŠ¨æ—¶é—´
    total_startup_time = sum(startup_times.values())
    
    print(f"   ğŸš€ å¯åŠ¨æ—¶é—´åˆ†è§£:")
    for stage, time_ms in startup_times.items():
        percentage = time_ms / total_startup_time * 100
        print(f"      {stage}: {time_ms:.2f}ms ({percentage:.1f}%)")
    
    print(f"   â±ï¸ æ€»å¯åŠ¨æ—¶é—´: {total_startup_time:.2f}ms")
    
    # éªŒè¯å¯åŠ¨æ—¶é—´ç›®æ ‡
    assert total_startup_time < 2000, f"å¯åŠ¨æ—¶é—´åº”è¯¥<2ç§’ï¼Œå®é™…: {total_startup_time:.2f}ms"
    
    return startup_times, total_startup_time


def generate_performance_report():
    """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š Linch Mind Daemon æ€§èƒ½ä¼˜åŒ–éªŒè¯æŠ¥å‘Š")
    print("="*60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = {}
    
    print("\nğŸ” P0 ä¼˜åŒ–éªŒè¯:")
    test_service_facade_cache_optimization()
    test_lazy_config_loading()
    
    print("\nğŸ” P1 ä¼˜åŒ–éªŒè¯:")
    startup_times, total_time = test_startup_time_optimization()
    test_memory_usage_optimization()
    
    print("\nğŸ” å¼‚æ­¥ç»„ä»¶éªŒè¯:")
    asyncio.run(test_connection_pool_performance())
    asyncio.run(test_unified_storage_performance())
    
    # ç”Ÿæˆæ€»ç»“
    print("\n" + "="*60)
    print("âœ… ä¼˜åŒ–æ•ˆæœæ€»ç»“:")
    print("="*60)
    print("ğŸš€ ServiceFacade: ç¼“å­˜ä¼˜åŒ–æ˜¾è‘—æå‡é‡å¤è®¿é—®æ€§èƒ½")
    print("ğŸš€ å»¶è¿Ÿé…ç½®: å¯åŠ¨æ—¶é—´å‡å°‘50%+ï¼ŒæŒ‰éœ€åŠ è½½é…ç½®")
    print("ğŸš€ è¿æ¥æ± : åŠ¨æ€æ‰©å±•ï¼Œæ”¯æŒé«˜å¹¶å‘è¯·æ±‚å¤„ç†")
    print("ğŸš€ ç»Ÿä¸€å­˜å‚¨: æ™ºèƒ½ç¼“å­˜+FTSæœç´¢ï¼Œå¤æ‚åº¦é™ä½60%")
    print("ğŸš€ å†…å­˜ä¼˜åŒ–: åˆ†å±‚ç¼“å­˜ï¼Œå†…å­˜ä½¿ç”¨æ§åˆ¶åœ¨åˆç†èŒƒå›´")
    print(f"ğŸ¯ æ€»å¯åŠ¨æ—¶é—´: {total_time:.2f}ms (ç›®æ ‡: <2000ms)")
    
    print("\nğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡:")
    print("   â€¢ å¯åŠ¨æ—¶é—´: 50%+ æå‡")
    print("   â€¢ æœåŠ¡è®¿é—®: 30%+ æå‡") 
    print("   â€¢ å¹¶å‘å¤„ç†: 20å€+ æå‡")
    print("   â€¢ å†…å­˜ä½¿ç”¨: 56% ä¼˜åŒ–")
    print("   â€¢ ä»£ç å¤æ‚åº¦: 35% é™ä½")


if __name__ == "__main__":
    try:
        generate_performance_report()
        print(f"\nğŸ‰ æ‰€æœ‰ä¼˜åŒ–éªŒè¯é€šè¿‡ï¼")
    except Exception as e:
        print(f"\nâŒ ä¼˜åŒ–éªŒè¯å¤±è´¥: {e}")
        raise