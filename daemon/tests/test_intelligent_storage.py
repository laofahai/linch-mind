#!/usr/bin/env python3
"""
æ™ºèƒ½å­˜å‚¨ç³»ç»Ÿæµ‹è¯•å¥—ä»¶
æµ‹è¯•AIè¯„ä¼°ã€å‘é‡å‹ç¼©ã€åˆ†ç‰‡ç®¡ç†å’Œç”Ÿå‘½å‘¨æœŸçš„å…³é”®åŠŸèƒ½
"""

import asyncio
import logging
import pytest
import tempfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List

import numpy as np

# æµ‹è¯•ç¯å¢ƒè®¾ç½®
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from config.intelligent_storage import IntelligentStorageConfig, OllamaConfig, FAISSConfig
from services.ai.ollama_service import OllamaService, ContentEvaluation
from services.storage.faiss_vector_store import FAISSVectorStore, VectorDocument
from services.storage.intelligent_event_processor import IntelligentEventProcessor
from services.storage.data_lifecycle_manager import DataLifecycleManager
from services.monitoring.storage_metrics import StorageMetricsCollector

# é…ç½®æµ‹è¯•æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TestOllamaService:
    """Ollama AIæœåŠ¡æµ‹è¯•"""
    
    @pytest.fixture
    async def ollama_service(self):
        """OllamaæœåŠ¡fixture"""
        service = OllamaService(
            ollama_host="http://localhost:11434",
            embedding_model="nomic-embed-text",
            llm_model="llama3.2:3b",
            value_threshold=0.3,
        )
        
        # æ£€æŸ¥Ollamaæ˜¯å¦å¯ç”¨
        try:
            if await service.initialize():
                yield service
                await service.close()
            else:
                pytest.skip("OllamaæœåŠ¡ä¸å¯ç”¨")
        except Exception as e:
            pytest.skip(f"OllamaæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

    @pytest.mark.asyncio
    async def test_content_value_evaluation(self, ollama_service):
        """æµ‹è¯•å†…å®¹ä»·å€¼è¯„ä¼°"""
        # æµ‹è¯•é«˜ä»·å€¼å†…å®¹
        high_value_content = "è¿™æ˜¯ä¸€ä»½é‡è¦çš„æŠ€æœ¯æ–‡æ¡£ï¼Œè¯¦ç»†æè¿°äº†ç³»ç»Ÿæ¶æ„è®¾è®¡åŸç†å’Œæœ€ä½³å®è·µã€‚"
        score = await ollama_service.evaluate_content_value(high_value_content)
        assert 0.0 <= score <= 1.0, "ä»·å€¼è¯„åˆ†åº”åœ¨0-1ä¹‹é—´"
        assert score > 0.5, "é«˜ä»·å€¼å†…å®¹è¯„åˆ†åº”è¯¥è¾ƒé«˜"
        
        # æµ‹è¯•ä½ä»·å€¼å†…å®¹
        low_value_content = "asdfjkl;asdfjkl;asdfjkl;éšæœºå­—ç¬¦ä¸²æ— æ„ä¹‰å†…å®¹"
        score = await ollama_service.evaluate_content_value(low_value_content)
        assert score < 0.5, "ä½ä»·å€¼å†…å®¹è¯„åˆ†åº”è¯¥è¾ƒä½"
        
        # æµ‹è¯•ç©ºå†…å®¹
        empty_score = await ollama_service.evaluate_content_value("")
        assert empty_score == 0.0, "ç©ºå†…å®¹è¯„åˆ†åº”ä¸º0"

    @pytest.mark.asyncio
    async def test_semantic_summary_extraction(self, ollama_service):
        """æµ‹è¯•è¯­ä¹‰æ‘˜è¦æå–"""
        long_content = """
        äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ç°ä»£ç¤¾ä¼šä¸­å‘æŒ¥ç€è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚ä»è‡ªç„¶è¯­è¨€å¤„ç†åˆ°è®¡ç®—æœºè§†è§‰ï¼Œ
        ä»æœºå™¨å­¦ä¹ åˆ°æ·±åº¦å­¦ä¹ ï¼ŒAIæŠ€æœ¯æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚æœ¬æ–‡æ¡£å°†è¯¦ç»†ä»‹ç»AIæŠ€æœ¯çš„
        å‘å±•å†ç¨‹ã€æ ¸å¿ƒç®—æ³•åŸç†ã€åº”ç”¨åœºæ™¯ä»¥åŠæœªæ¥å‘å±•è¶‹åŠ¿ã€‚æˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨æœºå™¨å­¦ä¹ æ¨¡å‹
        çš„è®­ç»ƒæ–¹æ³•ã€æ•°æ®é¢„å¤„ç†æŠ€æœ¯ã€æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ç­‰å…³é”®æŠ€æœ¯è¦ç‚¹ã€‚
        """
        
        summary = await ollama_service.extract_semantic_summary(long_content, max_length=100)
        
        assert len(summary) <= 100, "æ‘˜è¦é•¿åº¦åº”ä¸è¶…è¿‡100å­—ç¬¦"
        assert len(summary) > 0, "æ‘˜è¦ä¸åº”ä¸ºç©º"
        assert "äººå·¥æ™ºèƒ½" in summary or "AI" in summary, "æ‘˜è¦åº”åŒ…å«å…³é”®æ¦‚å¿µ"

    @pytest.mark.asyncio
    async def test_text_embedding(self, ollama_service):
        """æµ‹è¯•æ–‡æœ¬å‘é‡åŒ–"""
        test_text = "æµ‹è¯•æ–‡æœ¬å‘é‡åŒ–åŠŸèƒ½"
        embedding = await ollama_service.embed_text(test_text)
        
        assert isinstance(embedding, list), "åµŒå…¥åº”è¿”å›åˆ—è¡¨"
        assert len(embedding) == 384, "nomic-embed-textåº”è¿”å›384ç»´å‘é‡"
        assert all(isinstance(x, (int, float)) for x in embedding), "å‘é‡å…ƒç´ åº”ä¸ºæ•°å€¼"
        
        # æµ‹è¯•ç©ºæ–‡æœ¬
        empty_embedding = await ollama_service.embed_text("")
        assert len(empty_embedding) == 384, "ç©ºæ–‡æœ¬ä¹Ÿåº”è¿”å›384ç»´é›¶å‘é‡"

    @pytest.mark.asyncio
    async def test_comprehensive_content_processing(self, ollama_service):
        """æµ‹è¯•ç»¼åˆå†…å®¹å¤„ç†"""
        test_content = "è¿™æ˜¯ä¸€ä¸ªåŒ…å«æŠ€æœ¯ä¿¡æ¯çš„é‡è¦æ–‡æ¡£ï¼Œæ¶‰åŠç³»ç»Ÿè®¾è®¡å’Œæ¶æ„ä¼˜åŒ–ã€‚"
        
        evaluation = await ollama_service.process_content_comprehensive(test_content)
        
        assert isinstance(evaluation, ContentEvaluation), "åº”è¿”å›ContentEvaluationå¯¹è±¡"
        assert 0.0 <= evaluation.value_score <= 1.0, "ä»·å€¼è¯„åˆ†åº”åœ¨æœ‰æ•ˆèŒƒå›´å†…"
        assert 0.0 <= evaluation.confidence <= 1.0, "ç½®ä¿¡åº¦åº”åœ¨æœ‰æ•ˆèŒƒå›´å†…"
        assert len(evaluation.summary) > 0, "æ‘˜è¦ä¸åº”ä¸ºç©º"
        assert evaluation.content_type in ["text", "document", "url", "file_path"], "å†…å®¹ç±»å‹åº”æœ‰æ•ˆ"


class TestFAISSVectorStore:
    """FAISSå‘é‡å­˜å‚¨æµ‹è¯•"""
    
    @pytest.fixture
    async def vector_store(self):
        """å‘é‡å­˜å‚¨fixture"""
        with tempfile.TemporaryDirectory() as temp_dir:
            store = FAISSVectorStore(
                storage_dir=Path(temp_dir),
                vector_dim=384,
                compressed_dim=256,
                shard_size_limit=100,  # å°åˆ†ç‰‡ä¾¿äºæµ‹è¯•
            )
            
            if await store.initialize():
                yield store
                await store.close()
            else:
                pytest.fail("å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥")

    @pytest.mark.asyncio
    async def test_document_addition(self, vector_store):
        """æµ‹è¯•æ–‡æ¡£æ·»åŠ """
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_doc = VectorDocument(
            id="test_doc_1",
            summary="æµ‹è¯•æ–‡æ¡£æ‘˜è¦",
            embedding=np.random.rand(384).astype(np.float32),
            metadata={"type": "test", "source": "unittest"},
            content_type="text",
            value_score=0.8,
        )
        
        # æ·»åŠ æ–‡æ¡£
        success = await vector_store.add_document(test_doc)
        assert success, "æ–‡æ¡£æ·»åŠ åº”æˆåŠŸ"
        
        # éªŒè¯æŒ‡æ ‡
        metrics = await vector_store.get_metrics()
        assert metrics.total_documents >= 1, "æ–‡æ¡£è®¡æ•°åº”å¢åŠ "

    @pytest.mark.asyncio
    async def test_batch_document_addition(self, vector_store):
        """æµ‹è¯•æ‰¹é‡æ–‡æ¡£æ·»åŠ """
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æ¡£
        docs = []
        for i in range(10):
            doc = VectorDocument(
                id=f"batch_doc_{i}",
                summary=f"æ‰¹é‡æµ‹è¯•æ–‡æ¡£ {i}",
                embedding=np.random.rand(384).astype(np.float32),
                metadata={"batch": True, "index": i},
                value_score=0.5 + i * 0.05,
            )
            docs.append(doc)
        
        # æ‰¹é‡æ·»åŠ 
        added_count = await vector_store.add_documents_batch(docs)
        assert added_count == 10, "åº”æˆåŠŸæ·»åŠ æ‰€æœ‰æ–‡æ¡£"

    @pytest.mark.asyncio
    async def test_vector_search(self, vector_store):
        """æµ‹è¯•å‘é‡æœç´¢"""
        # å…ˆæ·»åŠ ä¸€äº›æµ‹è¯•æ–‡æ¡£
        docs = []
        for i in range(5):
            doc = VectorDocument(
                id=f"search_doc_{i}",
                summary=f"æœç´¢æµ‹è¯•æ–‡æ¡£ {i}",
                embedding=np.random.rand(384).astype(np.float32),
                metadata={"searchable": True},
                value_score=0.7,
            )
            docs.append(doc)
        
        await vector_store.add_documents_batch(docs)
        
        # æ‰§è¡Œæœç´¢
        query_vector = np.random.rand(384).astype(np.float32)
        results = await vector_store.search_similar(query_vector, k=3)
        
        assert len(results) <= 3, "ç»“æœæ•°é‡ä¸åº”è¶…è¿‡k"
        assert all(hasattr(r, 'score') for r in results), "ç»“æœåº”åŒ…å«ç›¸ä¼¼æ€§åˆ†æ•°"

    @pytest.mark.asyncio
    async def test_shard_management(self, vector_store):
        """æµ‹è¯•åˆ†ç‰‡ç®¡ç†"""
        # æ·»åŠ è¶³å¤Ÿå¤šçš„æ–‡æ¡£è§¦å‘åˆ†ç‰‡åˆ›å»º
        docs = []
        for i in range(150):  # è¶…è¿‡shard_size_limit
            doc = VectorDocument(
                id=f"shard_doc_{i}",
                summary=f"åˆ†ç‰‡æµ‹è¯•æ–‡æ¡£ {i}",
                embedding=np.random.rand(384).astype(np.float32),
                metadata={"shard_test": True},
                value_score=0.6,
            )
            docs.append(doc)
        
        # åˆ†æ‰¹æ·»åŠ ä»¥è§¦å‘åˆ†ç‰‡åˆ›å»º
        for i in range(0, 150, 50):
            batch = docs[i:i+50]
            await vector_store.add_documents_batch(batch)
        
        # éªŒè¯åˆ†ç‰‡åˆ›å»º
        metrics = await vector_store.get_metrics()
        assert metrics.total_shards >= 1, "åº”åˆ›å»ºè‡³å°‘ä¸€ä¸ªåˆ†ç‰‡"


class TestIntelligentEventProcessor:
    """æ™ºèƒ½äº‹ä»¶å¤„ç†å™¨æµ‹è¯•"""
    
    @pytest.fixture
    async def processor(self):
        """æ™ºèƒ½å¤„ç†å™¨fixture"""
        # æ³¨æ„ï¼šè¿™éœ€è¦OllamaæœåŠ¡è¿è¡Œ
        try:
            processor = IntelligentEventProcessor(
                value_threshold=0.3,
                entity_threshold=0.8,
                enable_vector_storage=False,  # æµ‹è¯•ä¸­ç¦ç”¨å‘é‡å­˜å‚¨
                enable_entity_extraction=False,  # æµ‹è¯•ä¸­ç¦ç”¨å®ä½“æå–
            )
            
            if await processor.initialize():
                yield processor
            else:
                pytest.skip("æ™ºèƒ½å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥")
        except Exception as e:
            pytest.skip(f"æ™ºèƒ½å¤„ç†å™¨ä¸å¯ç”¨: {e}")

    @pytest.mark.asyncio
    async def test_garbage_content_filtering(self, processor):
        """æµ‹è¯•åƒåœ¾å†…å®¹è¿‡æ»¤"""
        # æµ‹è¯•åƒåœ¾å†…å®¹ï¼ˆå¤§é‡é‡å¤å­—ç¬¦ï¼‰
        garbage_event_data = {"content": "a" * 10000}  # 10KBåƒåœ¾æ•°æ®
        
        result = await processor.process_connector_event(
            connector_id="test_connector",
            event_type="clipboard_changed",
            event_data=garbage_event_data,
            timestamp=datetime.utcnow().isoformat(),
        )
        
        assert not result.accepted, "åƒåœ¾å†…å®¹åº”è¢«æ‹’ç»"
        assert result.value_score < 0.3, "åƒåœ¾å†…å®¹ä»·å€¼è¯„åˆ†åº”ä½"

    @pytest.mark.asyncio
    async def test_valuable_content_acceptance(self, processor):
        """æµ‹è¯•æœ‰ä»·å€¼å†…å®¹æ¥å—"""
        # æµ‹è¯•æœ‰ä»·å€¼å†…å®¹
        valuable_event_data = {
            "content": "è¿™æ˜¯ä¸€ä»½é‡è¦çš„é¡¹ç›®æ–‡æ¡£ï¼ŒåŒ…å«è¯¦ç»†çš„æŠ€æœ¯è§„èŒƒå’Œå®æ–½æŒ‡å—ã€‚"
        }
        
        result = await processor.process_connector_event(
            connector_id="test_connector",
            event_type="document_created",
            event_data=valuable_event_data,
            timestamp=datetime.utcnow().isoformat(),
        )
        
        assert result.accepted, "æœ‰ä»·å€¼å†…å®¹åº”è¢«æ¥å—"
        assert result.value_score >= 0.3, "æœ‰ä»·å€¼å†…å®¹è¯„åˆ†åº”è¾¾åˆ°é˜ˆå€¼"
        assert len(result.summary) > 0, "åº”ç”Ÿæˆæ‘˜è¦"

    @pytest.mark.asyncio
    async def test_empty_content_handling(self, processor):
        """æµ‹è¯•ç©ºå†…å®¹å¤„ç†"""
        # æµ‹è¯•ç©ºå†…å®¹
        empty_event_data = {"content": ""}
        
        result = await processor.process_connector_event(
            connector_id="test_connector",
            event_type="empty_event",
            event_data=empty_event_data,
            timestamp=datetime.utcnow().isoformat(),
        )
        
        assert not result.accepted, "ç©ºå†…å®¹åº”è¢«æ‹’ç»"
        assert "æ— æœ‰æ•ˆå†…å®¹" in result.reasoning, "åº”è¯†åˆ«ä¸ºæ— æœ‰æ•ˆå†…å®¹"


class TestPerformanceBenchmarks:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_processing_performance(self):
        """æµ‹è¯•å¤„ç†æ€§èƒ½"""
        try:
            from services.ai.ollama_service import OllamaService
            
            service = OllamaService()
            if not await service.initialize():
                pytest.skip("OllamaæœåŠ¡ä¸å¯ç”¨")
            
            # æµ‹è¯•å†…å®¹è¯„ä¼°æ€§èƒ½
            test_content = "è¿™æ˜¯ä¸€ä¸ªæ€§èƒ½æµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºè¯„ä¼°AIå¤„ç†é€Ÿåº¦ã€‚"
            
            start_time = datetime.utcnow()
            for _ in range(10):
                await service.evaluate_content_value(test_content)
            
            duration = (datetime.utcnow() - start_time).total_seconds()
            avg_time_ms = (duration / 10) * 1000
            
            assert avg_time_ms < 5000, f"å¹³å‡å¤„ç†æ—¶é—´åº”å°äº5ç§’ï¼Œå®é™…: {avg_time_ms:.1f}ms"
            
            await service.close()
            
        except Exception as e:
            pytest.skip(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")

    @pytest.mark.asyncio
    async def test_compression_ratio(self):
        """æµ‹è¯•å‹ç¼©æ¯”"""
        with tempfile.TemporaryDirectory() as temp_dir:
            store = FAISSVectorStore(
                storage_dir=Path(temp_dir),
                vector_dim=384,
                compressed_dim=256,
            )
            
            if not await store.initialize():
                pytest.skip("å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥")
            
            # æ·»åŠ æµ‹è¯•æ•°æ®
            docs = []
            for i in range(100):
                doc = VectorDocument(
                    id=f"compression_test_{i}",
                    summary=f"å‹ç¼©æµ‹è¯•æ–‡æ¡£ {i}",
                    embedding=np.random.rand(384).astype(np.float32),
                    metadata={"test": "compression"},
                    value_score=0.5,
                )
                docs.append(doc)
            
            await store.add_documents_batch(docs)
            
            # æ£€æŸ¥å‹ç¼©æ¯”
            metrics = await store.get_metrics()
            compression_ratio = metrics.compression_ratio
            
            assert compression_ratio > 1.0, f"å‹ç¼©æ¯”åº”å¤§äº1ï¼Œå®é™…: {compression_ratio:.2f}"
            # æœŸæœ›å‹ç¼©æ¯”è‡³å°‘ä¸º5:1 (384ç»´float32 -> 256ç»´float16)
            assert compression_ratio >= 3.0, f"å‹ç¼©æ¯”åº”è‡³å°‘ä¸º3:1ï¼Œå®é™…: {compression_ratio:.2f}"
            
            await store.close()


class TestIntegrationFlow:
    """é›†æˆæµç¨‹æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_complete_processing_pipeline(self):
        """æµ‹è¯•å®Œæ•´å¤„ç†æµæ°´çº¿"""
        try:
            # åˆ›å»ºä¸´æ—¶ç¯å¢ƒ
            with tempfile.TemporaryDirectory() as temp_dir:
                # åˆå§‹åŒ–ç»„ä»¶
                vector_store = FAISSVectorStore(storage_dir=Path(temp_dir))
                await vector_store.initialize()
                
                processor = IntelligentEventProcessor(
                    value_threshold=0.3,
                    enable_vector_storage=True,
                    enable_entity_extraction=False,  # ç®€åŒ–æµ‹è¯•
                )
                await processor.initialize()
                
                # æµ‹è¯•å®Œæ•´æµç¨‹
                test_events = [
                    {
                        "connector_id": "test_connector",
                        "event_type": "document_created",
                        "event_data": {"content": "è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯æ–‡æ¡£"},
                        "timestamp": datetime.utcnow().isoformat(),
                    },
                    {
                        "connector_id": "test_connector", 
                        "event_type": "spam_content",
                        "event_data": {"content": "x" * 5000},  # åƒåœ¾å†…å®¹
                        "timestamp": datetime.utcnow().isoformat(),
                    },
                ]
                
                accepted_count = 0
                rejected_count = 0
                
                for event in test_events:
                    result = await processor.process_connector_event(**event)
                    if result.accepted:
                        accepted_count += 1
                    else:
                        rejected_count += 1
                
                # éªŒè¯ç»“æœ
                assert accepted_count > 0, "åº”æœ‰å†…å®¹è¢«æ¥å—"
                assert rejected_count > 0, "åº”æœ‰åƒåœ¾å†…å®¹è¢«æ‹’ç»"
                
                # è·å–å¤„ç†æŒ‡æ ‡
                metrics = await processor.get_metrics()
                assert metrics.total_events == 2, "åº”å¤„ç†2ä¸ªäº‹ä»¶"
                assert metrics.acceptance_rate < 1.0, "æ¥å—ç‡åº”å°äº100%"
                
                await vector_store.close()
                
        except Exception as e:
            pytest.skip(f"é›†æˆæµ‹è¯•å¤±è´¥: {e}")


# æµ‹è¯•è¿è¡Œå™¨
def run_tests():
    """è¿è¡Œæµ‹è¯•å¥—ä»¶"""
    print("ğŸ§ª å¼€å§‹è¿è¡Œæ™ºèƒ½å­˜å‚¨æµ‹è¯•å¥—ä»¶...")
    
    # é…ç½®pytestå‚æ•°
    pytest_args = [
        __file__,
        "-v",  # è¯¦ç»†è¾“å‡º
        "--tb=short",  # ç®€çŸ­å›æº¯
        "--asyncio-mode=auto",  # è‡ªåŠ¨å¼‚æ­¥æ¨¡å¼
    ]
    
    # è¿è¡Œæµ‹è¯•
    exit_code = pytest.main(pytest_args)
    
    if exit_code == 0:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å‡º")
    
    return exit_code


if __name__ == "__main__":
    import sys
    
    try:
        exit_code = run_tests()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)