#!/usr/bin/env python3
"""
å¿«é€Ÿç´¢å¼•å­˜å‚¨æœåŠ¡
ä¸“é—¨å¤„ç†æ¥è‡ªæ–‡ä»¶ç³»ç»Ÿè¿æ¥å™¨çš„å¿«é€Ÿç´¢å¼•äº‹ä»¶ï¼Œæä¾›Everythingçº§åˆ«çš„æœç´¢æ€§èƒ½
"""

import logging
import sqlite3
import threading
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass

from core.service_facade import get_service
from models.database_models import EntityMetadata
from services.storage.core.database import UnifiedDatabaseService

logger = logging.getLogger(__name__)


@dataclass
class FastIndexEntry:
    """å¿«é€Ÿç´¢å¼•æ¡ç›®"""
    path: str
    name: str
    size: int
    is_directory: bool
    extension: str
    last_modified: datetime
    priority: int
    indexed_at: datetime


class FastIndexStorageService:
    """
    å¿«é€Ÿç´¢å¼•å­˜å‚¨æœåŠ¡
    
    ä½¿ç”¨ä¸“é—¨ä¼˜åŒ–çš„æ•°æ®ç»“æ„å­˜å‚¨æ–‡ä»¶ç³»ç»Ÿå¿«é€Ÿç´¢å¼•ï¼Œæ”¯æŒï¼š
    - æé€Ÿæ–‡ä»¶åæœç´¢ï¼ˆç±»ä¼¼Everythingï¼‰
    - è·¯å¾„å‰ç¼€åŒ¹é…
    - æ‰©å±•åè¿‡æ»¤
    - å¤§å°å’Œæ—¶é—´èŒƒå›´æŸ¥è¯¢
    """
    
    def __init__(self):
        self._db_service = None
        self._fast_db_path = None
        self._fast_db_connection = None
        self._db_lock = threading.RLock()
        self._initialized = False
        self._stats = {
            'total_entries': 0,
            'last_update': None,
            'index_start_time': None,
            'index_completion_time': None
        }
        
    @property
    def db_service(self):
        """æ‡’åŠ è½½æ•°æ®åº“æœåŠ¡"""
        if self._db_service is None:
            try:
                self._db_service = get_service(UnifiedDatabaseService)
            except Exception as e:
                logger.warning(f"Database service not available: {str(e)}")
                return None
        return self._db_service
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–å¿«é€Ÿç´¢å¼•å­˜å‚¨"""
        if self._initialized:
            return True
            
        try:
            # è·å–æ•°æ®åº“è·¯å¾„
            if self.db_service and hasattr(self.db_service, 'database_url'):
                db_dir = Path(self.db_service.database_url).parent
                self._fast_db_path = db_dir / "fast_index.db"
            else:
                # å›é€€è·¯å¾„
                from core.environment_manager import EnvironmentManager
                env_manager = EnvironmentManager()
                self._fast_db_path = env_manager.current_config.data_dir / "fast_index.db"
            
            # åˆ›å»ºå¿«é€Ÿç´¢å¼•æ•°æ®åº“
            self._create_fast_index_database()
            self._initialized = True
            
            logger.info(f"ğŸš€ å¿«é€Ÿç´¢å¼•å­˜å‚¨æœåŠ¡åˆå§‹åŒ–å®Œæˆ: {self._fast_db_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¿«é€Ÿç´¢å¼•å­˜å‚¨æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _create_fast_index_database(self):
        """åˆ›å»ºå¿«é€Ÿç´¢å¼•æ•°æ®åº“"""
        with self._db_lock:
            try:
                self._fast_db_connection = sqlite3.connect(
                    str(self._fast_db_path),
                    check_same_thread=False,
                    timeout=30.0
                )
                
                # å¯ç”¨æ€§èƒ½ä¼˜åŒ–
                self._fast_db_connection.execute("PRAGMA journal_mode=WAL")
                self._fast_db_connection.execute("PRAGMA synchronous=NORMAL")
                self._fast_db_connection.execute("PRAGMA cache_size=10000")
                self._fast_db_connection.execute("PRAGMA temp_store=MEMORY")
                
                # åˆ›å»ºå¿«é€Ÿç´¢å¼•è¡¨
                self._fast_db_connection.execute("""
                    CREATE TABLE IF NOT EXISTS fast_index (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        path TEXT UNIQUE NOT NULL,
                        name TEXT NOT NULL,
                        name_lower TEXT NOT NULL,  -- å°å†™æ–‡ä»¶åç”¨äºå¿«é€Ÿæœç´¢
                        parent_path TEXT NOT NULL,
                        size INTEGER DEFAULT 0,
                        is_directory BOOLEAN DEFAULT 0,
                        extension TEXT DEFAULT '',
                        last_modified INTEGER NOT NULL,  -- Unixæ—¶é—´æˆ³
                        priority INTEGER DEFAULT 2,
                        indexed_at INTEGER NOT NULL,
                        UNIQUE(path)
                    )
                """)
                
                # åˆ›å»ºä¼˜åŒ–ç´¢å¼•
                indices = [
                    "CREATE INDEX IF NOT EXISTS idx_name_lower ON fast_index(name_lower)",
                    "CREATE INDEX IF NOT EXISTS idx_parent_path ON fast_index(parent_path)",
                    "CREATE INDEX IF NOT EXISTS idx_extension ON fast_index(extension)",
                    "CREATE INDEX IF NOT EXISTS idx_size ON fast_index(size)",
                    "CREATE INDEX IF NOT EXISTS idx_last_modified ON fast_index(last_modified)",
                    "CREATE INDEX IF NOT EXISTS idx_is_directory ON fast_index(is_directory)",
                    "CREATE INDEX IF NOT EXISTS idx_priority ON fast_index(priority)",
                    # å¤åˆç´¢å¼•ç”¨äºå¤æ‚æŸ¥è¯¢
                    "CREATE INDEX IF NOT EXISTS idx_name_ext ON fast_index(name_lower, extension)",
                    "CREATE INDEX IF NOT EXISTS idx_parent_name ON fast_index(parent_path, name_lower)"
                ]
                
                for idx_sql in indices:
                    self._fast_db_connection.execute(idx_sql)
                
                # åˆ›å»ºç»Ÿè®¡è¡¨
                self._fast_db_connection.execute("""
                    CREATE TABLE IF NOT EXISTS index_stats (
                        key TEXT PRIMARY KEY,
                        value TEXT NOT NULL,
                        updated_at INTEGER NOT NULL
                    )
                """)
                
                self._fast_db_connection.commit()
                logger.info("âœ… å¿«é€Ÿç´¢å¼•æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºå¿«é€Ÿç´¢å¼•æ•°æ®åº“å¤±è´¥: {e}")
                raise
    
    async def store_fast_index_batch(self, entries: List[Dict[str, Any]]) -> bool:
        """
        æ‰¹é‡å­˜å‚¨å¿«é€Ÿç´¢å¼•æ¡ç›®
        
        Args:
            entries: å¿«é€Ÿç´¢å¼•æ¡ç›®åˆ—è¡¨
            
        Returns:
            bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
        """
        if not self._initialized:
            if not self.initialize():
                return False
        
        if not entries:
            return True
            
        try:
            with self._db_lock:
                cursor = self._fast_db_connection.cursor()
                
                # å‡†å¤‡æ‰¹é‡æ’å…¥æ•°æ®
                insert_data = []
                current_time = int(datetime.utcnow().timestamp())
                
                for entry in entries:
                    path = entry.get('path', '')
                    name = entry.get('name', '')
                    
                    if not path or not name:
                        continue
                    
                    # è§£æè·¯å¾„ä¿¡æ¯
                    path_obj = Path(path)
                    parent_path = str(path_obj.parent)
                    name_lower = name.lower()
                    extension = entry.get('extension', path_obj.suffix.lower())
                    
                    # å¤„ç†ä¿®æ”¹æ—¶é—´
                    last_modified = entry.get('last_modified', current_time)
                    if isinstance(last_modified, float):
                        last_modified = int(last_modified)
                    elif isinstance(last_modified, str):
                        try:
                            last_modified = int(datetime.fromisoformat(last_modified).timestamp())
                        except:
                            last_modified = current_time
                    
                    insert_data.append((
                        path,
                        name,
                        name_lower,
                        parent_path,
                        entry.get('size', 0),
                        entry.get('is_directory', False),
                        extension,
                        last_modified,
                        entry.get('priority', 2),
                        current_time
                    ))
                
                if not insert_data:
                    return True
                
                # ä½¿ç”¨ REPLACE è¿›è¡Œæ‰¹é‡æ’å…¥ï¼ˆæ›´æ–°å·²å­˜åœ¨çš„æ¡ç›®ï¼‰
                cursor.executemany("""
                    REPLACE INTO fast_index (
                        path, name, name_lower, parent_path, size, 
                        is_directory, extension, last_modified, priority, indexed_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, insert_data)
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                total_count = cursor.execute("SELECT COUNT(*) FROM fast_index").fetchone()[0]
                self._update_stats(total_count, current_time)
                
                self._fast_db_connection.commit()
                
                logger.info(f"âœ… æ‰¹é‡å­˜å‚¨å¿«é€Ÿç´¢å¼•: {len(insert_data)} æ¡ç›®ï¼Œæ€»è®¡: {total_count}")
                return True
                
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å­˜å‚¨å¿«é€Ÿç´¢å¼•å¤±è´¥: {e}")
            if self._fast_db_connection:
                self._fast_db_connection.rollback()
            return False
    
    def search_files(
        self,
        query: str,
        limit: int = 100,
        extension_filter: Optional[str] = None,
        directory_only: bool = False,
        min_size: Optional[int] = None,
        max_size: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        å¿«é€Ÿæ–‡ä»¶æœç´¢ï¼ˆç±»ä¼¼Everythingï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
            limit: ç»“æœé™åˆ¶
            extension_filter: æ‰©å±•åè¿‡æ»¤
            directory_only: ä»…æœç´¢ç›®å½•
            min_size: æœ€å°æ–‡ä»¶å¤§å°
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self._initialized:
            if not self.initialize():
                return []
        
        try:
            with self._db_lock:
                cursor = self._fast_db_connection.cursor()
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                conditions = []
                params = []
                
                # æ–‡ä»¶åæœç´¢ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
                if query.strip():
                    query_lower = query.lower().replace('*', '%').replace('?', '_')
                    if '%' in query_lower or '_' in query_lower:
                        conditions.append("name_lower LIKE ?")
                    else:
                        conditions.append("name_lower LIKE ?")
                        query_lower = f"%{query_lower}%"
                    params.append(query_lower)
                
                # æ‰©å±•åè¿‡æ»¤
                if extension_filter:
                    if not extension_filter.startswith('.'):
                        extension_filter = '.' + extension_filter
                    conditions.append("extension = ?")
                    params.append(extension_filter.lower())
                
                # ç›®å½•è¿‡æ»¤
                if directory_only:
                    conditions.append("is_directory = 1")
                else:
                    # é»˜è®¤ä¸ä»…é™äºç›®å½•
                    pass
                
                # æ–‡ä»¶å¤§å°è¿‡æ»¤
                if min_size is not None:
                    conditions.append("size >= ?")
                    params.append(min_size)
                
                if max_size is not None:
                    conditions.append("size <= ?")
                    params.append(max_size)
                
                # æ„å»ºå®Œæ•´æŸ¥è¯¢
                where_clause = " AND ".join(conditions) if conditions else "1=1"
                sql = f"""
                    SELECT path, name, size, is_directory, extension, 
                           last_modified, priority, parent_path
                    FROM fast_index 
                    WHERE {where_clause}
                    ORDER BY priority ASC, name_lower ASC
                    LIMIT ?
                """
                params.append(limit)
                
                cursor.execute(sql, params)
                results = cursor.fetchall()
                
                # è½¬æ¢ç»“æœæ ¼å¼
                search_results = []
                for row in results:
                    search_results.append({
                        'path': row[0],
                        'name': row[1],
                        'size': row[2],
                        'is_directory': bool(row[3]),
                        'extension': row[4],
                        'last_modified': datetime.fromtimestamp(row[5]),
                        'priority': row[6],
                        'parent_path': row[7]
                    })
                
                logger.debug(f"ğŸ” å¿«é€Ÿæœç´¢å®Œæˆ: æŸ¥è¯¢='{query}', ç»“æœ={len(search_results)}")
                return search_results
                
        except Exception as e:
            logger.error(f"âŒ å¿«é€Ÿæœç´¢å¤±è´¥: {e}")
            return []
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        if not self._initialized:
            return self._stats.copy()
        
        try:
            with self._db_lock:
                cursor = self._fast_db_connection.cursor()
                
                # è·å–æ€»æ¡ç›®æ•°
                total_count = cursor.execute("SELECT COUNT(*) FROM fast_index").fetchone()[0]
                
                # è·å–æŒ‰ç±»å‹ç»Ÿè®¡
                type_stats = cursor.execute("""
                    SELECT is_directory, COUNT(*) 
                    FROM fast_index 
                    GROUP BY is_directory
                """).fetchall()
                
                files_count = 0
                dirs_count = 0
                for is_dir, count in type_stats:
                    if is_dir:
                        dirs_count = count
                    else:
                        files_count = count
                
                # è·å–æœ€è¿‘æ›´æ–°æ—¶é—´
                last_update = cursor.execute("""
                    SELECT MAX(indexed_at) FROM fast_index
                """).fetchone()[0]
                
                if last_update:
                    last_update = datetime.fromtimestamp(last_update)
                
                return {
                    'total_entries': total_count,
                    'files_count': files_count,
                    'directories_count': dirs_count,
                    'last_update': last_update,
                    'database_size': self._fast_db_path.stat().st_size if self._fast_db_path.exists() else 0,
                    'index_start_time': self._stats.get('index_start_time'),
                    'index_completion_time': self._stats.get('index_completion_time')
                }
                
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return self._stats.copy()
    
    def _update_stats(self, total_count: int, timestamp: int):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cursor = self._fast_db_connection.cursor()
            
            stats_data = [
                ('total_entries', str(total_count), timestamp),
                ('last_update', str(timestamp), timestamp)
            ]
            
            cursor.executemany("""
                REPLACE INTO index_stats (key, value, updated_at) 
                VALUES (?, ?, ?)
            """, stats_data)
            
            self._stats['total_entries'] = total_count
            self._stats['last_update'] = datetime.fromtimestamp(timestamp)
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    def clear_index(self) -> bool:
        """æ¸…ç©ºå¿«é€Ÿç´¢å¼•"""
        if not self._initialized:
            return True
            
        try:
            with self._db_lock:
                cursor = self._fast_db_connection.cursor()
                cursor.execute("DELETE FROM fast_index")
                cursor.execute("DELETE FROM index_stats")
                self._fast_db_connection.commit()
                
                self._stats = {
                    'total_entries': 0,
                    'last_update': None,
                    'index_start_time': None,
                    'index_completion_time': None
                }
                
                logger.info("ğŸ§¹ å¿«é€Ÿç´¢å¼•å·²æ¸…ç©º")
                return True
                
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºå¿«é€Ÿç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def close(self):
        """å…³é—­æœåŠ¡"""
        if self._fast_db_connection:
            self._fast_db_connection.close()
            self._fast_db_connection = None
        self._initialized = False
        logger.info("ğŸ“¦ å¿«é€Ÿç´¢å¼•å­˜å‚¨æœåŠ¡å·²å…³é—­")