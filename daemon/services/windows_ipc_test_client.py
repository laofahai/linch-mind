#!/usr/bin/env python3
"""
Windows Named Pipe IPC å®¢æˆ·ç«¯æµ‹è¯•å·¥å…·
ç”¨äºéªŒè¯Windows IPCæœåŠ¡å™¨çš„åŠŸèƒ½å’Œæ€§èƒ½
"""

import json
import logging
import platform
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from statistics import mean, median
from typing import Dict

logger = logging.getLogger(__name__)

# Windowsç‰¹å®šå¯¼å…¥
if platform.system() == "Windows":
    try:
        import pywintypes
        import win32file
        import win32pipe

        WINDOWS_SUPPORT = True
    except ImportError:
        WINDOWS_SUPPORT = False
        logger.error("éœ€è¦pywin32åº“æ”¯æŒ: pip install pywin32")
else:
    WINDOWS_SUPPORT = False


class WindowsIPCTestClient:
    """Windows IPCæµ‹è¯•å®¢æˆ·ç«¯"""

    def __init__(self, pipe_name: str = "linch-mind-test"):
        self.pipe_name = pipe_name
        self.full_pipe_name = f"\\\\.\\pipe\\{pipe_name}"

    def _connect_to_pipe(self, timeout_ms: int = 5000):
        """è¿æ¥åˆ°Named Pipe"""
        if not WINDOWS_SUPPORT:
            raise RuntimeError("Windows Named Pipeéœ€è¦pywin32åº“æ”¯æŒ")

        try:
            # ç­‰å¾…Named Pipeå¯ç”¨
            win32pipe.WaitNamedPipe(self.full_pipe_name, timeout_ms)

            # è¿æ¥åˆ°Named Pipe
            handle = win32file.CreateFile(
                self.full_pipe_name,
                win32file.GENERIC_READ | win32file.GENERIC_WRITE,
                0,  # ä¸å…±äº«
                None,  # é»˜è®¤å®‰å…¨å±æ€§
                win32file.OPEN_EXISTING,
                0,  # é»˜è®¤å±æ€§
                None,  # æ— æ¨¡æ¿æ–‡ä»¶
            )

            if handle == win32file.INVALID_HANDLE_VALUE:
                raise Exception("æ— æ³•è¿æ¥åˆ°Named Pipe")

            return handle

        except pywintypes.error as e:
            raise Exception(f"è¿æ¥Named Pipeå¤±è´¥: {e}")

    def _send_message(self, handle, message: Dict) -> Dict:
        """å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶å“åº”"""
        try:
            # åºåˆ—åŒ–æ¶ˆæ¯
            message_str = json.dumps(message)
            message_bytes = message_str.encode("utf-8")
            length_bytes = len(message_bytes).to_bytes(4, byteorder="big")

            # å‘é€é•¿åº¦å‰ç¼€å’Œæ¶ˆæ¯
            win32file.WriteFile(handle, length_bytes)
            win32file.WriteFile(handle, message_bytes)

            # è¯»å–å“åº”é•¿åº¦
            result, length_data = win32file.ReadFile(handle, 4)
            if result != 0:
                raise Exception(f"è¯»å–å“åº”é•¿åº¦å¤±è´¥: {result}")

            response_length = int.from_bytes(length_data, byteorder="big")

            # è¯»å–å®Œæ•´å“åº”
            result, response_data = win32file.ReadFile(handle, response_length)
            if result != 0:
                raise Exception(f"è¯»å–å“åº”æ•°æ®å¤±è´¥: {result}")

            response_str = response_data.decode("utf-8")
            return json.loads(response_str)

        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            raise

    def _close_connection(self, handle):
        """å…³é—­è¿æ¥"""
        try:
            win32file.CloseHandle(handle)
        except Exception as e:
            logger.warning(f"å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")

    def test_single_request(self, message: Dict = None) -> Dict:
        """æµ‹è¯•å•ä¸ªè¯·æ±‚"""
        if message is None:
            message = {
                "method": "GET",
                "path": "/test",
                "data": {"test": True, "timestamp": time.time()},
                "headers": {},
                "query_params": {},
            }

        start_time = time.perf_counter()

        try:
            handle = self._connect_to_pipe()
            response = self._send_message(handle, message)
            self._close_connection(handle)

            end_time = time.perf_counter()
            response_time = end_time - start_time

            return {
                "success": True,
                "response": response,
                "response_time_ms": response_time * 1000,
                "request": message,
            }

        except Exception as e:
            end_time = time.perf_counter()
            response_time = end_time - start_time

            return {
                "success": False,
                "error": str(e),
                "response_time_ms": response_time * 1000,
                "request": message,
            }

    def test_concurrent_requests(
        self, num_requests: int = 10, num_workers: int = 5
    ) -> Dict:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        logger.info(f"å¼€å§‹å¹¶å‘æµ‹è¯•: {num_requests} è¯·æ±‚, {num_workers} å·¥ä½œçº¿ç¨‹")

        def worker_task(request_id: int):
            message = {
                "method": "POST",
                "path": f"/test/concurrent/{request_id}",
                "data": {
                    "request_id": request_id,
                    "timestamp": time.time(),
                    "test_type": "concurrent",
                },
                "headers": {"X-Request-ID": str(request_id)},
                "query_params": {"concurrent": "true"},
            }
            return self.test_single_request(message)

        start_time = time.perf_counter()
        results = []

        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = [executor.submit(worker_task, i) for i in range(num_requests)]

            for future in as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    logger.error(f"å¹¶å‘è¯·æ±‚å¤±è´¥: {e}")
                    results.append(
                        {"success": False, "error": str(e), "response_time_ms": 0}
                    )

        end_time = time.perf_counter()
        total_time = end_time - start_time

        # ç»Ÿè®¡åˆ†æ
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]

        response_times = [r["response_time_ms"] for r in successful_requests]

        stats = {
            "total_requests": num_requests,
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "success_rate": len(successful_requests) / num_requests * 100,
            "total_time_seconds": total_time,
            "requests_per_second": num_requests / total_time,
        }

        if response_times:
            stats.update(
                {
                    "avg_response_time_ms": mean(response_times),
                    "median_response_time_ms": median(response_times),
                    "min_response_time_ms": min(response_times),
                    "max_response_time_ms": max(response_times),
                }
            )
        else:
            stats.update(
                {
                    "avg_response_time_ms": 0,
                    "median_response_time_ms": 0,
                    "min_response_time_ms": 0,
                    "max_response_time_ms": 0,
                }
            )

        return {"stats": stats, "results": results, "failed_requests": failed_requests}

    def test_stress_load(
        self, duration_seconds: int = 30, max_workers: int = 20
    ) -> Dict:
        """å‹åŠ›æµ‹è¯•"""
        logger.info(f"å¼€å§‹å‹åŠ›æµ‹è¯•: {duration_seconds} ç§’, æœ€å¤§ {max_workers} å·¥ä½œçº¿ç¨‹")

        start_time = time.perf_counter()
        end_time = start_time + duration_seconds

        results = []
        request_counter = 0

        def stress_worker():
            nonlocal request_counter
            while time.perf_counter() < end_time:
                request_id = request_counter
                request_counter += 1

                message = {
                    "method": "GET",
                    "path": f"/stress/{request_id}",
                    "data": {
                        "request_id": request_id,
                        "timestamp": time.time(),
                        "stress_test": True,
                    },
                }

                try:
                    result = self.test_single_request(message)
                    results.append(result)

                    # çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡è½½
                    time.sleep(0.001)
                except Exception as e:
                    results.append(
                        {"success": False, "error": str(e), "response_time_ms": 0}
                    )

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(stress_worker) for _ in range(max_workers)]

            # ç­‰å¾…æ‰€æœ‰å·¥ä½œå®Œæˆæˆ–è¶…æ—¶
            for future in as_completed(futures, timeout=duration_seconds + 5):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"å‹åŠ›æµ‹è¯•å·¥ä½œçº¿ç¨‹å¤±è´¥: {e}")

        actual_duration = time.perf_counter() - start_time

        # åˆ†æç»“æœ
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]

        response_times = [r["response_time_ms"] for r in successful_requests]

        stats = {
            "duration_seconds": actual_duration,
            "total_requests": len(results),
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "success_rate": (
                len(successful_requests) / len(results) * 100 if results else 0
            ),
            "requests_per_second": len(results) / actual_duration,
        }

        if response_times:
            stats.update(
                {
                    "avg_response_time_ms": mean(response_times),
                    "median_response_time_ms": median(response_times),
                    "min_response_time_ms": min(response_times),
                    "max_response_time_ms": max(response_times),
                }
            )

        return {
            "stats": stats,
            "sample_failures": failed_requests[:10],  # åªä¿ç•™å‰10ä¸ªå¤±è´¥ç¤ºä¾‹
        }

    def test_large_payload(self, payload_size_kb: int = 100) -> Dict:
        """æµ‹è¯•å¤§è´Ÿè½½"""
        large_data = "A" * (payload_size_kb * 1024)  # åˆ›å»ºæŒ‡å®šå¤§å°çš„æ•°æ®

        message = {
            "method": "POST",
            "path": "/test/large-payload",
            "data": {
                "large_field": large_data,
                "size_kb": payload_size_kb,
                "timestamp": time.time(),
            },
        }

        logger.info(f"æµ‹è¯•å¤§è´Ÿè½½: {payload_size_kb} KB")
        return self.test_single_request(message)


def run_comprehensive_test(pipe_name: str = "linch-mind-test"):
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    if not WINDOWS_SUPPORT:
        print("âŒ Windows Named Pipeæµ‹è¯•éœ€è¦pywin32åº“æ”¯æŒ")
        print("è¯·å®‰è£…: pip install pywin32")
        return False

    client = WindowsIPCTestClient(pipe_name)

    print("=" * 60)
    print("ğŸ§ª Windows Named Pipe IPC ç»¼åˆæµ‹è¯•")
    print("=" * 60)

    # 1. åŸºæœ¬è¿æ¥æµ‹è¯•
    print("\n1ï¸âƒ£ åŸºæœ¬è¿æ¥æµ‹è¯•")
    print("-" * 30)

    try:
        result = client.test_single_request()
        if result["success"]:
            print(f"âœ… è¿æ¥æˆåŠŸ (å“åº”æ—¶é—´: {result['response_time_ms']:.2f}ms)")
            print(f"   æœåŠ¡å™¨å“åº”: {result['response']['success']}")
        else:
            print(f"âŒ è¿æ¥å¤±è´¥: {result['error']}")
            return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

    # 2. å¹¶å‘æµ‹è¯•
    print("\n2ï¸âƒ£ å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print("-" * 30)

    concurrent_result = client.test_concurrent_requests(num_requests=20, num_workers=5)
    stats = concurrent_result["stats"]

    print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"æˆåŠŸè¯·æ±‚: {stats['successful_requests']}")
    print(f"å¤±è´¥è¯·æ±‚: {stats['failed_requests']}")
    print(f"æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    print(f"å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time_ms']:.2f}ms")
    print(f"ä¸­ä½å“åº”æ—¶é—´: {stats['median_response_time_ms']:.2f}ms")
    print(f"æœ€å¤§å“åº”æ—¶é—´: {stats['max_response_time_ms']:.2f}ms")
    print(f"ååé‡: {stats['requests_per_second']:.1f} req/s")

    if stats["success_rate"] < 95:
        print("âš ï¸  æˆåŠŸç‡è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨ç¨³å®šæ€§é—®é¢˜")
    elif stats["avg_response_time_ms"] > 100:
        print("âš ï¸  å“åº”æ—¶é—´è¾ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½é—®é¢˜")
    else:
        print("âœ… å¹¶å‘æµ‹è¯•é€šè¿‡")

    # 3. å‹åŠ›æµ‹è¯•
    print("\n3ï¸âƒ£ å‹åŠ›æµ‹è¯• (30ç§’)")
    print("-" * 30)

    stress_result = client.test_stress_load(
        duration_seconds=10, max_workers=10
    )  # ç¼©çŸ­æµ‹è¯•æ—¶é—´
    stress_stats = stress_result["stats"]

    print(f"æµ‹è¯•æ—¶é•¿: {stress_stats['duration_seconds']:.1f}s")
    print(f"æ€»è¯·æ±‚æ•°: {stress_stats['total_requests']}")
    print(f"æˆåŠŸç‡: {stress_stats['success_rate']:.1f}%")
    print(f"å¹³å‡ååé‡: {stress_stats['requests_per_second']:.1f} req/s")

    if "avg_response_time_ms" in stress_stats:
        print(f"å¹³å‡å“åº”æ—¶é—´: {stress_stats['avg_response_time_ms']:.2f}ms")

    if stress_stats["requests_per_second"] > 1000:
        print("âœ… å‹åŠ›æµ‹è¯•: é«˜æ€§èƒ½ (>1000 req/s)")
    elif stress_stats["requests_per_second"] > 500:
        print("âœ… å‹åŠ›æµ‹è¯•: è‰¯å¥½æ€§èƒ½ (>500 req/s)")
    else:
        print("âš ï¸  å‹åŠ›æµ‹è¯•: æ€§èƒ½éœ€ä¼˜åŒ–")

    # 4. å¤§è´Ÿè½½æµ‹è¯•
    print("\n4ï¸âƒ£ å¤§è´Ÿè½½æµ‹è¯•")
    print("-" * 30)

    for size_kb in [10, 50, 100]:
        result = client.test_large_payload(size_kb)
        if result["success"]:
            print(f"âœ… {size_kb}KB è´Ÿè½½: {result['response_time_ms']:.2f}ms")
        else:
            print(f"âŒ {size_kb}KB è´Ÿè½½å¤±è´¥: {result['error']}")

    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
    return True


if __name__ == "__main__":
    import sys

    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # ä»å‘½ä»¤è¡Œå‚æ•°è·å–pipeåç§°
    pipe_name = sys.argv[1] if len(sys.argv) > 1 else "linch-mind-test"

    success = run_comprehensive_test(pipe_name)
    sys.exit(0 if success else 1)
