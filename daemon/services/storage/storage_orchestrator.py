#!/usr/bin/env python3
"""
å­˜å‚¨ç¼–æ’å™¨ - ç»Ÿä¸€å­˜å‚¨æ¶æ„æ¥å£

é‡æ„è¯´æ˜ (2025-08-15):
- æ›¿ä»£UnifiedStorageServiceä½œä¸ºä¸»è¦å­˜å‚¨æ¥å£
- åè°ƒSQLite + NetworkX + FAISSçš„æ•°æ®è®¿é—®  
- æä¾›ç»Ÿä¸€çš„CRUD + æœç´¢ + å…³ç³»ç®¡ç†API
- ä¼˜åŒ–æœåŠ¡ä¾èµ–å’Œé”™è¯¯å¤„ç†
"""

import asyncio
import logging
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

from core.service_facade import get_service
from services.storage.core.database import UnifiedDatabaseService

logger = logging.getLogger(__name__)


@dataclass
class StorageMetrics:
    """å­˜å‚¨æŒ‡æ ‡"""
    health_status: str = "healthy"
    total_entities: int = 0
    total_relationships: int = 0
    search_requests: int = 0
    last_updated: float = field(default_factory=time.time)


class StorageOrchestrator:
    """å­˜å‚¨ç¼–æ’å™¨ - ç»Ÿä¸€å­˜å‚¨æœåŠ¡æ¥å£"""
    
    def __init__(self):
        self.db_service: Optional[UnifiedDatabaseService] = None
        self.graph_service = None
        self.vector_service = None
        self.embedding_service = None
        self._metrics = StorageMetrics()
        self._auto_sync_enabled = True
        self._initialized = False
        
        logger.info("ğŸ¯ StorageOrchestrator åˆå§‹åŒ–")
    
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰å­˜å‚¨æœåŠ¡"""
        if self._initialized:
            return
            
        try:
            # è·å–æ•°æ®åº“æœåŠ¡
            self.db_service = get_service(UnifiedDatabaseService)
            
            # å°è¯•è·å–å…¶ä»–æœåŠ¡ï¼ˆå¦‚æœå·²æ³¨å†Œï¼‰
            try:
                from services.storage.graph_service import GraphService
                self.graph_service = get_service(GraphService)
            except Exception as e:
                logger.warning(f"GraphService ä¸å¯ç”¨: {e}")
                
            try:
                from services.storage.vector_service import VectorService
                self.vector_service = get_service(VectorService)
            except Exception as e:
                logger.warning(f"VectorService ä¸å¯ç”¨: {e}")
                
            try:
                from services.storage.embedding_service import EmbeddingService
                self.embedding_service = get_service(EmbeddingService)
            except Exception as e:
                logger.warning(f"EmbeddingService ä¸å¯ç”¨: {e}")
            
            self._initialized = True
            self._metrics.health_status = "healthy"
            logger.info("âœ… StorageOrchestrator æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ StorageOrchestrator åˆå§‹åŒ–å¤±è´¥: {e}")
            self._metrics.health_status = "unhealthy"
            raise

    async def create_entity(
        self,
        entity_id: str,
        name: str,
        entity_type: str,
        description: str,
        content: str = "",
        auto_embed: bool = True,
        **kwargs
    ) -> bool:
        """åˆ›å»ºå®ä½“"""
        if not self._initialized:
            await self.initialize()
            
        try:
            # ç®€åŒ–å®ç°ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨è®°å½•å®ä½“ä¿¡æ¯
            if not hasattr(self, '_entities'):
                self._entities = {}
            
            entity_data = {
                "id": entity_id,
                "name": name,
                "type": entity_type,
                "description": description,
                "content": content,
                "created_at": time.time(),
                **kwargs
            }
            self._entities[entity_id] = entity_data
            
            # æ·»åŠ åˆ°å›¾æœåŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.graph_service and hasattr(self.graph_service, 'create_entity'):
                try:
                    await self.graph_service.create_entity(
                        entity_id=entity_id,
                        name=name,
                        entity_type=entity_type,
                        metadata={
                            "description": description,
                            "content": content,
                            **kwargs
                        }
                    )
                except Exception as e:
                    logger.warning(f"å›¾æœåŠ¡åˆ›å»ºå®ä½“å¤±è´¥ {entity_id}: {e}")
            
            # ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆå¦‚æœæœåŠ¡å¯ç”¨ï¼‰
            if auto_embed and self.embedding_service and self.vector_service:
                try:
                    if hasattr(self.embedding_service, 'create_embedding'):
                        embedding = await self.embedding_service.create_embedding(content or description)
                        if embedding and hasattr(self.vector_service, 'add_document'):
                            await self.vector_service.add_document(
                                doc_id=entity_id,
                                content=content or description,
                                embedding=embedding,
                                metadata={
                                    "name": name,
                                    "type": entity_type,
                                    "description": description
                                }
                            )
                except Exception as e:
                    logger.warning(f"åµŒå…¥ç”Ÿæˆå¤±è´¥ {entity_id}: {e}")
            
            self._metrics.total_entities += 1
            logger.debug(f"åˆ›å»ºå®ä½“æˆåŠŸ: {entity_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå®ä½“å¤±è´¥ {entity_id}: {e}")
            return False

    async def create_relationship(
        self,
        source_id: str,
        target_id: str,
        relationship_type: str,
        weight: float = 1.0,
        **metadata
    ) -> bool:
        """åˆ›å»ºå…³ç³»"""
        if not self._initialized:
            await self.initialize()
            
        try:
            # ç®€åŒ–å®ç°ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨è®°å½•å…³ç³»ä¿¡æ¯
            if not hasattr(self, '_relationships'):
                self._relationships = []
            
            relationship_data = {
                "source_id": source_id,
                "target_id": target_id,
                "type": relationship_type,
                "weight": weight,
                "created_at": time.time(),
                **metadata
            }
            self._relationships.append(relationship_data)
            
            # åœ¨å›¾æœåŠ¡ä¸­åˆ›å»ºå…³ç³»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.graph_service and hasattr(self.graph_service, 'create_relationship'):
                try:
                    await self.graph_service.create_relationship(
                        source_id=source_id,
                        target_id=target_id,
                        relationship_type=relationship_type,
                        weight=weight,
                        metadata=metadata
                    )
                except Exception as e:
                    logger.warning(f"å›¾æœåŠ¡åˆ›å»ºå…³ç³»å¤±è´¥ {source_id}->{target_id}: {e}")
            
            self._metrics.total_relationships += 1
            logger.debug(f"åˆ›å»ºå…³ç³»æˆåŠŸ: {source_id}->{target_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå…³ç³»å¤±è´¥ {source_id}->{target_id}: {e}")
            return False

    async def semantic_search(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """è¯­ä¹‰æœç´¢"""
        if not self._initialized:
            await self.initialize()
            
        results = []
        try:
            if self.vector_service and self.embedding_service:
                # ç”ŸæˆæŸ¥è¯¢å‘é‡
                query_embedding = await self.embedding_service.create_embedding(query)
                if query_embedding:
                    # æ‰§è¡Œå‘é‡æœç´¢
                    if hasattr(self.vector_service, 'search_similar'):
                        search_results = await self.vector_service.search_similar(
                            query_embedding=query_embedding,
                            limit=limit
                        )
                    else:
                        search_results = []
                    
                    # æ ¼å¼åŒ–ç»“æœ
                    for result in search_results:
                        results.append({
                            "entity_id": result.get("doc_id"),
                            "score": result.get("score", 0.0),
                            "content": result.get("content", ""),
                            "entity_type": result.get("metadata", {}).get("type", "unknown"),
                            "metadata": result.get("metadata", {})
                        })
            
            self._metrics.search_requests += 1
            return results
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            return []

    async def graph_search(self, start_entity_id: str, depth: int = 1) -> List[Dict[str, Any]]:
        """å›¾æœç´¢"""
        if not self._initialized:
            await self.initialize()
            
        try:
            if self.graph_service and hasattr(self.graph_service, 'get_neighbors'):
                neighbors = await self.graph_service.get_neighbors(
                    start_entity_id=start_entity_id,
                    depth=depth
                )
                return neighbors
            return []
            
        except Exception as e:
            logger.error(f"å›¾æœç´¢å¤±è´¥ {start_entity_id}: {e}")
            return []

    async def get_smart_recommendations(
        self, 
        entity_id: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """æ™ºèƒ½æ¨è"""
        if not self._initialized:
            await self.initialize()
            
        try:
            # ç»¼åˆå›¾å’Œå‘é‡æœç´¢çš„æ¨è
            recommendations = []
            
            # åŸºäºå›¾çš„æ¨è
            if self.graph_service:
                graph_neighbors = await self.graph_search(entity_id, depth=2)
                recommendations.extend(graph_neighbors[:limit//2])
            
            # åŸºäºè¯­ä¹‰çš„æ¨è - è·å–å®ä½“å†…å®¹è¿›è¡Œç›¸ä¼¼æœç´¢
            if self.vector_service and len(recommendations) < limit:
                entity = await self.get_entity(entity_id)
                if entity and entity.get("content"):
                    semantic_results = await self.semantic_search(
                        entity["content"], 
                        limit=limit - len(recommendations)
                    )
                    recommendations.extend(semantic_results)
            
            return recommendations[:limit]
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½æ¨èå¤±è´¥ {entity_id}: {e}")
            return []

    async def get_entity(self, entity_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å®ä½“"""
        if not self._initialized:
            await self.initialize()
            
        try:
            # ä»å†…å­˜å­˜å‚¨è·å–å®ä½“
            if hasattr(self, '_entities') and entity_id in self._entities:
                return self._entities[entity_id]
            
            # å°è¯•ä»å›¾æœåŠ¡è·å–
            if self.graph_service and hasattr(self.graph_service, 'get_entity'):
                try:
                    return await self.graph_service.get_entity(entity_id)
                except Exception as e:
                    logger.warning(f"å›¾æœåŠ¡è·å–å®ä½“å¤±è´¥ {entity_id}: {e}")
            
            return None
            
        except Exception as e:
            logger.error(f"è·å–å®ä½“å¤±è´¥ {entity_id}: {e}")
            return None

    async def update_entity(self, entity_id: str, **kwargs) -> bool:
        """æ›´æ–°å®ä½“"""
        if not self._initialized:
            await self.initialize()
            
        try:
            # æ›´æ–°å†…å­˜å­˜å‚¨ä¸­çš„å®ä½“
            if hasattr(self, '_entities') and entity_id in self._entities:
                self._entities[entity_id].update(kwargs)
                self._entities[entity_id]["updated_at"] = time.time()
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ›´æ–°å®ä½“å¤±è´¥ {entity_id}: {e}")
            return False

    async def delete_entity(self, entity_id: str) -> bool:
        """åˆ é™¤å®ä½“"""
        if not self._initialized:
            await self.initialize()
            
        try:
            deleted = False
            
            # ä»å†…å­˜å­˜å‚¨ä¸­åˆ é™¤
            if hasattr(self, '_entities') and entity_id in self._entities:
                del self._entities[entity_id]
                deleted = True
            
            # ä»å›¾æœåŠ¡ä¸­åˆ é™¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.graph_service and hasattr(self.graph_service, 'delete_entity'):
                try:
                    await self.graph_service.delete_entity(entity_id)
                    deleted = True
                except Exception as e:
                    logger.warning(f"å›¾æœåŠ¡åˆ é™¤å®ä½“å¤±è´¥ {entity_id}: {e}")
            
            # ä»å‘é‡æœåŠ¡ä¸­åˆ é™¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.vector_service and hasattr(self.vector_service, 'delete_document'):
                try:
                    await self.vector_service.delete_document(entity_id)
                    deleted = True
                except Exception as e:
                    logger.warning(f"å‘é‡æœåŠ¡åˆ é™¤å®ä½“å¤±è´¥ {entity_id}: {e}")
            
            if deleted:
                self._metrics.total_entities -= 1
            
            return deleted
            
        except Exception as e:
            logger.error(f"åˆ é™¤å®ä½“å¤±è´¥ {entity_id}: {e}")
            return False

    async def get_metrics(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨æŒ‡æ ‡"""
        if not self._initialized:
            await self.initialize()
            
        metrics_data = {
            "health_status": self._metrics.health_status,
            "total_entities": self._metrics.total_entities,
            "total_relationships": self._metrics.total_relationships,
            "search_requests": self._metrics.search_requests,
            "last_updated": self._metrics.last_updated
        }
        
        # æ”¶é›†å„æœåŠ¡çš„æŒ‡æ ‡
        if self.graph_service:
            try:
                graph_metrics = await self.graph_service.get_metrics()
                metrics_data["graph"] = graph_metrics
            except Exception as e:
                logger.warning(f"è·å–å›¾æœåŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
        
        if self.vector_service:
            try:
                vector_metrics = await self.vector_service.get_metrics()
                metrics_data["vector"] = vector_metrics
            except Exception as e:
                logger.warning(f"è·å–å‘é‡æœåŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
        
        return metrics_data

    async def sync_all(self):
        """åŒæ­¥æ‰€æœ‰å­˜å‚¨æœåŠ¡"""
        if self._auto_sync_enabled and self._initialized:
            try:
                if self.graph_service and hasattr(self.graph_service, 'sync'):
                    await self.graph_service.sync()
                
                if self.vector_service and hasattr(self.vector_service, 'sync'):
                    await self.vector_service.sync()
                
                logger.debug("å­˜å‚¨æœåŠ¡åŒæ­¥å®Œæˆ")
            except Exception as e:
                logger.error(f"å­˜å‚¨åŒæ­¥å¤±è´¥: {e}")


# å…¨å±€å®ä¾‹ç®¡ç†
_storage_orchestrator_instance: Optional[StorageOrchestrator] = None


async def get_storage_orchestrator() -> StorageOrchestrator:
    """è·å–å­˜å‚¨ç¼–æ’å™¨å•ä¾‹"""
    global _storage_orchestrator_instance
    
    if _storage_orchestrator_instance is None:
        _storage_orchestrator_instance = StorageOrchestrator()
        await _storage_orchestrator_instance.initialize()
    
    return _storage_orchestrator_instance


async def cleanup_storage_orchestrator():
    """æ¸…ç†å­˜å‚¨ç¼–æ’å™¨"""
    global _storage_orchestrator_instance
    
    if _storage_orchestrator_instance:
        try:
            # æ‰§è¡Œæ¸…ç†é€»è¾‘
            if hasattr(_storage_orchestrator_instance, 'close'):
                await _storage_orchestrator_instance.close()
        except Exception as e:
            logger.error(f"æ¸…ç†å­˜å‚¨ç¼–æ’å™¨å¤±è´¥: {e}")
        finally:
            _storage_orchestrator_instance = None