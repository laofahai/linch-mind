#!/usr/bin/env python3
"""
å…±äº«çº¿ç¨‹æ± æœåŠ¡ - æ¶ˆé™¤6ä¸ªé‡å¤ThreadPoolExecutorå®ç°
ç»Ÿä¸€ç®¡ç†IOã€CPUã€MLä»»åŠ¡çš„çº¿ç¨‹æ± èµ„æº
"""

import asyncio
import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor, Future, as_completed
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Callable, Union
import queue
import os

logger = logging.getLogger(__name__)


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    IO = "io"                    # IOå¯†é›†å‹ä»»åŠ¡ (æ–‡ä»¶è¯»å†™ã€ç½‘ç»œè¯·æ±‚)
    CPU = "cpu"                  # CPUå¯†é›†å‹ä»»åŠ¡ (è®¡ç®—ã€æ•°æ®å¤„ç†)  
    ML = "ml"                    # æœºå™¨å­¦ä¹ ä»»åŠ¡ (æ¨¡å‹æ¨ç†ã€è®­ç»ƒ)
    DATABASE = "database"        # æ•°æ®åº“æ“ä½œ
    COMPRESSION = "compression"  # å‹ç¼©/è§£å‹ç¼©
    CRYPTO = "crypto"           # åŠ å¯†/è§£å¯†æ“ä½œ
    GENERAL = "general"         # é€šç”¨ä»»åŠ¡


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4


@dataclass
class TaskInfo:
    """ä»»åŠ¡ä¿¡æ¯"""
    task_id: str
    task_type: TaskType
    priority: TaskPriority
    submitted_at: datetime = field(default_factory=datetime.utcnow)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    executor_name: str = ""
    duration_seconds: float = 0.0
    success: bool = True
    error: Optional[str] = None


@dataclass
class ExecutorStats:
    """æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯"""
    name: str
    task_type: TaskType
    max_workers: int
    active_tasks: int = 0
    queued_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    total_execution_time: float = 0.0
    avg_execution_time: float = 0.0
    peak_active_tasks: int = 0
    last_task_time: Optional[datetime] = None


@dataclass
class SystemStats:
    """ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    total_executors: int = 0
    total_active_tasks: int = 0
    total_completed_tasks: int = 0
    total_failed_tasks: int = 0
    system_load: float = 0.0
    memory_usage_mb: float = 0.0
    uptime_seconds: float = 0.0


class PriorityQueue:
    """ä¼˜å…ˆçº§ä»»åŠ¡é˜Ÿåˆ—"""
    
    def __init__(self):
        self._queue = queue.PriorityQueue()
        self._lock = threading.Lock()
        self._task_counter = 0
    
    def put(self, priority: TaskPriority, task: Callable, task_id: str):
        """æ·»åŠ ä»»åŠ¡åˆ°ä¼˜å…ˆçº§é˜Ÿåˆ—"""
        with self._lock:
            self._task_counter += 1
            # ä½¿ç”¨è´Ÿä¼˜å…ˆçº§å€¼æ¥å®ç°é«˜ä¼˜å…ˆçº§å…ˆæ‰§è¡Œ
            priority_value = -priority.value
            item = (priority_value, self._task_counter, task, task_id)
            self._queue.put(item)
    
    def get(self):
        """è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        priority_value, counter, task, task_id = self._queue.get()
        return task, task_id
    
    def qsize(self):
        """è·å–é˜Ÿåˆ—å¤§å°"""
        return self._queue.qsize()
    
    def empty(self):
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º"""
        return self._queue.empty()


class SharedExecutorService:
    """å…±äº«çº¿ç¨‹æ± æœåŠ¡ - æ¶ˆé™¤6ä¸ªé‡å¤ThreadPoolExecutorå®ç°"""
    
    def __init__(
        self,
        io_workers: int = 8,           # IOå¯†é›†å‹ä»»åŠ¡
        cpu_workers: int = 4,          # CPUå¯†é›†å‹ä»»åŠ¡  
        ml_workers: int = 2,           # MLä»»åŠ¡
        database_workers: int = 4,     # æ•°æ®åº“ä»»åŠ¡
        compression_workers: int = 2,  # å‹ç¼©ä»»åŠ¡
        crypto_workers: int = 2,       # åŠ å¯†ä»»åŠ¡
        enable_monitoring: bool = True,
        task_timeout: int = 300        # ä»»åŠ¡è¶…æ—¶(ç§’)
    ):
        # è‡ªåŠ¨è°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°é‡
        if cpu_workers == 4:  # ä½¿ç”¨é»˜è®¤å€¼æ—¶è‡ªåŠ¨è°ƒæ•´
            cpu_workers = max(2, os.cpu_count() or 4)
        
        # åˆ›å»ºä¸“ç”¨çº¿ç¨‹æ± 
        self.executors: Dict[TaskType, ThreadPoolExecutor] = {
            TaskType.IO: ThreadPoolExecutor(max_workers=io_workers, thread_name_prefix="io"),
            TaskType.CPU: ThreadPoolExecutor(max_workers=cpu_workers, thread_name_prefix="cpu"),
            TaskType.ML: ThreadPoolExecutor(max_workers=ml_workers, thread_name_prefix="ml"),
            TaskType.DATABASE: ThreadPoolExecutor(max_workers=database_workers, thread_name_prefix="db"),
            TaskType.COMPRESSION: ThreadPoolExecutor(max_workers=compression_workers, thread_name_prefix="compress"),
            TaskType.CRYPTO: ThreadPoolExecutor(max_workers=crypto_workers, thread_name_prefix="crypto"),
            TaskType.GENERAL: ThreadPoolExecutor(max_workers=io_workers, thread_name_prefix="general"),
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.executor_stats: Dict[TaskType, ExecutorStats] = {}
        for task_type, executor in self.executors.items():
            self.executor_stats[task_type] = ExecutorStats(
                name=f"{task_type.value}_executor",
                task_type=task_type,
                max_workers=executor._max_workers
            )
        
        self.system_stats = SystemStats(
            total_executors=len(self.executors),
            uptime_seconds=0.0
        )
        
        # ä»»åŠ¡è¿½è¸ª
        self.active_tasks: Dict[str, TaskInfo] = {}
        self.completed_tasks: List[TaskInfo] = []
        self.task_counter = 0
        self.task_timeout = task_timeout
        
        # ç›‘æ§å’Œæ¸…ç†
        self.enable_monitoring = enable_monitoring
        self._start_time = time.time()
        self._monitor_task = None
        self._cleanup_task = None
        self._shutdown_event = threading.Event()
        
        # ä¼˜å…ˆçº§é˜Ÿåˆ— (æœªæ¥æ‰©å±•)
        self._priority_queues: Dict[TaskType, PriorityQueue] = {
            task_type: PriorityQueue() for task_type in TaskType
        }
        
        logger.info(f"ğŸš€ SharedExecutorService åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   IOå·¥ä½œè€…: {io_workers}, CPUå·¥ä½œè€…: {cpu_workers}")
        logger.info(f"   MLå·¥ä½œè€…: {ml_workers}, æ•°æ®åº“å·¥ä½œè€…: {database_workers}")
        
        # å¯åŠ¨ç›‘æ§ (å»¶è¿Ÿåˆ°äº‹ä»¶å¾ªç¯å¯ç”¨æ—¶)
        if self.enable_monitoring:
            self._monitoring_enabled = True
        else:
            self._monitoring_enabled = False

    async def _ensure_monitoring_started(self):
        """ç¡®ä¿ç›‘æ§å·²å¯åŠ¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        if self._monitoring_enabled and self._monitor_task is None:
            try:
                self._start_monitoring()
            except Exception as e:
                logger.warning(f"å¯åŠ¨ç›‘æ§å¤±è´¥: {e}")

    async def submit(
        self,
        task: Callable,
        task_type: TaskType = TaskType.GENERAL,
        priority: TaskPriority = TaskPriority.NORMAL,
        timeout: Optional[int] = None,
        *args,
        **kwargs
    ) -> Any:
        """æäº¤ä»»åŠ¡åˆ°é€‚å½“çš„çº¿ç¨‹æ± """
        
        # ç¡®ä¿ç›‘æ§å·²å¯åŠ¨
        await self._ensure_monitoring_started()
        
        task_id = self._generate_task_id()
        task_info = TaskInfo(
            task_id=task_id,
            task_type=task_type,
            priority=priority,
            executor_name=self.executor_stats[task_type].name
        )
        
        try:
            # é€‰æ‹©åˆé€‚çš„æ‰§è¡Œå™¨
            executor = self.executors[task_type]
            
            # åˆ›å»ºåŒ…è£…ä»»åŠ¡
            wrapped_task = self._wrap_task(task, task_info, args, kwargs)
            
            # æäº¤ä»»åŠ¡
            future = executor.submit(wrapped_task)
            
            # è®°å½•ä»»åŠ¡
            self.active_tasks[task_id] = task_info
            self.executor_stats[task_type].queued_tasks += 1
            
            # ç­‰å¾…ç»“æœï¼ˆå¸¦è¶…æ—¶ï¼‰
            timeout_value = timeout or self.task_timeout
            
            try:
                result = await asyncio.wait_for(
                    asyncio.wrap_future(future),
                    timeout=timeout_value
                )
                
                # æ ‡è®°æˆåŠŸ
                task_info.success = True
                task_info.completed_at = datetime.utcnow()
                
                return result
                
            except asyncio.TimeoutError:
                logger.error(f"ä»»åŠ¡è¶…æ—¶ [{task_type.value}]: {task_id}")
                task_info.success = False
                task_info.error = "Task timeout"
                future.cancel()
                raise
                
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥ [{task_type.value}]: {e}")
            task_info.success = False
            task_info.error = str(e)
            raise
        
        finally:
            # æ¸…ç†å’Œç»Ÿè®¡
            self._finalize_task(task_id)

    async def submit_batch(
        self,
        tasks: List[Callable],
        task_type: TaskType = TaskType.GENERAL,
        priority: TaskPriority = TaskPriority.NORMAL,
        timeout: Optional[int] = None,
        max_concurrent: Optional[int] = None
    ) -> List[Any]:
        """æ‰¹é‡æäº¤ä»»åŠ¡"""
        
        if not tasks:
            return []
        
        # é™åˆ¶å¹¶å‘æ•°é‡
        if max_concurrent is None:
            max_concurrent = self.executors[task_type]._max_workers * 2
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def submit_single(task):
            async with semaphore:
                return await self.submit(task, task_type, priority, timeout)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(
            *[submit_single(task) for task in tasks],
            return_exceptions=True
        )
        
        return results

    def submit_sync(
        self,
        task: Callable,
        task_type: TaskType = TaskType.GENERAL,
        timeout: Optional[int] = None,
        *args,
        **kwargs
    ) -> Any:
        """åŒæ­¥æäº¤ä»»åŠ¡ï¼ˆéåç¨‹ç¯å¢ƒä½¿ç”¨ï¼‰"""
        
        executor = self.executors[task_type]
        future = executor.submit(task, *args, **kwargs)
        
        timeout_value = timeout or self.task_timeout
        
        try:
            return future.result(timeout=timeout_value)
        except Exception as e:
            logger.error(f"åŒæ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥ [{task_type.value}]: {e}")
            raise

    # === ä¾¿æ·æ–¹æ³• - æ›¿ä»£åŸæœ‰çš„å„ç§çº¿ç¨‹æ± ä½¿ç”¨ ===
    
    async def run_io_task(self, task: Callable, *args, **kwargs) -> Any:
        """è¿è¡ŒIOä»»åŠ¡"""
        return await self.submit(task, TaskType.IO, *args, **kwargs)
    
    async def run_cpu_task(self, task: Callable, *args, **kwargs) -> Any:
        """è¿è¡ŒCPUä»»åŠ¡"""
        return await self.submit(task, TaskType.CPU, *args, **kwargs)
    
    async def run_ml_task(self, task: Callable, *args, **kwargs) -> Any:
        """è¿è¡ŒMLä»»åŠ¡"""
        return await self.submit(task, TaskType.ML, *args, **kwargs)
    
    async def run_db_task(self, task: Callable, *args, **kwargs) -> Any:
        """è¿è¡Œæ•°æ®åº“ä»»åŠ¡"""
        return await self.submit(task, TaskType.DATABASE, *args, **kwargs)
    
    async def run_compression_task(self, task: Callable, *args, **kwargs) -> Any:
        """è¿è¡Œå‹ç¼©ä»»åŠ¡"""
        return await self.submit(task, TaskType.COMPRESSION, *args, **kwargs)
    
    async def run_crypto_task(self, task: Callable, *args, **kwargs) -> Any:
        """è¿è¡ŒåŠ å¯†ä»»åŠ¡"""
        return await self.submit(task, TaskType.CRYPTO, *args, **kwargs)

    # === ç›‘æ§å’Œç»Ÿè®¡ ===
    
    def get_executor_stats(self, task_type: Optional[TaskType] = None) -> Union[ExecutorStats, Dict[TaskType, ExecutorStats]]:
        """è·å–æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯"""
        if task_type:
            return self.executor_stats[task_type]
        return self.executor_stats.copy()
    
    def get_system_stats(self) -> SystemStats:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.system_stats.uptime_seconds = time.time() - self._start_time
        self.system_stats.total_active_tasks = len(self.active_tasks)
        self.system_stats.total_completed_tasks = len(self.completed_tasks)
        
        # è®¡ç®—ç³»ç»Ÿè´Ÿè½½
        total_active = sum(stats.active_tasks for stats in self.executor_stats.values())
        total_capacity = sum(stats.max_workers for stats in self.executor_stats.values())
        self.system_stats.system_load = total_active / total_capacity if total_capacity > 0 else 0.0
        
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        try:
            import psutil
            process = psutil.Process()
            self.system_stats.memory_usage_mb = process.memory_info().rss / 1024 / 1024
        except:
            pass
        
        return self.system_stats
    
    def get_active_tasks(self, task_type: Optional[TaskType] = None) -> List[TaskInfo]:
        """è·å–æ´»è·ƒä»»åŠ¡åˆ—è¡¨"""
        if task_type:
            return [task for task in self.active_tasks.values() if task.task_type == task_type]
        return list(self.active_tasks.values())
    
    def get_completed_tasks(
        self, 
        task_type: Optional[TaskType] = None,
        limit: int = 100
    ) -> List[TaskInfo]:
        """è·å–å·²å®Œæˆä»»åŠ¡åˆ—è¡¨"""
        tasks = self.completed_tasks[-limit:] if limit > 0 else self.completed_tasks
        
        if task_type:
            tasks = [task for task in tasks if task.task_type == task_type]
        
        return tasks

    # === å¥åº·æ£€æŸ¥å’Œç®¡ç† ===
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_info = {
            "status": "healthy",
            "executors": {},
            "issues": []
        }
        
        for task_type, executor in self.executors.items():
            stats = self.executor_stats[task_type]
            
            # æ£€æŸ¥æ‰§è¡Œå™¨çŠ¶æ€
            is_healthy = True
            if stats.active_tasks >= stats.max_workers:
                health_info["issues"].append(f"{task_type.value} executor at capacity")
                is_healthy = False
            
            if stats.failed_tasks > stats.completed_tasks * 0.1:  # å¤±è´¥ç‡>10%
                health_info["issues"].append(f"{task_type.value} executor high failure rate")
                is_healthy = False
            
            health_info["executors"][task_type.value] = {
                "healthy": is_healthy,
                "active_tasks": stats.active_tasks,
                "max_workers": stats.max_workers,
                "utilization": stats.active_tasks / stats.max_workers
            }
        
        if health_info["issues"]:
            health_info["status"] = "degraded"
        
        return health_info
    
    async def shutdown(self, wait: bool = True, timeout: float = 30.0):
        """å…³é—­æ‰€æœ‰æ‰§è¡Œå™¨"""
        logger.info("ğŸ›‘ SharedExecutorService å¼€å§‹å…³é—­")
        
        # åœæ­¢ç›‘æ§
        self._shutdown_event.set()
        if self._monitor_task:
            self._monitor_task.cancel()
        if self._cleanup_task:
            self._cleanup_task.cancel()
        
        # å…³é—­æ‰€æœ‰æ‰§è¡Œå™¨
        shutdown_tasks = []
        for task_type, executor in self.executors.items():
            logger.info(f"å…³é—­æ‰§è¡Œå™¨: {task_type.value}")
            shutdown_tasks.append(
                asyncio.get_event_loop().run_in_executor(
                    None, 
                    executor.shutdown, 
                    wait
                )
            )
        
        try:
            await asyncio.wait_for(
                asyncio.gather(*shutdown_tasks, return_exceptions=True),
                timeout=timeout
            )
            logger.info("âœ… æ‰€æœ‰æ‰§è¡Œå™¨å·²å…³é—­")
        except asyncio.TimeoutError:
            logger.warning("âš ï¸ æ‰§è¡Œå™¨å…³é—­è¶…æ—¶")
        
        # æ¸…ç†èµ„æº
        self.active_tasks.clear()
        self.completed_tasks.clear()

    # === å†…éƒ¨æ–¹æ³• ===
    
    def _generate_task_id(self) -> str:
        """ç”Ÿæˆä»»åŠ¡ID"""
        self.task_counter += 1
        timestamp = int(time.time() * 1000)
        return f"task_{timestamp}_{self.task_counter}"
    
    def _wrap_task(self, task: Callable, task_info: TaskInfo, args, kwargs) -> Callable:
        """åŒ…è£…ä»»åŠ¡ä»¥æ·»åŠ ç›‘æ§"""
        def wrapped():
            try:
                # è®°å½•å¼€å§‹æ—¶é—´
                task_info.started_at = datetime.utcnow()
                self.executor_stats[task_info.task_type].active_tasks += 1
                self.executor_stats[task_info.task_type].queued_tasks -= 1
                
                # æ›´æ–°å³°å€¼
                current_active = self.executor_stats[task_info.task_type].active_tasks
                if current_active > self.executor_stats[task_info.task_type].peak_active_tasks:
                    self.executor_stats[task_info.task_type].peak_active_tasks = current_active
                
                # æ‰§è¡Œä»»åŠ¡
                if args or kwargs:
                    result = task(*args, **kwargs)
                else:
                    result = task()
                
                return result
                
            except Exception as e:
                import traceback
                error_trace = traceback.format_exc()
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ [{task_info.task_id}]: {e}")
                logger.error(f"å¼‚å¸¸å †æ ˆ:\n{error_trace}")
                raise
            finally:
                # æ¸…ç†æ´»è·ƒä»»åŠ¡è®¡æ•°
                self.executor_stats[task_info.task_type].active_tasks -= 1
        
        return wrapped
    
    def _finalize_task(self, task_id: str):
        """å®Œæˆä»»åŠ¡å¤„ç†"""
        if task_id not in self.active_tasks:
            return
        
        task_info = self.active_tasks.pop(task_id)
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        if task_info.started_at and task_info.completed_at:
            task_info.duration_seconds = (
                task_info.completed_at - task_info.started_at
            ).total_seconds()
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats = self.executor_stats[task_info.task_type]
        if task_info.success:
            stats.completed_tasks += 1
        else:
            stats.failed_tasks += 1
        
        stats.total_execution_time += task_info.duration_seconds
        if stats.completed_tasks > 0:
            stats.avg_execution_time = stats.total_execution_time / stats.completed_tasks
        
        stats.last_task_time = task_info.completed_at or datetime.utcnow()
        
        # ä¿å­˜åˆ°å†å²è®°å½•
        self.completed_tasks.append(task_info)
        
        # é™åˆ¶å†å²è®°å½•å¤§å°
        if len(self.completed_tasks) > 1000:
            self.completed_tasks = self.completed_tasks[-1000:]
    
    def _start_monitoring(self):
        """å¯åŠ¨ç›‘æ§ä»»åŠ¡"""
        async def monitor():
            while not self._shutdown_event.is_set():
                try:
                    await asyncio.sleep(60)  # æ¯åˆ†é’Ÿç›‘æ§ä¸€æ¬¡
                    self._log_stats()
                    await self._cleanup_completed_tasks()
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {e}")
        
        self._monitor_task = asyncio.create_task(monitor())
    
    def _log_stats(self):
        """è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
        system_stats = self.get_system_stats()
        
        logger.info(f"ğŸ“Š ç³»ç»Ÿè´Ÿè½½: {system_stats.system_load:.1%}")
        logger.info(f"   æ´»è·ƒä»»åŠ¡: {system_stats.total_active_tasks}")
        logger.info(f"   å·²å®Œæˆ: {system_stats.total_completed_tasks}")
        
        # è®°å½•å„æ‰§è¡Œå™¨çŠ¶æ€
        for task_type, stats in self.executor_stats.items():
            if stats.active_tasks > 0 or stats.completed_tasks > 0:
                logger.debug(
                    f"   {task_type.value}: "
                    f"æ´»è·ƒ={stats.active_tasks}/{stats.max_workers}, "
                    f"å·²å®Œæˆ={stats.completed_tasks}, "
                    f"å¤±è´¥={stats.failed_tasks}"
                )
    
    async def _cleanup_completed_tasks(self):
        """æ¸…ç†æ—§çš„å·²å®Œæˆä»»åŠ¡è®°å½•"""
        cutoff_time = datetime.utcnow() - timedelta(hours=24)
        original_count = len(self.completed_tasks)
        
        self.completed_tasks = [
            task for task in self.completed_tasks 
            if task.completed_at and task.completed_at > cutoff_time
        ]
        
        cleaned_count = original_count - len(self.completed_tasks)
        if cleaned_count > 0:
            logger.debug(f"æ¸…ç†æ—§ä»»åŠ¡è®°å½•: {cleaned_count} é¡¹")


# å…¨å±€å®ä¾‹ç®¡ç†
_shared_executor_service: Optional[SharedExecutorService] = None


def get_shared_executor_service(**kwargs) -> SharedExecutorService:
    """è·å–å…±äº«æ‰§è¡Œå™¨æœåŠ¡å®ä¾‹"""
    global _shared_executor_service
    
    if _shared_executor_service is None:
        _shared_executor_service = SharedExecutorService(**kwargs)
    
    return _shared_executor_service


async def cleanup_shared_executor_service():
    """æ¸…ç†å…±äº«æ‰§è¡Œå™¨æœåŠ¡"""
    global _shared_executor_service
    
    if _shared_executor_service:
        try:
            await _shared_executor_service.shutdown()
            logger.info("ğŸš€ SharedExecutorService å·²æ¸…ç†")
        except Exception as e:
            logger.error(f"æ¸…ç†SharedExecutorServiceå¤±è´¥: {e}")
        finally:
            _shared_executor_service = None